"Item type","Authors","Title","Journal","Publication year","Volume","Issue","Pages","Publisher","Address","Proceedings title","Conference location","Date published","ISBN","ISSN","URLs","DOI","Abstract","Keywords","Notes","Series"
"Conference Paper","Wu J,Huang Z,Liu Q,Lian D,Wang H,Chen E,Ma H,Wang S","Federated Deep Knowledge Tracing","","2021","","","662–670","Association for Computing Machinery","New York, NY, USA","Proceedings of the 14th ACM International Conference on Web Search and Data Mining","Virtual Event, Israel","2021","9781450382977","","https://doi.org/10.1145/3437963.3441747;http://dx.doi.org/10.1145/3437963.3441747","10.1145/3437963.3441747","Knowledge tracing is a fundamental task in intelligent education for tracking the knowledge states of students on necessary concepts. In recent years, Deep Knowledge Tracing (DKT) utilizes recurrent neural networks to model student learning sequences. This approach has achieved significant success and has been widely used in many educational applications. However, in practical scenarios, it tends to suffer from the following critical problems due to data isolation: 1) Data scarcity. Educational data, which is usually distributed across different silos (e.g., schools), is difficult to gather. 2) Different data quality. Students in different silos have different learning schedules, which results in unbalanced learning records, meaning that it is necessary to evaluate the learning data quality independently for different silos. 3) Data incomparability. It is difficult to compare the knowledge states of students with different learning processes from different silos. Inspired by federated learning, in this paper, we propose a novel Federated Deep Knowledge Tracing (FDKT) framework to collectively train high-quality DKT models for multiple silos. In this framework, each client takes charge of training a distributed DKT model and evaluating data quality by leveraging its own local data, while a center server is responsible for aggregating models and updating the parameters for all the clients. In particular, in the client part, we evaluate data quality incorporating different education measurement theories, and we construct two quality-oriented implementations based on FDKT, i.e., FDKTCTT and FDKTIRT-where the means of data quality evaluation follow Classical Test Theory and Item Response Theory, respectively. Moreover, in the server part, we adopt hierarchical model interpolation to uptake local effects for model personalization. Extensive experiments on real-world datasets demonstrate the effectiveness and superiority of the FDKT framework.","intelligent education, federated learning, knowledge tracing, data quality evaluation, data isolation","","WSDM '21"
"Journal Article","Abdelrahman G,Wang Q,Nunes B","Knowledge Tracing: A Survey","ACM Comput. Surv.","2023","55","11","","Association for Computing Machinery","New York, NY, USA","","","2023-02","","0360-0300","https://doi.org/10.1145/3569576;http://dx.doi.org/10.1145/3569576","10.1145/3569576","Humans’ ability to transfer knowledge through teaching is one of the essential aspects for human intelligence. A human teacher can track the knowledge of students to customize the teaching on students’ needs. With the rise of online education platforms, there is a similar need for machines to track the knowledge of students and tailor their learning experience. This is known as the Knowledge Tracing (KT) problem in the literature. Effectively solving the KT problem would unlock the potential of computer-aided education applications such as intelligent tutoring systems, curriculum learning, and learning materials’ recommendation. Moreover, from a more general viewpoint, a student may represent any kind of intelligent agents including both human and artificial agents. Thus, the potential of KT can be extended to any machine teaching application scenarios which seek for customizing the learning experience for a student agent (i.e., a machine learning model). In this paper, we provide a comprehensive survey for the KT literature. We cover a broad range of methods starting from the early attempts to the recent state-of-the-art methods using deep learning, while highlighting the theoretical aspects of models and the characteristics of benchmark datasets. Besides these, we shed light on key modelling differences between closely related methods and summarize them in an easy-to-understand format. Finally, we discuss current research gaps in the KT literature and possible future research and application directions.","sequence modelling, key-value memory, survey, Bayesian knowledge tracing (BKT), Knowledge tracing, intelligent education, deep learning, memory networks, factor analysis","",""
"Conference Paper","Lee W,Chun J,Lee Y,Park K,Park S","Contrastive Learning for Knowledge Tracing","","2022","","","2330–2338","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM Web Conference 2022","Virtual Event, Lyon, France","2022","9781450390965","","https://doi.org/10.1145/3485447.3512105;http://dx.doi.org/10.1145/3485447.3512105","10.1145/3485447.3512105","Knowledge tracing is the task of understanding student’s knowledge acquisition processes by estimating whether to solve the next question correctly or not. Most deep learning-based methods tackle this problem by identifying hidden representations of knowledge states from learning histories. However, due to the sparse interactions between students and questions, the hidden representations can be easily over-fitted and often fail to capture student’s knowledge states accurately. This paper introduces a contrastive learning framework for knowledge tracing that reveals semantically similar or dissimilar examples of a learning history and stimulates to learn their relationships. To deal with the complexity of knowledge acquisition during learning, we carefully design the components of contrastive learning, such as architectures, data augmentation methods, and hard negatives, taking into account pedagogical rationales. Our extensive experiments on six benchmarks show statistically significant improvements from the previous methods. Further analysis shows how our methods contribute to improving knowledge tracing performances.","personalized learning, contrastive learning, educational data mining, knowledge tracing, intelligent tutoring system","","WWW '22"
"Conference Paper","Ghosh A,Heffernan N,Lan AS","Context-Aware Attentive Knowledge Tracing","","2020","","","2330–2339","Association for Computing Machinery","New York, NY, USA","Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","Virtual Event, CA, USA","2020","9781450379984","","https://doi.org/10.1145/3394486.3403282;http://dx.doi.org/10.1145/3394486.3403282","10.1145/3394486.3403282","Knowledge tracing (KT) refers to the problem of predicting future learner performance given their past performance in educational applications. Recent developments in KT using flexible deep neural network-based models excel at this task. However, these models often offer limited interpretability, thus making them insufficient for personalized learning, which requires using interpretable feedback and actionable recommendations to help learners achieve better learning outcomes. In this paper, we propose attentive knowledge tracing (AKT), which couples flexible attention-based neural network models with a series of novel, interpretable model components inspired by cognitive and psychometric models. AKT uses a novel monotonic attention mechanism that relates a learner's future responses to assessment questions to their past responses; attention weights are computed using exponential decay and a context-aware relative distance measure, in addition to the similarity between questions. Moreover, we use the Rasch model to regularize the concept and question embeddings; these embeddings are able to capture individual differences among questions on the same concept without using an excessive number of parameters. We conduct experiments on several real-world benchmark datasets and show that AKT outperforms existing KT methods (by up to $6\%$ in AUC in some cases) on predicting future learner responses. We also conduct several case studies and show that AKT exhibits excellent interpretability and thus has potential for automated feedback and personalization in real-world educational settings.","item response theory, monotonic attention, personalized learning, knowledge tracing","","KDD '20"
"Conference Paper","Long T,Qin J,Shen J,Zhang W,Xia W,Tang R,He X,Yu Y","Improving Knowledge Tracing with Collaborative Information","","2022","","","599–607","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining","Virtual Event, AZ, USA","2022","9781450391320","","https://doi.org/10.1145/3488560.3498374;http://dx.doi.org/10.1145/3488560.3498374","10.1145/3488560.3498374","Knowledge tracing, which estimates students' knowledge states by predicting the probability that they correctly answer questions, is an essential task for online learning platforms. It has gained much attention in the decades due to its importance to downstream tasks like learning material arrangement, etc. The previous deep learning-based methods trace students' knowledge states with the explicitly intra-student information, i.e., they only consider the historical information of individuals to make predictions. However, they neglect the inter-student information, which contains the response correctness of other students who have similar question-answering experiences, may offer some valuable clues. Based on this consideration, we propose a method called Collaborative Knowledge Tracing (CoKT) in this paper, which sufficiently exploits the inter-student information in knowledge tracing. It retrieves the sequences of peer students who have similar question-answering experiences to obtain the inter-student information, and integrates the inter-student information with the intra-student information to trace students' knowledge states and predict their correctness in answering questions. We validate the effectiveness of our method on four real-world datasets and compare it with 11 baselines. The experimental results reveal that CoKT achieves the best performance.","sequence retrieval, knowledge tracing, correctness prediction","","WSDM '22"
"Conference Paper","Xu B,Huang Z,Liu J,Shen S,Liu Q,Chen E,Wu J,Wang S","Learning Behavior-Oriented Knowledge Tracing","","2023","","","2789–2800","Association for Computing Machinery","New York, NY, USA","Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining","Long Beach, CA, USA","2023","","","https://doi.org/10.1145/3580305.3599407;http://dx.doi.org/10.1145/3580305.3599407","10.1145/3580305.3599407","Exploring how learners' knowledge states evolve during the learning activities is a critical task in online learning systems, which can facilitate personalized services downstream, such as course recommendation. Most of existing methods have devoted great efforts to analyzing learners' knowledge states according to their responses (i.e., right or wrong) to different questions. However, the significant effect of learners' learning behaviors (e.g., answering speed, the number of attempts) is omitted, which can reflect their knowledge acquisition deeper and ensure the reliability of the response. In this paper, we propose a Learning Behavior-oriented Knowledge Tracing (LBKT) model, with the goal of explicitly exploring the learning behavior effects on learners' knowledge states. Specifically, we first analyze and summarize several dominated learning behaviors including Speed, Attempts and Hints in the learning process. As the characteristics of different learning behaviors vary greatly, we separately estimate their various effects on learners' knowledge acquisition in a quantitative manner. Then, considering that different learning behaviors are closely dependent with each other, we assess the fused effect of multiple learning behaviors by capturing their complex dependent patterns. Finally, we integrate the forgetting factor with learners' knowledge acquisition to comprehensively update their changing knowledge states in learning. Extensive experimental results on several public datasets demonstrate that our model generates better performance prediction for learners against existing methods. Moreover, LBKT shows good interpretability in tracking learners' knowledge state by incorporating the learning behavior effects. Our codes are available at https://github.com/xbh0720/LBKT.","learning behaviors, user modeling, knowledge tracing","","KDD '23"
"Conference Paper","Zhu L,Ji Y","Deep Knowledge Tracing Integrating Multiple Learning Behaviors","","2023","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence","Sanya, China","2023","9781450398336","","https://doi.org/10.1145/3579654.3579772;http://dx.doi.org/10.1145/3579654.3579772","10.1145/3579654.3579772","By analyzing students' external learning behaviors, knowledge tracing quantifies students' latent knowledge state on this learning task, so as to further develop targeted learning and teaching plans and promote personalized learning. Students' learning behaviors in online learning platforms are diverse, such as exercise, exam and tutorial browsing. However, most of the existing knowledge tracing models only consider exercise and do not fully utilize other behaviors that also reflect students' learning process. In order to solve this problem, this paper proposes a deep knowledge tracing with multiple learning behaviors model (DKT-MLB), which combines multiple learning behaviors with knowledge concepts. The effectiveness of the proposed model is verified by experiments in a dataset built in real online learning platforms.","personalized learning, knowledge tracing, deep learning","","ACAI '22"
"Conference Paper","Tu L,Zhu X,Ji Y","Graph-Based Dynamic Interactive Knowledge Tracing","","2023","","","49–56","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2023 8th International Conference on Distance Education and Learning","Beijing, China","2023","","","https://doi.org/10.1145/3606094.3606124;http://dx.doi.org/10.1145/3606094.3606124","10.1145/3606094.3606124","Knowledge Tracing (KT) is a research field that aims to trace the students’ knowledge states based on their historical learning. Much research has explored the value of relations among concepts and proposed to introduce knowledge structure into KT tasks. However, these studies suffer from two major shortcomings: 1) they only consider the dynamic state of students or the stationary property of concepts, but ignore the dynamic state of concepts and questions. 2) they do not make full use of the rich structural information of the relations between questions and concepts. In this paper, we propose a Graph-based Dynamic Interactive Knowledge Tracing (DGKT) to address these limitations. Specifically, we design two embeddings for each student, question, and concept: static embedding and dynamic embedding, which respectively represent stable attributes and time-varying properties. Additionally, DGKT utilizes graph self-supervised learning to enrich the stationary embeddings of questions and concepts. Finally, extensive experiments on three real-world datasets demonstrate that the proposed DGKT outperforms other baseline models.","Individualized Learning, Knowledge Tracing, Graph Self-supervised Learning","","ICDEL '23"
"Conference Paper","Zhang L,Xiong X,Zhao S,Botelho A,Heffernan NT","Incorporating Rich Features into Deep Knowledge Tracing","","2017","","","169–172","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale","Cambridge, Massachusetts, USA","2017","9781450344500","","https://doi.org/10.1145/3051457.3053976;http://dx.doi.org/10.1145/3051457.3053976","10.1145/3051457.3053976","Knowledge Tracing aims to model student knowledge by predicting the correctness of each next item as students work through an assignment. Through recent developments in deep learning, Deep Knowledge Tracing (DKT) was explored as a method to improve upon traditional methods. Thus far, the DKT model has only considered the knowledge components and correctness as input, neglecting the other important features collected by computer-based learning platforms. This paper seeks to further improve upon DKT by incorporating more problem-level features. With this higher dimensional input, an adaption to the original DKT model structure is also proposed to convert the input into a low dimensional feature vector. Our results show that this adapted DKT model can effectively improve accuracy.","knowledge tracing, deep knowledge tracing (dkt), auto encoder, recurrent neural networks (rnn)","","L@S '17"
"Conference Paper","Nagatani K,Zhang Q,Sato M,Chen YY,Chen F,Ohkuma T","Augmenting Knowledge Tracing by Considering Forgetting Behavior","","2019","","","3101–3107","Association for Computing Machinery","New York, NY, USA","The World Wide Web Conference","San Francisco, CA, USA","2019","9781450366748","","https://doi.org/10.1145/3308558.3313565;http://dx.doi.org/10.1145/3308558.3313565","10.1145/3308558.3313565","Computer-aided education systems are now seeking to provide each student with personalized materials based on a student's individual knowledge. To provide suitable learning materials, tracing each student's knowledge over a period of time is important. However, predicting each student's knowledge is difficult because students tend to forget. The forgetting behavior is mainly because of two reasons: the lag time from the previous interaction, and the number of past trials on a question. Although there are a few studies that consider forgetting while modeling a student's knowledge, some models consider only partial information about forgetting, whereas others consider multiple features about forgetting, ignoring a student's learning sequence. In this paper, we focus on modeling and predicting a student's knowledge by considering their forgetting behavior. We extend the deep knowledge tracing model [17], which is a state-of-the-art sequential model for knowledge tracing, to consider forgetting by incorporating multiple types of information related to forgetting. Experiments on knowledge tracing datasets show that our proposed model improves the predictive performance as compared to baselines. Moreover, we also examine that the combination of multiple types of information that affect the behavior of forgetting results in performance improvement.","knowledge tracing, deep neural network, forgetting behavior","","WWW '19"
"Conference Paper","Guo X,Huang Z,Gao J,Shang M,Shu M,Sun J","Enhancing Knowledge Tracing via Adversarial Training","","2021","","","367–375","Association for Computing Machinery","New York, NY, USA","Proceedings of the 29th ACM International Conference on Multimedia","Virtual Event, China","2021","9781450386517","","https://doi.org/10.1145/3474085.3475554;http://dx.doi.org/10.1145/3474085.3475554","10.1145/3474085.3475554","We study the problem of knowledge tracing (KT) where the goal is to trace the students' knowledge mastery over time so as to make predictions on their future performance. Owing to the good representation capacity of deep neural networks (DNNs), recent advances on KT have increasingly concentrated on exploring DNNs to improve the performance of KT. However, we empirically reveal that the DNNs based KT models may run the risk of overfitting, especially on small datasets, leading to limited generalization. In this paper, by leveraging the current advances in adversarial training (AT), we propose an efficient AT based KT method (ATKT) to enhance KT model's generalization and thus push the limit of KT. Specifically, we first construct adversarial perturbations and add them on the original interaction embeddings as adversarial examples. The original and adversarial examples are further used to jointly train the KT model, forcing it is not only to be robust to the adversarial examples, but also to enhance the generalization over the original ones. To better implement AT, we then present an efficient attentive-LSTM model as KT backbone, where the key is a proposed knowledge hidden state attention module that adaptively aggregates information from previous knowledge hidden states while simultaneously highlighting the importance of current knowledge hidden state to make a more accurate prediction. Extensive experiments on four public benchmark datasets demonstrate that our ATKT achieves new state-of-the-art performance. Code is available at: https://github.com/xiaopengguo/ATKT.","knowledge tracing, adversarial training, knowledge hidden state attention","","MM '21"
"Conference Paper","Cheng S,Liu Q,Chen E,Zhang K,Huang Z,Yin Y,Huang X,Su Y","AdaptKT: A Domain Adaptable Method for Knowledge Tracing","","2022","","","123–131","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining","Virtual Event, AZ, USA","2022","9781450391320","","https://doi.org/10.1145/3488560.3498379;http://dx.doi.org/10.1145/3488560.3498379","10.1145/3488560.3498379","Knowledge tracing is a crucial and fundamental task in online education systems, which can predict students' knowledge state for personalized learning. Unfortunately, existing methods are domain-specific, whereas there are many domains (e.g., subjects, schools) in the real education scene and some domains suffer from the problem of lacking sufficient data. Therefore, how to exploit the knowledge in other domains, to improve the model's performance for target domain remains pretty much open. We term this problem as Domain Adaptation for Knowledge Tracing (DAKT), which aims to transfer knowledge from the source domain to the target one for knowledge tracing. In this paper, we propose a novel adaptable method, namely Adaptable Knowledge Tracing (AdaptKT), which contains three phases to explore this problem. Specifically, phase I is instance selection. Given the question texts of two domains, we train an auto-encoder to select and embed similar instances from both domains. Phase II is distribution discrepancy minimizing. After obtaining the selected instances and their linguistic representations, we train a knowledge tracing model and adopt the Maximum Mean Discrepancy (MMD) to minimize the discrepancy between the distributions of the domain-specific knowledge states. Phase III is fine-tuning of the output layer. We replace the output layer of the model that trained in phase II by a new one to make the knowledge tracing model's output dimension matches the number of knowledge concepts in the target domain. The new output layer is trained while other parameters that before it are frozen. We conduct extensive experiments on two large-scale real-world datasets, where the experimental results clearly demonstrate the effectiveness of AdaptKT for solving DAKT problem. We will public the code on the Github after the acceptance of the paper.","domain adaptation, deep learning, knowledge tracing","","WSDM '22"
"Conference Paper","Ruan S,Wei W,Landay J","Variational Deep Knowledge Tracing for Language Learning","","2021","","","323–332","Association for Computing Machinery","New York, NY, USA","LAK21: 11th International Learning Analytics and Knowledge Conference","Irvine, CA, USA","2021","9781450389358","","https://doi.org/10.1145/3448139.3448170;http://dx.doi.org/10.1145/3448139.3448170","10.1145/3448139.3448170","Deep Knowledge Tracing (DKT), which traces a student’s knowledge change using deep recurrent neural networks, is widely adopted in student cognitive modeling. Current DKT models only predict a student’s performance based on the observed learning history. However, a student’s learning processes often contain latent events not directly observable in the learning history, such as partial understanding, making slips, and guessing answers. Current DKT models fail to model this kind of stochasticity in the learning process. To address this issue, we propose Variational Deep Knowledge Tracing (VDKT), a latent variable DKT model that incorporates stochasticity into DKT through latent variables. We show that VDKT outperforms both a sequence-to-sequence DKT baseline and previous SoTA methods on MAE, F1, and AUC by evaluating our approach on two Duolingo language learning datasets. We also draw various interpretable analyses from VDKT and offer insights into students’ stochastic behaviors in language learning.","variational inference, student modeling, knowledge tracing, language learning, deep learning","","LAK21"
"Conference Paper","Zhao J,Bhatt S,Thille C,Zimmaro D,Gattani N","Interpretable Personalized Knowledge Tracing and Next Learning Activity Recommendation","","2020","","","325–328","Association for Computing Machinery","New York, NY, USA","Proceedings of the Seventh ACM Conference on Learning @ Scale","Virtual Event, USA","2020","9781450379519","","https://doi.org/10.1145/3386527.3406739;http://dx.doi.org/10.1145/3386527.3406739","10.1145/3386527.3406739","Online learning systems that provide actionable and personalized guidance can help learners make better decisions during learning. Bayesian Knowledge Tracing (BKT) extensions and deep learning based approaches have demonstrated improved mastery prediction accuracy compared to the basic BKT model; however, neither set of models provides actionable guidance on learning activities beyond mastery prediction. We propose a novel framework for personalized knowledge tracing with attention mechanism. Our proposed framework incorporates auxiliary learner attributes into knowledge tracing and interprets mastery prediction with the learning attributes. The proposed approach can also provide personalized next best learning activity recommendations. We demonstrate that the accuracy of the proposed approach in mastery prediction is slightly higher compared to deep learning based approaches and that the proposed approach can provide personalized next best learning activity recommendation.","attention mechanism, personalized knowledge tracing, knowledge tracing, recommendation","","L@S '20"
"Conference Paper","Wang C,Ma W,Zhang M,Lv C,Wan F,Lin H,Tang T,Liu Y,Ma S","Temporal Cross-Effects in Knowledge Tracing","","2021","","","517–525","Association for Computing Machinery","New York, NY, USA","Proceedings of the 14th ACM International Conference on Web Search and Data Mining","Virtual Event, Israel","2021","9781450382977","","https://doi.org/10.1145/3437963.3441802;http://dx.doi.org/10.1145/3437963.3441802","10.1145/3437963.3441802","Knowledge tracing (KT) aims to model students' knowledge level based on their historical performance, which plays an important role in computer-assisted education and adaptive learning. Recent studies try to take temporal effects of past interactions into consideration, such as the forgetting behavior. However, existing work mainly relies on time-related features or a global decay function to model the time-sensitive effects. Fine-grained temporal dynamics of different cross-skill impacts have not been well studied (named as temporal cross-effects). For example, cross-effects on some difficult skills may drop quickly, and the effects caused by distinct previous interactions may also have different temporal evolutions, which cannot be captured in a global way. In this work, we investigate fine-grained temporal cross-effects between different skills in KT. We first validate the existence of temporal cross-effects in real-world datasets through empirical studies. Then, a novel model, HawkesKT, is proposed to explicitly model the temporal cross-effects inspired by the point process, where each previous interaction will have different time-sensitive impacts on the mastery of the target skill. HawkesKT adopts two components to model temporal cross-effects: 1) mutual excitation represents the degree of cross-effects and 2) kernel function controls the adaptive temporal evolution. To the best of our knowledge, we are the first to introduce Hawkes process to model temporal cross-effects in KT. Extensive experiments on three benchmark datasets show that HawkesKT is superior to state-of-the-art KT methods. Remarkably, our method also exhibits excellent interpretability and shows significant advantages in training efficiency, which makes it more applicable in real-world large-scale educational settings.","educational data mining, knowledge tracing, temporal cross-effects, hawkes process, collaborative filtering","","WSDM '21"
"Conference Paper","Zhang M,Zhu X,Zhang C,Ji Y,Pan F,Yin C","Multi-Factors Aware Dual-Attentional Knowledge Tracing","","2021","","","2588–2597","Association for Computing Machinery","New York, NY, USA","Proceedings of the 30th ACM International Conference on Information & Knowledge Management","Virtual Event, Queensland, Australia","2021","9781450384469","","https://doi.org/10.1145/3459637.3482372;http://dx.doi.org/10.1145/3459637.3482372","10.1145/3459637.3482372","With the increasing demands of personalized learning, knowledge tracing has become important which traces students' knowledge states based on their historical practices. Factor analysis methods mainly use two kinds of factors which are separately related to students and questions to model students' knowledge states. These methods use the total number of attempts of students to model students' learning progress and hardly highlight the impact of the most recent relevant practices. Besides, current factor analysis methods ignore rich information contained in questions. In this paper, we propose Multi-Factors Aware Dual-Attentional model (MF-DAKT) which enriches question representations and utilizes multiple factors to model students' learning progress based on a dual-attentional mechanism. More specifically, we propose a novel student-related factor which records the most recent attempts on relevant concepts of students to highlight the impact of recent exercises. To enrich questions representations, we use a pre-training method to incorporate two kinds of question information including questions' relation and difficulty level. We also add a regularization term about questions' difficulty level to restrict pre-trained question representations to fine-tuning during the process of predicting students' performance. Moreover, we apply a dual-attentional mechanism to differentiate contributions of factors and factor interactions to final prediction in different practice records. At last, we conduct experiments on several real-world datasets and results show that MF-DAKT can outperform existing knowledge tracing methods. We also conduct several studies to validate the effects of each component of MF-DAKT.","deep learning, individualized learning, factor analysis, knowledge tracing","","CIKM '21"
"Conference Paper","Wang L,Sy A,Liu L,Piech C","Deep Knowledge Tracing On Programming Exercises","","2017","","","201–204","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale","Cambridge, Massachusetts, USA","2017","9781450344500","","https://doi.org/10.1145/3051457.3053985;http://dx.doi.org/10.1145/3051457.3053985","10.1145/3051457.3053985","Modeling a student's knowledge state while she is solving exercises is a crucial stepping stone towards providing better personalized learning experiences at scale. This task, also referred to as ""knowledge tracing"", has been explored extensively on exercises where student submissions fall into a finite discrete solution space, e.g. a multiple-choice answer. However, we believe that rich information about a student's learning is captured within their responses to open-ended problems with unbounded solution spaces, such as programming exercises. In addition, sequential snapshots of a student's progress while she is solving a single exercise can provide valuable insights into her learning behavior. In this setting, creating representations for a student's knowledge state is a challenging task, but with recent advances in machine learning, there are more promising techniques to learn representations for complex entities. In our work, we feed the embedded program submissions into a recurrent neural network and train it on the task of predicting the student's success on the subsequent programming exercise. By training on this task, the model learns nuanced representations of a student's knowledge, and reliably predicts future student performance.","knowledge tracing, representation learning, deep learning, machine learning, online education, sequential modeling., educational data mining, personalized learning","","L@S '17"
"Conference Paper","Liu Z,Liu Q,Chen J,Huang S,Gao B,Luo W,Weng J","Enhancing Deep Knowledge Tracing with Auxiliary Tasks","","2023","","","4178–4187","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM Web Conference 2023","Austin, TX, USA","2023","9781450394161","","https://doi.org/10.1145/3543507.3583866;http://dx.doi.org/10.1145/3543507.3583866","10.1145/3543507.3583866","Knowledge tracing (KT) is the problem of predicting students’ future performance based on their historical interactions with intelligent tutoring systems. Recent studies have applied multiple types of deep neural networks to solve the KT problem. However, there are two important factors in real-world educational data that are not well represented. First, most existing works augment input representations with the co-occurrence matrix of questions and knowledge components1 (KCs) but fail to explicitly integrate such intrinsic relations into the final response prediction task. Second, the individualized historical performance of students has not been well captured. In this paper, we proposed AT-DKT to improve the prediction performance of the original deep knowledge tracing model with two auxiliary learning tasks, i.e., question tagging (QT) prediction task and individualized prior knowledge (IK) prediction task. Specifically, the QT task helps learn better question representations by predicting whether questions contain specific KCs. The IK task captures students’ global historical performance by progressively predicting student-level prior knowledge that is hidden in students’ historical learning interactions. We conduct comprehensive experiments on three real-world educational datasets and compare the proposed approach to both deep sequential KT models and non-sequential models. Experimental results show that AT-DKT outperforms all sequential models with more than 0.9% improvements of AUC for all datasets, and is almost the second best compared to non-sequential models. Furthermore, we conduct both ablation studies and quantitative analysis to show the effectiveness of auxiliary tasks and the superior prediction outcomes of AT-DKT. To encourage reproducible research, we make our data and code publicly available at https://github.com/pykt-team/pykt-toolkit 2.","deep learning, auxiliary learning, student modeling, knowledge tracing, AI in education","","WWW '23"
"Conference Paper","Pandey S,Srivastava J","RKT: Relation-Aware Self-Attention for Knowledge Tracing","","2020","","","1205–1214","Association for Computing Machinery","New York, NY, USA","Proceedings of the 29th ACM International Conference on Information & Knowledge Management","Virtual Event, Ireland","2020","9781450368599","","https://doi.org/10.1145/3340531.3411994;http://dx.doi.org/10.1145/3340531.3411994","10.1145/3340531.3411994","The world has transitioned into a new phase of online learning in response to the recent Covid19 pandemic. Now more than ever, it has become paramount to push the limits of online learning in every manner to keep flourishing the education system. One crucial component of online learning is Knowledge Tracing (KT). The aim of KT is to model student's knowledge level based on their answers to a sequence of exercises referred as interactions. Students acquire their skills while solving exercises and each such interaction has a distinct impact on student ability to solve a future exercise. This impact is characterized by 1) the relation between exercises involved in the interactions and 2) student forget behavior. Traditional studies on knowledge tracing do not explicitly model both the components jointly to estimate the impact of these interactions. In this paper, we propose a novel Relation-aware self-attention model for Knowledge Tracing (RKT). We introduce a relation-aware self-attention layer that incorporates the contextual information. This contextual information integrates both the exercise relation information through their textual content as well as student performance data and the forget behavior information through modeling an exponentially decaying kernel function. Extensive experiments on three real-world datasets, among which two new collections are released to the public, show that our model outperforms state-of-the-art knowledge tracing methods. Furthermore, the interpretable attention weights help visualize the relation between interactions and temporal patterns in the human learning process.","relation-aware model, knowledge tracing, educational data mining, attention networks","","CIKM '20"
"Conference Paper","Zhang J,Shi X,King I,Yeung DY","Dynamic Key-Value Memory Networks for Knowledge Tracing","","2017","","","765–774","International World Wide Web Conferences Steering Committee","Republic and Canton of Geneva, CHE","Proceedings of the 26th International Conference on World Wide Web","Perth, Australia","2017","9781450349130","","https://doi.org/10.1145/3038912.3052580;http://dx.doi.org/10.1145/3038912.3052580","10.1145/3038912.3052580","Knowledge Tracing (KT) is a task of tracing evolving knowledge state of students with respect to one or more concepts as they engage in a sequence of learning activities. One important purpose of KT is to personalize the practice sequence to help students learn knowledge concepts efficiently. However, existing methods such as Bayesian Knowledge Tracing and Deep Knowledge Tracing either model knowledge state for each predefined concept separately or fail to pinpoint exactly which concepts a student is good at or unfamiliar with. To solve these problems, this work introduces a new model called Dynamic Key-Value Memory Networks (DKVMN) that can exploit the relationships between underlying concepts and directly output a student's mastery level of each concept. Unlike standard memory-augmented neural networks that facilitate a single memory matrix or two static memory matrices, our model has one static matrix called key, which stores the knowledge concepts and the other dynamic matrix called value, which stores and updates the mastery levels of corresponding concepts. Experiments show that our model consistently outperforms the state-of-the-art model in a range of KT datasets. Moreover, the DKVMN model can automatically discover underlying concepts of exercises typically performed by human annotations and depict the changing knowledge state of a student.","dynamic key-value memory networks, deep learning, massive open online courses, knowledge tracing","","WWW '17"
"Conference Paper","Sun J,Yu F,Liu S,Luo Y,Liang R,Shen X","Adversarial Bootstrapped Question Representation Learning for Knowledge Tracing","","2023","","","8016–8025","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st ACM International Conference on Multimedia","Ottawa ON, Canada","2023","","","https://doi.org/10.1145/3581783.3612044;http://dx.doi.org/10.1145/3581783.3612044","10.1145/3581783.3612044","Knowledge tracing (KT), which estimates and traces the degree of learners' mastery of concepts based on students' responses to learning resources, has become an increasingly relevant problem in intelligent education. The accuracy of predictions greatly depends on the quality of question representations. While contrastive learning has been commonly used to generate high-quality representations, the selection of positive and negative samples for knowledge tracing remains a challenge. To address this issue, we propose an adversarial bootstrapped question representation (ABQR) model, which can generate robust and high-quality question representations without requiring negative samples. Specifically, ABQR introduces the bootstrap self-supervised learning framework, which learns question representations from different views of the skill-informed question interaction graph and facilitates question representations between each view to predict one another, thereby circumventing the need for negative sample selection. Moreover, we propose a multi-objective multi-round feature adversarial graph augmentation method to obtain a higher-quality target view, while preserving the structural information of the original graph. ABQR is versatile and can be easily integrated with any base KT model as a plug-in to enhance the quality of question representation. Extensive experiments demonstrate that ABQR significantly improves the performance of the base KT model and outperforms state-of-the-art models. Ablation experiments confirm the effectiveness of each module of ABQR. The code is available at https://github.com/lilstrawberry/ABQR.","knowledge tracing, adversarial learning, question representation, contrastive learning","","MM '23"
"Conference Paper","Liu Z,Chen J,Luo W","Recent Advances on Deep Learning Based Knowledge Tracing","","2023","","","1295–1296","Association for Computing Machinery","New York, NY, USA","Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining","Singapore, Singapore","2023","9781450394079","","https://doi.org/10.1145/3539597.3575790;http://dx.doi.org/10.1145/3539597.3575790","10.1145/3539597.3575790","Knowledge tracing (KT) is the task of using students' historical learning interaction data to model their knowledge mastery over time so as to make predictions on their future interaction performance. Recently, remarkable progress has been made of using various deep learning techniques to solve the KT problem. However, the success behind deep learning based knowledge tracing (DLKT) approaches is still left somewhat unknown and proper measurement and analysis of these DLKT approaches remain a challenge.In this talk, we will comprehensively review recent developments of applying state-of-the-art deep learning approaches in KT problems, with a focus on those real-world educational data. Beyond introducing the recent advances of various DLKT models, we will discuss how to guarantee valid comparisons across DLKT methods via thorough evaluations on several publicly available datasets. More specifically, we will talk about (1) KT related psychometric theories; (2) the general DLKT modeling framework that covers recently developed DLKT approaches from different categories; (3) the general DLKT benchmark that allows existing approaches comparable on public KT datasets; (4) the broad application of algorithmic assessment and personalized feedback. Participants will learn about recent trends and emerging challenges in this topic, representative tools and learning resources to obtain ready-to-use models, and how related models and techniques benefit real-world KT applications.","knowledge tracing, psychometric theory, cognitive diagnosis, AI in education, deep learning","","WSDM '23"
"Conference Paper","Chen M,Guan Q,He Y,He Z,Fang L,Luo W","Knowledge Tracing Model with Learning and Forgetting Behavior","","2022","","","3863–3867","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st ACM International Conference on Information & Knowledge Management","Atlanta, GA, USA","2022","9781450392365","","https://doi.org/10.1145/3511808.3557622;http://dx.doi.org/10.1145/3511808.3557622","10.1145/3511808.3557622","The Knowledge Tracing (KT) task aims to trace the changes of students' knowledge state in real time according to students' historical learning behavior, and predict students' future learning performance. The modern KT models have two problems. One is that these KT models can't reflect students' actual knowledge level. Most KT models only judge students' knowledge state based on their performance in exercises, and poor performance will lead to a decline in knowledge state. However, the essence of students' learning process is the process of acquiring knowledge, which is also a manifestation of learning behavior. Even if they answer the exercises incorrectly, they will still gain knowledge. The other problem is that many KT models don't pay enough attention to the impact of students' forgetting behavior on the knowledge state in the learning process. In fact, learning and forgetting behavior run through students' learning process, and their effects on students' knowledge state shouldn't be ignored. In this paper, based on educational psychology theory, we propose a knowledge tracing model with learning and forgetting behavior (LFBKT). LFBKT comprehensively considers the factors that affect learning and forgetting behavior to build the knowledge acquisition layer, knowledge absorption layer and knowledge forgetting layer. In addition, LFBKT introduces difficulty information to enrich the information of the exercise itself, while taking into account other answering performances besides the answer. Experimental results on two public datasets show that LFBKT can better trace students' knowledge state and outperforms existing models in terms of ACC and AUC.","knowledge tracing, educational data mining, learning and forgetting","","CIKM '22"
"Conference Paper","Im Y,Choi E,Kook H,Lee J","Forgetting-Aware Linear Bias for Attentive Knowledge Tracing","","2023","","","3958–3962","Association for Computing Machinery","New York, NY, USA","Proceedings of the 32nd ACM International Conference on Information and Knowledge Management","Birmingham, United Kingdom","2023","","","https://doi.org/10.1145/3583780.3615191;http://dx.doi.org/10.1145/3583780.3615191","10.1145/3583780.3615191","Knowledge Tracing (KT) aims to track proficiency based on a question-solving history, allowing us to offer a streamlined curriculum. Recent studies actively utilize attention-based mechanisms to capture the correlation between questions and combine it with the learner's characteristics for responses. However, our empirical study shows that existing attention-based KT models neglect the learner's forgetting behavior, especially as the interaction history becomes longer. This problem arises from the bias that overprioritizes the correlation of questions while inadvertently ignoring the impact of forgetting behavior. This paper proposes a simple-yet-effective solution, namely Forgetting-aware Linear Bias (FoLiBi), to reflect forgetting behavior as a linear bias. Despite its simplicity, FoLiBi is readily equipped with existing attentive KT models by effectively decomposing question correlations with forgetting behavior. FoLiBi plugged with several KT models yields a consistent improvement of up to 2.58% in AUC over state-of-the-art KT models on four benchmark datasets.","forgetting behavior, attention mechanism, knowledge tracing","","CIKM '23"
"Conference Paper","Abdelrahman G,Wang Q","Knowledge Tracing with Sequential Key-Value Memory Networks","","2019","","","175–184","Association for Computing Machinery","New York, NY, USA","Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval","Paris, France","2019","9781450361729","","https://doi.org/10.1145/3331184.3331195;http://dx.doi.org/10.1145/3331184.3331195","10.1145/3331184.3331195","Can machines trace human knowledge like humans? Knowledge tracing (KT) is a fundamental task in a wide range of applications in education, such as massive open online courses (MOOCs), intelligent tutoring systems, educational games, and learning management systems. It models dynamics in a student's knowledge states in relation to different learning concepts through their interactions with learning activities. Recently, several attempts have been made to use deep learning models for tackling the KT problem. Although these deep learning models have shown promising results, they have limitations: either lack the ability to go deeper to trace how specific concepts in a knowledge state are mastered by a student, or fail to capture long-term dependencies in an exercise sequence. In this paper, we address these limitations by proposing a novel deep learning model for knowledge tracing, namely Sequential Key-Value Memory Networks (SKVMN). This model unifies the strengths of recurrent modelling capacity and memory capacity of the existing deep learning KT models for modelling student learning. We have extensively evaluated our proposed model on five benchmark datasets. The experimental results show that (1) SKVMN outperforms the state-of-the-art KT models on all datasets, (2) SKVMN can better discover the correlation between latent concepts and questions, and (3) SKVMN can trace the knowledge state of students dynamics, and a leverage sequential dependencies in an exercise sequence for improved predication accuracy.","deep learning, sequence modelling, knowledge tracing, key-value memory, memory networks","","SIGIR'19"
"Conference Paper","Shen S,Liu Q,Chen E,Huang Z,Huang W,Yin Y,Su Y,Wang S","Learning Process-Consistent Knowledge Tracing","","2021","","","1452–1460","Association for Computing Machinery","New York, NY, USA","Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining","Virtual Event, Singapore","2021","9781450383325","","https://doi.org/10.1145/3447548.3467237;http://dx.doi.org/10.1145/3447548.3467237","10.1145/3447548.3467237","Knowledge tracing (KT), which aims to trace students' changing knowledge state during their learning process, has improved students' learning efficiency in online learning systems. Recently, KT has attracted much research attention due to its critical significance in education. However, most of the existing KT methods pursue high accuracy of student performance prediction but neglect the consistency of students' changing knowledge state with their learning process. In this paper, we explore a new paradigm for the KT task and propose a novel model named Learning Process-consistent Knowledge Tracing (LPKT), which monitors students' knowledge state through directly modeling their learning process. Specifically, we first formalize the basic learning cell as the tuple exercise---answer time---answer. Then, we deeply measure the learning gain as well as its diversity from the difference of the present and previous learning cells, their interval time, and students' related knowledge state. We also design a learning gate to distinguish students' absorptive capacity of knowledge. Besides, we design a forgetting gate to model the decline of students' knowledge over time, which is based on their previous knowledge state, present learning gains, and the interval time. Extensive experimental results on three public datasets demonstrate that LPKT could obtain more reasonable knowledge state in line with the learning process. Moreover, LPKT also outperforms state-of-the-art KT methods on student performance prediction. Our work indicates a potential future research direction for KT, which is of both high interpretability and accuracy.","","","KDD '21"
"Conference Paper","Shen S,Liu Q,Chen E,Wu H,Huang Z,Zhao W,Su Y,Ma H,Wang S","Convolutional Knowledge Tracing: Modeling Individualization in Student Learning Process","","2020","","","1857–1860","Association for Computing Machinery","New York, NY, USA","Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","Virtual Event, China","2020","9781450380164","","https://doi.org/10.1145/3397271.3401288;http://dx.doi.org/10.1145/3397271.3401288","10.1145/3397271.3401288","With the development of online education systems, a growing number of research works are focusing on Knowledge Tracing (KT), which aims to assess students' changing knowledge state and help them learn knowledge concepts more efficiently. However, only given student learning interactions, most of existing KT methods neglect the individualization of students, i.e., the prior knowledge and learning rates differ from student to student. To this end, in this paper, we propose a novel Convolutional Knowledge Tracing (CKT) method to model individualization in KT. Specifically, for individualized prior knowledge, we measure it from students' historical learning interactions. For individualized learning rates, we design hierarchical convolutional layers to extract them based on continuous learning interactions of students. Extensive experiments demonstrate that CKT could obtain better knowledge tracing results through modeling individualization in learning process. Moreover, CKT can learn meaningful exercise embeddings automatically.","knowledge tracing, convolution neural networks, intelligent education, individualized learning","","SIGIR '20"
"Conference Paper","Ai L,Zhang X,Hu X","MPSKT: Multi-Head ProbSparse Self-Attention for Knowledge Tracing","","2022","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 6th International Conference on Computer Science and Application Engineering","Virtual Event, China","2022","9781450396004","","https://doi.org/10.1145/3565387.3565420;http://dx.doi.org/10.1145/3565387.3565420","10.1145/3565387.3565420","Over the past two years, COVID-19 has led to a widespread rise in online education, and knowledge tracing has been used on various educational platforms. However, most existing knowledge tracing models still suffer from long-term dependence. To address this problem, we propose a Multi-head ProbSparse Self-Attention for Knowledge Tracing(MPSKT). Firstly, the temporal convolutional network is used to encode the position information of the input sequence. Then, the Multi-head ProbSparse Self-Attention in the encoder and decoder blocks is used to capture the relationship between the input sequences, and the convolution and pooling layers in the encoder block are used to shorten the length of the input sequence, which greatly reduces the time complexity of the model and better solves the problem of long-term dependence of the model. Finally, experimental results on three public online education datasets demonstrate the effectiveness of our proposed model.","deep learning, knowledge tracing, temporal convolutional network, self-attention mechanism","","CSAE '22"
"Conference Paper","Zhao J,Bhatt S,Thille C,Gattani N,Zimmaro D","Cold Start Knowledge Tracing with Attentive Neural Turing Machine","","2020","","","333–336","Association for Computing Machinery","New York, NY, USA","Proceedings of the Seventh ACM Conference on Learning @ Scale","Virtual Event, USA","2020","9781450379519","","https://doi.org/10.1145/3386527.3406741;http://dx.doi.org/10.1145/3386527.3406741","10.1145/3386527.3406741","Deep learning based knowledge tracing approaches achieve high accuracy in mastery prediction with pattern extraction on a large learning behavior data set. However, when there is little training data available, these approaches either fail to extract the key patterns or result in over fitting. Ideally, we aim to provide a similar learning experience to both the first group of learners, who interact with a new course or a new activity with little learning behavior data to provide personalized guidance, and the learners who interact with the course later. We propose a novel architecture, Attentive Neural Turing Machine (ANTM), to solve the cold start knowledge tracing problem. The proposed ANTM comprises an attentive controller module and differential reading and writing processes with extra memory bank. Accuracy (ACC) and Area Under Curve (AUC) measures are used for model performance comparison. Results show the proposed approach can learn fast and generalize well to unseen data. It achieves around 95% ACC trained with only 3 learners, while conventional deep learning based approaches achieve only 65% ACC with over prediction issues.","neural turing machine, attention mechanism, knowledge tracing","","L@S '20"
"Conference Paper","Shi H,Yang Y,Chen Z,Fu P","Dynamic Multi-Skill Knowledge Tracing for Intelligent Educational System","","2023","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence","Sanya, China","2023","9781450398336","","https://doi.org/10.1145/3579654.3579740;http://dx.doi.org/10.1145/3579654.3579740","10.1145/3579654.3579740","Knowledge tracing (KT) is the task of tracing students’ evolving knowledge proficiency in learning interactions. In KT research, the modeling of exercise-student relations always plays a key role. How to construct the exercise and student representation is still a pending problem. To solve this problem, we propose a novel Dynamic Multi-skill Knowledge Tracing (DMKT) method in this paper. First, the Res-embedding layer is exploited to make the exercise representation more complete. Then, a new approach is proposed for simulating students’ learning process. Furthermore, a Learning Absorption Indicator (LAI) is designed to effectively model the student's knowledge mastery. To verify the performance of our method, we implement DMKT with several baselines on three real-world datasets. Experimental results demonstrate the superiority and effectiveness of the proposed method.","Res-embedding, Learning Absorption Indicator, Multi-skill, Knowledge Tracing","","ACAI '22"
"Conference Paper","Ding X,Larson EC","Automatic RNN Cell Design for Knowledge Tracing Using Reinforcement Learning","","2020","","","285–288","Association for Computing Machinery","New York, NY, USA","Proceedings of the Seventh ACM Conference on Learning @ Scale","Virtual Event, USA","2020","9781450379519","","https://doi.org/10.1145/3386527.3406729;http://dx.doi.org/10.1145/3386527.3406729","10.1145/3386527.3406729","Empirical results have shown that deep neural networks achieve superior performance in the application of Knowledge Tracing. However, the design of recurrent cells like long short term memory (LSTM) cells or gated recurrent units (GRU) is influenced largely by applications in natural language processing. They were proposed and evaluated in the context of sequence to sequence modeling, like machine translation. Even though the LSTM cell works well for knowledge tracing, it is unknown if its architecture is ideally suited for knowledge tracing. Despite the fact that there are several recurrent neural network based architectures proposed for knowledge tracing, the methodologies rely on empirical observations and trial and error, which may not be efficient or scalable. In this study, we investigate using reinforcement learning for the automatic design of recurrent neural network cells for knowledge tracing, showing improved performance compared to the LSTM cell. We also discuss a potential method for model regularization using neural architecture search.","reinforcement learning, knowledge tracing, neural architecture search, recurrent neural network, regularization","","L@S '20"
"Conference Paper","Kasurinen J,Nikula U","Estimating Programming Knowledge with Bayesian Knowledge Tracing","","2009","","","313–317","Association for Computing Machinery","New York, NY, USA","Proceedings of the 14th Annual ACM SIGCSE Conference on Innovation and Technology in Computer Science Education","Paris, France","2009","9781605583815","","https://doi.org/10.1145/1562877.1562972;http://dx.doi.org/10.1145/1562877.1562972","10.1145/1562877.1562972","In this paper we present a concept for three-phase measuring method, which can be used to obtain data on student learning. The focus of this method lies on the technical aspects of learning programming, answering questions like which programming constructs students applied and how large portion of the students understood the concepts of programming language.The model is based on three consecutive measurements, which are used to observe the student errors, applied programming structures and an application of a Bayesian learning model to determine the programming knowledge. So far the model has produced results which confirm prior knowledge on student learning, indicating that the concept is feasible for further development. Despite of the early development phase of the method, it offers a straightforward way for teacher to assess the course contents and student performance.","error analysis, knowledge tracing, programming knowledge","","ITiCSE '09"
"Journal Article","Kasurinen J,Nikula U","Estimating Programming Knowledge with Bayesian Knowledge Tracing","SIGCSE Bull.","2009","41","3","313–317","Association for Computing Machinery","New York, NY, USA","","","2009-07","","0097-8418","https://doi.org/10.1145/1595496.1562972;http://dx.doi.org/10.1145/1595496.1562972","10.1145/1595496.1562972","In this paper we present a concept for three-phase measuring method, which can be used to obtain data on student learning. The focus of this method lies on the technical aspects of learning programming, answering questions like which programming constructs students applied and how large portion of the students understood the concepts of programming language.The model is based on three consecutive measurements, which are used to observe the student errors, applied programming structures and an application of a Bayesian learning model to determine the programming knowledge. So far the model has produced results which confirm prior knowledge on student learning, indicating that the concept is feasible for further development. Despite of the early development phase of the method, it offers a straightforward way for teacher to assess the course contents and student performance.","knowledge tracing, error analysis, programming knowledge","",""
"Conference Paper","Doroudi S,Brunskill E","Fairer but Not Fair Enough On the Equitability of Knowledge Tracing","","2019","","","335–339","Association for Computing Machinery","New York, NY, USA","Proceedings of the 9th International Conference on Learning Analytics & Knowledge","Tempe, AZ, USA","2019","9781450362566","","https://doi.org/10.1145/3303772.3303838;http://dx.doi.org/10.1145/3303772.3303838","10.1145/3303772.3303838","Adaptive educational technologies have the capacity to meet the needs of individual students in theory, but in some cases, the degree of personalization might be less than desired, which could lead to inequitable outcomes for students. In this paper, we use simulations to demonstrate that while knowledge tracing algorithms are substantially more equitable than giving all students the same amount of practice, such algorithms can still be inequitable when they rely on inaccurate models. This can arise as a result of two factors: (1) using student models that are fit to aggregate populations of students, and (2) using student models that make incorrect assumptions about student learning. In particular, we demonstrate that both the Bayesian knowledge tracing algorithm and the N-Consecutive Correct Responses heuristic are susceptible to these concerns, but that knowledge tracing with the additive factor model may be more equitable. The broader message of this paper is that when designing learning analytics algorithms, we need to explicitly consider whether the algorithms act fairly with respect to different populations of students, and if not, how we can make our algorithms more equitable.","fairness, equity, model misspecification, knowledge tracing","","LAK19"
"Conference Paper","Lee J,Yeung DY","Knowledge Query Network for Knowledge Tracing: How Knowledge Interacts with Skills","","2019","","","491–500","Association for Computing Machinery","New York, NY, USA","Proceedings of the 9th International Conference on Learning Analytics & Knowledge","Tempe, AZ, USA","2019","9781450362566","","https://doi.org/10.1145/3303772.3303786;http://dx.doi.org/10.1145/3303772.3303786","10.1145/3303772.3303786","Knowledge Tracing (KT) is to trace the knowledge of students as they solve a sequence of problems represented by their related skills. This involves abstract concepts of students' states of knowledge and the interactions between those states and skills. Therefore, a KT model is designed to predict whether students will give correct answers and to describe such abstract concepts. However, existing methods either give relatively low prediction accuracy or fail to explain those concepts intuitively. In this paper, we propose a new model called Knowledge Query Network (KQN) to solve these problems. KQN uses neural networks to encode student learning activities into knowledge state and skill vectors, and models the interactions between the two types of vectors with the dot product. Through this, we introduce a novel concept called probabilistic skill similarity that relates the pairwise cosine and Euclidean distances between skill vectors to the odds ratios of the corresponding skills, which makes KQN interpretable and intuitive.On four public datasets, we have carried out experiments to show the following: 1. KQN outperforms all the existing KT models based on prediction accuracy. 2. The interaction between the knowledge state and skills can be visualized for interpretation. 3. Based on probabilistic skill similarity, a skill domain can be analyzed with clustering using the distances between the skill vectors of KQN. 4. For different values of the vector space dimensionality, KQN consistently exhibits high prediction accuracy and a strong positive correlation between the distance matrices of the skill vectors.","Massive Open Online Courses, Domain Modeling, Learner Modeling, Deep Learning, Learning Analytics, Knowledge Tracing, Knowledge Modeling, Intelligent Tutoring Systems, Educational Data Mining","","LAK19"
"Conference Paper","Tong H,Wang Z,Zhou Y,Tong S,Han W,Liu Q","Introducing Problem Schema with Hierarchical Exercise Graph for Knowledge Tracing","","2022","","","405–415","Association for Computing Machinery","New York, NY, USA","Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval","Madrid, Spain","2022","9781450387323","","https://doi.org/10.1145/3477495.3532004;http://dx.doi.org/10.1145/3477495.3532004","10.1145/3477495.3532004","Knowledge tracing (KT) which aims at predicting learner's knowledge mastery plays an important role in the computer-aided educational system. The goal of KT is to provide personalized learning paths for learners by diagnosing the mastery of each knowledge, thus improving the learning efficiency. In recent years, many deep learning models have been applied to tackle the KT task, which has shown promising results. However, most existing methods simplify the exercising records as knowledge sequences, which fail to explore the rich information that existed in exercises. Besides, the existing diagnosis results of knowledge tracing are not convincing enough since they neglect hierarchical relations between exercises. To solve the above problems, we propose a hierarchical graph knowledge tracing model called HGKT to explore the latent complex relations between exercises. Specifically, we introduce the concept of problem schema to construct a hierarchical exercise graph that could model the exercise learning dependencies. Moreover, we employ two attention mechanisms to highlight important historical states of learners. In the testing stage, we present a knowledge&schema diagnosis matrix that could trace the transition of mastery of knowledge and problem schema, which can be more easily applied to different applications. Extensive experiments show the effectiveness and interpretability of our proposed model.","attention mechanism, intelligent education, hierarchical graph convolutional network, knowledge tracing","","SIGIR '22"
"Conference Paper","Choi Y,Lee Y,Cho J,Baek J,Kim B,Cha Y,Shin D,Bae C,Heo J","Towards an Appropriate Query, Key, and Value Computation for Knowledge Tracing","","2020","","","341–344","Association for Computing Machinery","New York, NY, USA","Proceedings of the Seventh ACM Conference on Learning @ Scale","Virtual Event, USA","2020","9781450379519","","https://doi.org/10.1145/3386527.3405945;http://dx.doi.org/10.1145/3386527.3405945","10.1145/3386527.3405945","In this paper, we propose a novel Transformer-based model for knowledge tracing, SAINT: Separated Self-AttentIve Neural Knowledge Tracing. SAINT has an encoder-decoder structure where the exercise and response embedding sequences separately enter, respectively, the encoder and the decoder. The encoder applies self-attention layers to the sequence of exercise embeddings, and the decoder alternately applies self-attention layers and encoder-decoder attention layers to the sequence of response embeddings. This separation of input allows us to stack attention layers multiple times, resulting in an improvement in area under receiver operating characteristic curve (AUC). To the best of our knowledge, this is the first work to suggest an encoder-decoder model for knowledge tracing that applies deep self-attentive layers to exercises and responses separately. We empirically evaluate SAINT on a large-scale knowledge tracing dataset, EdNet, collected by an active mobile education application, Santa, which has 627,347 users, 72,907,005 response data points as well as a set of 16,175 exercises gathered since 2016. The results show that SAINT achieves state-of-the-art performance in knowledge tracing with an improvement of 1.8% in AUC compared to the current state-of-the-art model.","knowledge tracing, personalized learning, transformer, deep learning, education","","L@S '20"
"Conference Paper","Wang C,Sahebi S","Continuous Personalized Knowledge Tracing: Modeling Long-Term Learning in Online Environments","","2023","","","2616–2625","Association for Computing Machinery","New York, NY, USA","Proceedings of the 32nd ACM International Conference on Information and Knowledge Management","Birmingham, United Kingdom","2023","","","https://doi.org/10.1145/3583780.3614822;http://dx.doi.org/10.1145/3583780.3614822","10.1145/3583780.3614822","With the advance of online education systems, accessibility to learning materials has increased. In these systems, students can practice independently and learn from different learning materials over long periods of time. As a result, it is essential to trace students' knowledge states over long learning sequences while maintaining a personalized model of each individual student's progress. However, the existing deep learning-based knowledge tracing models are either not personalized or not tailored for handling long sequences. Handling long sequences are especially essential in the online education environments, in where models are preferred to be updated with the newly collected user data in a timely manner as students could acquire knowledge on each learning activity. In this paper, we propose a knowledge tracing model, Continuous Personalized Knowledge Tracing (CPKT), that can mimic the real-world long-term continuous learning scenario by incorporating a novel online model training paradigm that is suitable for the knowledge tracing problem. To achieve personalized knowledge tracing, we propose two model components: 1) personalized memory slots to maintain learner's knowledge in a lifelong manner, and 2) personalized user embeddings that help to accurately predict the individual responses, correctly detect the personalized knowledge acquisition and forgetting patterns, and better interpret and analyze the learner's progress. Additionally, we propose transition-aware stochastic shared embedding according to the learning transition matrix to regularize the online model training. Extensive experiments on four real-world datasets showcase the effectiveness and superiority of CPKT, especially for students with longer sequences.","personalization, knowledge tracing, intelligent education, online learning, learner modeling","","CIKM '23"
"Conference Paper","Wang Z,Zhu J,Li X,Hu Z,Zhang M","Structured Knowledge Tracing Models for Student Assessment on Coursera","","2016","","","209–212","Association for Computing Machinery","New York, NY, USA","Proceedings of the Third (2016) ACM Conference on Learning @ Scale","Edinburgh, Scotland, UK","2016","9781450337267","","https://doi.org/10.1145/2876034.2893416;http://dx.doi.org/10.1145/2876034.2893416","10.1145/2876034.2893416","Massive Open Online Courses (MOOCs) provide an effective learning platform with various high-quality educational materials accessible to learners from all over the world. However, current MOOCs lack personalized learning guidance and intelligent assessment for individuals. Though a few recent attempts have been made to trace students' knowledge states by adapting the popular Bayesian Knowledge Tracing (BKT) model, they have largely ignored the rich structures and correlations among knowledge components (KCs) within a course. This paper proposes to model both the hierarchical and the temporal properties of the knowledge states in order to improve the modeling accuracy. Based on the content organization characteristics on the Coursera MOOC platform, we provide a well-defined KC model, and develop Multi-Grained-BKT and Historical-BKT to capture the above features effectively. Experiments on a Coursera course dataset show our approach significantly improves over previous vanilla BKT models on predicting students' quiz performance.","student modeling, knowledge tracing, student assessment, hierarchical and temporal, moocs","","L@S '16"
"Conference Paper","Nakagawa H,Iwasawa Y,Matsuo Y","Graph-Based Knowledge Tracing: Modeling Student Proficiency Using Graph Neural Network","","2019","","","156–163","Association for Computing Machinery","New York, NY, USA","IEEE/WIC/ACM International Conference on Web Intelligence","Thessaloniki, Greece","2019","9781450369343","","https://doi.org/10.1145/3350546.3352513;http://dx.doi.org/10.1145/3350546.3352513","10.1145/3350546.3352513","Recent advancements in computer-assisted learning systems have caused an increase in the research of knowledge tracing, wherein student performance on coursework exercises is predicted over time. From the viewpoint of data structure, the coursework can be potentially structured as a graph. Incorporating this graph-structured nature into the knowledge tracing model as a relational inductive bias can improve its performance; however, previous methods, such as deep knowledge tracing, did not consider such a latent graph structure. Inspired by the recent successes of the graph neural network (GNN), we herein propose a GNN-based knowledge tracing method, i.e., graph-based knowledge tracing. Casting the knowledge structure as a graph enabled us to reformulate the knowledge tracing task as a time-series node-level classification problem in the GNN. As the knowledge graph structure is not explicitly provided in most cases, we propose various implementations of the graph structure. Empirical validations on two open datasets indicated that our method could potentially improve the prediction of student performance and demonstrated more interpretable predictions compared to those of the previous methods, without the requirement of any additional information.","Learning sciences, Knowledge tracing, Graph neural network, Educational data mining","","WI '19"
"Journal Article","Cui J,Chen Z,Zhou A,Wang J,Zhang W","Fine-Grained Interaction Modeling with Multi-Relational Transformer for Knowledge Tracing","ACM Trans. Inf. Syst.","2023","41","4","","Association for Computing Machinery","New York, NY, USA","","","2023-03","","1046-8188","https://doi.org/10.1145/3580595;http://dx.doi.org/10.1145/3580595","10.1145/3580595","Knowledge tracing, the goal of which is predicting students’ future performance given their past question response sequences to trace their knowledge states, is pivotal for computer-aided education and intelligent tutoring systems. Although many technical efforts have been devoted to modeling students based on their question-response sequences, fine-grained interaction modeling between question-response pairs within each sequence is underexplored. This causes question-response representations less contextualized and further limits student modeling. To address this issue, we first conduct a data analysis and reveal the existence of complex cross effects between different question-response pairs within a sequence. Consequently, we propose MRT-KT, a multi-relational transformer for knowledge tracing, to enable fine-grained interaction modeling between question-response pairs. It introduces a novel relation encoding scheme based on knowledge concepts and student performance. Comprehensive experimental results show that MRT-KT outperforms state-of-the-art knowledge tracing methods on four widely-used datasets, validating the effectiveness of considering fine-grained interaction for knowledge tracing.","user behavior modeling, Knowledge tracing, multi-relational transformer","",""
"Conference Paper","Huang S,Liu Z,Zhao X,Luo W,Weng J","Towards Robust Knowledge Tracing Models via K-Sparse Attention","","2023","","","2441–2445","Association for Computing Machinery","New York, NY, USA","Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval","Taipei, Taiwan","2023","9781450394086","","https://doi.org/10.1145/3539618.3592073;http://dx.doi.org/10.1145/3539618.3592073","10.1145/3539618.3592073","Knowledge tracing (KT) is the problem of predicting students' future performance based on their historical interaction sequences. With the advanced capability of capturing contextual long-term dependency, attention mechanism becomes one of the essential components in many deep learning based KT (DLKT) models. In spite of the impressive performance achieved by these attentional DLKT models, many of them are often vulnerable to run the risk of overfitting, especially on small-scale educational datasets. Therefore, in this paper, we propose sparseKT, a simple yet effective framework to improve the robustness and generalization of the attention based DLKT approaches. Specifically, we incorporate a k-selection module to only pick items with the highest attention scores. We propose two sparsification heuristics: (1) soft-thresholding sparse attention and (2) top-K sparse attention. We show that our sparseKT is able to help attentional KT models get rid of irrelevant student interactions and improve the predictive performance when compared to 11 state-of-the-art KT models on three publicly available real-world educational datasets. To encourage reproducible research, we make our data and code publicly available at https://github.com/pykt-team/pykt-toolkit1..","ai in education, sparse attention, knowledge tracing, student modeling, deep learning","","SIGIR '23"
"Conference Paper","Huang Y","Deeper Knowledge Tracing by Modeling Skill Application Context for Better Personalized Learning","","2016","","","325–328","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization","Halifax, Nova Scotia, Canada","2016","9781450343688","","https://doi.org/10.1145/2930238.2930373;http://dx.doi.org/10.1145/2930238.2930373","10.1145/2930238.2930373","Traditional Knowledge Tracing, which traces students' knowledge of each decomposed individual skill, has been a popular learner model for adaptive tutoring. Typically, a student is guided to the next skill when the student's knowledge on current skill is inferred as mastery. Unfortunately, this traditional approach no longer suffices to model complex skill practices where simple decompositions can not capture potential additional skills underlying the context as a whole. In such cases, mastery should only be granted when a student not only understands the basic of a skill but also can fluently apply a skill in varied application contexts. In this thesis, we aim to propose a data-driven approach to construct learner models considering different skill application contexts for tracing deeper knowledge, primarily based on Bayesian Networks. We aim to conduct novel, comprehensive, ``deep"" evaluations, including internal data-drive evaluations, and external end-user evaluations examining the real world impact for students' personalized learning.","deep learning, bayesian network, complex skill, multiple skills, knowledge tracing","","UMAP '16"
"Conference Paper","Al-Jadaa AA,Abu-Issa AS,Ghanem WT,Hussein MS","Enhancing the Intelligence of Web Tutoring Systems Using a Multi-Entry Based Open Learner Model","","2017","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing","Cambridge, United Kingdom","2017","9781450347747","","https://doi.org/10.1145/3018896.3036389;http://dx.doi.org/10.1145/3018896.3036389","10.1145/3018896.3036389","The accuracy of learner model is the heart of any Intelligent Tutoring System (ITS). More intelligence in the ITS needs a more accurate learner model. In the earlier versions of ITS, the student must submit a test before using the ITS. That test was used to build the student model, which contains information about the knowledge of the student, his/her misconceptions, preferences and other related issues. However, this method doesn't work efficiently for school students, because one test canfit accurately evaluate their knowledge and misconceptions. In this research, we implement a system (web application) to get the student model for school students by allowing the students, parents, and instructors to add their assessment and feedback to the model. Then the system uses these multi-entries together with the traditional test to build an enhanced student model (smart learner model). Furthermore, in order to support collaborative learning, the implemented system gives the student the access to open his/her model for other instructors and peers. The proposed system has been applied on a group of students, their parents and instructors. According to the obtained results and the surveys, the studentfis knowledge has been improved in many students. also the students, parents, instructors found the system to be useful, interesting and easy to use. Furthermore, all parties were happy to be engaged in the educational process.","web application, student model, open learner model, intelligent tutoring system","","ICC '17"
"Conference Paper","Zhu M,Han S,Yuan P,Lu X","Enhancing Programming Knowledge Tracing by Interacting Programming Skills and Student Code","","2022","","","438–443","Association for Computing Machinery","New York, NY, USA","LAK22: 12th International Learning Analytics and Knowledge Conference","Online, USA","2022","9781450395731","","https://doi.org/10.1145/3506860.3506870;http://dx.doi.org/10.1145/3506860.3506870","10.1145/3506860.3506870","Programming education has received extensive attention in recent years due to the increasing demand for programming ability in almost all industries. Educational institutions have widely employed online judges for programming training, which can help teachers automatically assess programming assignments by executing students’ code with test cases. However, a more important teaching process with online judges should be to evaluate how students master each of the programming skills such as strings or pointers, so that teachers may give personalized feedback and help them proceed to the success more efficiently. Previous studies have adopted deep models of knowledge tracing to evaluate a student’s mastery level of skills during the interaction with programming exercises. However, existing models generally follow the conventional assumption of knowledge tracing that each programming exercise requires only one skill, whereas in practice a programming exercise usually inspects the comprehensive use of multiple skills. Moreover, the feature of student code is often simply concatenated with other input features without the consideration of its relationship with the inspected programming skills. To bridge the gap, we propose a simple attention-based approach to learn from student code the features reflecting the multiple programming skills inspected by each programming exercise. In particular, we first use a program embedding method to obtain the representations of student code. Then we use the skill embeddings of each programming exercise to query the embeddings of student code and form an aggregated hidden state representing how the inspected skills are used in the student code. We combine the learned hidden state with DKT (Deep Knowledge Tracing), an LSTM (Long Short-Term Memory)-based knowledge tracing model, and show the improvements over baseline model. We point out some possible directions to improve the current work.","programming education, code representation, intelligent education, knowledge tracing, attention mechanism","","LAK22"
"Conference Paper","Zhang Z,Li H","BSLKT: A Bagging Model with Self-Attention and LightGBM for Knowledge Tracing","","2021","","","126–130","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM Turing Award Celebration Conference - China","Hefei, China","2021","9781450385671","","https://doi.org/10.1145/3472634.3472664;http://dx.doi.org/10.1145/3472634.3472664","10.1145/3472634.3472664","Knowledge tracing(KT) is a hot topic in computer-supported education. It’s a task that can model a sequences of learning activities that students engage with, so as to trace the students’ continuously developing state of knowledge. One important purpose of knowledge tracing is that it can evaluate students’ mastery of knowledge concepts(KCs) according to their performance in learning activities, in order to customize personalized learning plans for students to help them get better learning plans. In recent years, many knowledge tracing methods have been proposed, which can be divided into Recurrent Neural Networks(RNN) based methods and self-attention based methods. Methods based on RNN include Deep Knowledge Tracing(DKT), Dynamic Key-Value Memory Network(DKVMN), etc. These RNN methods have better performance than traditional knowledge tracing methods. However, they are not suitable for dealing with sparse data, that is, situations where students interact with few KCs. The Self-Attention model for Knowledge Tracing(SAKT) uses the self-attention mechanism, which can identify the KCs from the learning activities that students participated in and are related to a given KC, so as to predict the mastery of the given KC. Therefore, SAKT can deal with the sparse data problem that the RNN methods are not suitable for processing. LightGBM is a gradient boosting framework that uses a tree based learning algorithm and is one of the current mainstream machine learning algorithms. In order to make the prediction more accurate, we propose the BSLKT model, which fuses the SAKT model and the LightGBM model in bagging manner. In addition, we performed feature engineering preprocessing on the experiment dataset. The experiment compared the accuracy of SAKT model, LightGBM model and the BSLKT model and the results show that BSLKT can achieve better prediction performance.","Knowledge Tracing, Self-Attention, Massive Open Online Courses","","ACM TURC '21"
"Conference Paper","Yeung CK,Yeung DY","Addressing Two Problems in Deep Knowledge Tracing via Prediction-Consistent Regularization","","2018","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fifth Annual ACM Conference on Learning at Scale","London, United Kingdom","2018","9781450358866","","https://doi.org/10.1145/3231644.3231647;http://dx.doi.org/10.1145/3231644.3231647","10.1145/3231644.3231647","Knowledge tracing is one of the key research areas for empowering personalized education. It is a task to model students' mastery level of a knowledge component (KC) based on their historical learning trajectories. In recent years, a recurrent neural network model called deep knowledge tracing (DKT) has been proposed to handle the knowledge tracing task and literature has shown that DKT generally outperforms traditional methods. However, through our extensive experimentation, we have noticed two major problems in the DKT model. The first problem is that the model fails to reconstruct the observed input. As a result, even when a student performs well on a KC, the prediction of that KC's mastery level decreases instead, and vice versa. Second, the predicted performance for KCs across time-steps is not consistent. This is undesirable and unreasonable because student's performance is expected to transit gradually over time. To address these problems, we introduce regularization terms that correspond to reconstruction and waviness to the loss function of the original DKT model to enhance the consistency in prediction. Experiments show that the regularized loss function effectively alleviates the two problems without degrading the original task of DKT.1","sequence modeling, regularization, deep learning, personalized learning, knowledge tracing, educational data mining","","L@S '18"
"Conference Paper","Chan WL,Yeung DY","Clickstream Knowledge Tracing: Modeling How Students Answer Interactive Online Questions","","2021","","","99–109","Association for Computing Machinery","New York, NY, USA","LAK21: 11th International Learning Analytics and Knowledge Conference","Irvine, CA, USA","2021","9781450389358","","https://doi.org/10.1145/3448139.3448149;http://dx.doi.org/10.1145/3448139.3448149","10.1145/3448139.3448149","Knowledge tracing (KT) is a research topic which seeks to model the knowledge acquisition process of students by analyzing their past performance in answering questions, based on which their performance in answering future questions is predicted. However, existing KT models only consider whether a student answers a question correctly when the answer is submitted but not the in-question activities. We argue that the interaction involved in the in-question activities can at least partially reveal the thinking process of the student, and hopefully even the competence of acquiring or understanding each piece of the knowledge required for the question. Based on real student interaction clickstream data collected from an online learning platform on which students solve mathematics problems, we conduct clustering analysis for each question to show that clickstreams can reflect different student behaviors. We then propose the first clickstream-based KT model, dubbed clickstream knowledge tracing (CKT), which augments a basic KT model by modeling the clickstream activities of students when answering questions. We apply different variants of CKT and compare them with the baseline KT model which does not use clickstream data. Despite the limited number of questions with clickstream data and its noisy nature which may compromise the data quality, we show that incorporating clickstream data leads to performance improvement. Through this pilot study, we hope to open a new direction in KT research to analyze finer-grained interaction data of students on online learning platforms.","Clickstream Analytics, Knowledge Tracing, Student Behavior Clustering, Knowledge Modeling, Learning Analytics, Learner Modeling, Interactive Questions","","LAK21"
"Conference Paper","Zhang W,Qu K,Han Y,Tan L","A Novel Knowledge Tracing Model Based on Collaborative Multi-Head Attention","","2022","","","210–215","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2022 6th International Conference on Innovation in Artificial Intelligence","Guangzhou, China","2022","9781450395502","","https://doi.org/10.1145/3529466.3529477;http://dx.doi.org/10.1145/3529466.3529477","10.1145/3529466.3529477","Online education is playing a more and more important role in today's education. The key link of online education is to model students' knowledge mastery according to their historical behaviors, so as to obtain the knowledge tracing represented by students' current knowledge state. Previous Transformer-based knowledge tracing models have disadvantages such as inefficient model computation and redundant information on the one hand. On the other hand, the traditional knowledge tracing model cannot solve the problem of imbalanced positive and negative samples in the data well. In order to better model the current knowledge state of students, this paper proposes a knowledge tracing model based on the collaborative multi-head attention mechanism. The model uses a collaborative multi-head attention mechanism to solve the information redundancy problem in the previous Transformer-based knowledge tracing model, and improves the computational efficiency and performance of the model. The model also introduces a focal loss function, which not only solves the problem of imbalanced question labeling divisions in knowledge tracing but also improves the differentiation of difficulty level among the questions and enhances the accuracy of model prediction. The experimental results on three public experimental datasets show that the knowledge tracing model based on the collaborative multi-head attention mechanism proposed in this paper outperforms other recent knowledge tracing models in terms of evaluation metric AUC and also has better performance in predicting students' responses.","Loss function, Collaborative multi-head attention, Key words: Knowledge Tracing, Deep learning","","ICIAI '22"
"Conference Paper","Labra C,Santos OC","Exploring Cognitive Models to Augment Explainability in Deep Knowledge Tracing","","2023","","","220–223","Association for Computing Machinery","New York, NY, USA","Adjunct Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization","Limassol, Cyprus","2023","9781450398916","","https://doi.org/10.1145/3563359.3597384;http://dx.doi.org/10.1145/3563359.3597384","10.1145/3563359.3597384","Adaptive learning systems allow a personalized adaptation based on the characteristics of the student. Tracing the progress of knowledge and skills during the learning process through cognitive models is essential so that these systems can make appropriate decisions when carrying out personalization. This is the objective of Knowledge Tracing, which studies how to infer a cognitive model from the answers given to a sequence of questions or exercises. The incorporation of Deep Learning techniques in this field has given rise to Deep Knowledge Tracing (DKT) which usually has excellent predictive outcomes. The problem is that this increase in accuracy comes with a lack of explainability since Deep Learning models can be considered black boxes from which it is difficult to build interpretations or explanations. By contrast, traditional Knowledge Tracing methods are based on underlying learning models and provide a solid basis for explainability. In this paper we describe an ongoing research to build DKT models with a good trade-off between accuracy and explainability. To this end, we propose to use a loss function based on a mixup approach where the ground truth is a mix between the dataset labels and the predictions of a surrogate explainable model. The approach has potential to improve, not only explainability through the use of the surrogate, but also accuracy thanks to regularization effects. We will validate the approach by exploring, for different cognitive models, the trade-off curve that is obtained by plotting accuracy against explainability for different mixup values.","cognitive models, personalized learning systems, deep knowledge tracing (DKT), explainability, scrutable user models","","UMAP '23 Adjunct"
"Conference Paper","Wang C,Sahebi S,Zhao S,Brusilovsky P,Moraes LO","Knowledge Tracing for Complex Problem Solving: Granular Rank-Based Tensor Factorization","","2021","","","179–188","Association for Computing Machinery","New York, NY, USA","Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization","Utrecht, Netherlands","2021","9781450383660","","https://doi.org/10.1145/3450613.3456831;http://dx.doi.org/10.1145/3450613.3456831","10.1145/3450613.3456831","Knowledge Tracing (KT), which aims to model student knowledge level and predict their performance, is one of the most important applications of user modeling. Modern KT approaches model and maintain an up-to-date state of student knowledge over a set of course concepts according to students’ historical performance in attempting the problems. However, KT approaches were designed to model knowledge by observing relatively small problem-solving steps in Intelligent Tutoring Systems. While these approaches were applied successfully to model student knowledge by observing student solutions for simple problems, such as multiple-choice questions, they do not perform well for modeling complex problem solving in students. Most importantly, current models assume that all problem attempts are equally valuable in quantifying current student knowledge. However, for complex problems that involve many concepts at the same time, this assumption is deficient. It results in inaccurate knowledge states and unnecessary fluctuations in estimated student knowledge, especially if students guess the correct answer to a problem that they have not mastered all of its concepts or slip in answering the problem that they have already mastered all of its concepts. In this paper, we argue that not all attempts are equivalently important in discovering students’ knowledge state, and some attempts can be summarized together to better represent student performance. We propose a novel student knowledge tracing approach, Granular RAnk based TEnsor factorization (GRATE), that dynamically selects student attempts that can be aggregated while predicting students’ performance in problems and discovering the concepts presented in them. Our experiments on three real-world datasets demonstrate the improved performance of GRATE, compared to the state-of-the-art baselines, in the task of student performance prediction. Our further analysis shows that attempt aggregation eliminates the unnecessary fluctuations from students’ discovered knowledge states and helps in discovering complex latent concepts in the problems.","knowledge tracing, aggregation, tensor factorization, complex problem solving","","UMAP '21"
"Conference Paper","Yin Y,Dai L,Huang Z,Shen S,Wang F,Liu Q,Chen E,Li X","Tracing Knowledge Instead of Patterns: Stable Knowledge Tracing with Diagnostic Transformer","","2023","","","855–864","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM Web Conference 2023","Austin, TX, USA","2023","9781450394161","","https://doi.org/10.1145/3543507.3583255;http://dx.doi.org/10.1145/3543507.3583255","10.1145/3543507.3583255","Knowledge Tracing (KT) aims at tracing the evolution of the knowledge states along the learning process of a learner. It has become a crucial task for online learning systems to model the learning process of their users, and further provide their users a personalized learning guidance. However, recent developments in KT based on deep neural networks mostly focus on increasing the accuracy of predicting the next performance of students. We argue that current KT modeling, as well as training paradigm, can lead to models tracing patterns of learner’s learning activities, instead of their evolving knowledge states. In this paper, we propose a new architecture, Diagnostic Transformer (DTransformer), along with a new training paradigm, to tackle this challenge. With DTransformer, we build the architecture from question-level to knowledge-level, explicitly diagnosing learner’s knowledge proficiency from each question mastery states. We also propose a novel training algorithm based on contrastive learning that focuses on maintaining the stability of the knowledge state diagnosis. Through extensive experiments, we will show that with its understanding of knowledge state evolution, DTransformer achieves a better performance prediction accuracy and more stable knowledge state tracing results. We will also show that DTransformer is less sensitive to specific patterns with case study. We open-sourced our code and data at https://github.com/yxonic/DTransformer.","DTransformer, contrastive learning, knowledge tracing","","WWW '23"
"Conference Paper","Mongkhonvanit K,Kanopka K,Lang D","Deep Knowledge Tracing and Engagement with MOOCs","","2019","","","340–342","Association for Computing Machinery","New York, NY, USA","Proceedings of the 9th International Conference on Learning Analytics & Knowledge","Tempe, AZ, USA","2019","9781450362566","","https://doi.org/10.1145/3303772.3303830;http://dx.doi.org/10.1145/3303772.3303830","10.1145/3303772.3303830","MOOCs and online courses have notoriously high attrition [1]. One challenge is that it can be difficult to tell if students fail to complete because of disinterest or because of course difficulty. Utilizing a Deep Knowledge Tracing framework, we account for student engagement by including course interaction covariates. With these, we find that we can predict a student's next item response with over 88% accuracy. Using these predictions, targeted interventions can be offered to students and targeted improvements can be made to courses. In particular, this approach would allow for gating of content until a student has reasonable likelihood of succeeding.","neural networks, MOOCS, video interactions, item response","","LAK19"
"Conference Paper","Kim DE,Hong C,Kim WH","Efficient Transformer-Based Knowledge Tracing for a Personalized Language Education Application","","2023","","","336–340","Association for Computing Machinery","New York, NY, USA","Proceedings of the Tenth ACM Conference on Learning @ Scale","Copenhagen, Denmark","2023","","","https://doi.org/10.1145/3573051.3596183;http://dx.doi.org/10.1145/3573051.3596183","10.1145/3573051.3596183","The purpose of this paper is to propose a new deep learning-based approach to recommend highly personalized educational contents to learners. Towards this goal, we present a knowledge tracing algorithm by adding long short-term memory units to a Transformer-based model. By inferring the knowledge state of a learner through the proposed KT algorithm, it not only removes problems that the learner does not have to solve but also suggest problems so that the learner's knowledge state level improves most efficiently. In this manner, a personalized educational curriculum can be provided to each learner. We trained the model with 90 million datasets collected from a Hangeul (i.e., Korean character) learning mobile application called ""Sojung-Hangeul"", one of the market-leading Korean learning services. The experimental results show that the AUC of the proposed model significantly improves from 0.88 to 0.92 compared to the recent Transformer-based approach in real-time environments. The proposed deep learning model is applied into ""Sojung-Hangeul"", and the application is currently available at https://bit.ly/Sojung-Hangeul.","recommendation system, transformer, personalized education, knowledge tracing","","L@S '23"
"Conference Paper","Schulz S,Lingnau A","An Evidence-Based Learner Model for Supporting Activities in Robotics","","2020","","","397–400","Association for Computing Machinery","New York, NY, USA","Proceedings of the Seventh ACM Conference on Learning @ Scale","Virtual Event, USA","2020","9781450379519","","https://doi.org/10.1145/3386527.3406760;http://dx.doi.org/10.1145/3386527.3406760","10.1145/3386527.3406760","Teaching robotics is an attractive way of motivating students to learn computer science. However, it is also a challenging topic for students of all ages and only one teacher in a classroom is too little to support approximately 30 students at the same time. Therefore, intelligent tutoring systems might be a meaningful way to support students and teachers. In this paper we describe an approach to support computer science lessons in secondary schools by using a learner model. We are explaining how the three phases of our learner model (data collection - profile construction - profile application) can be implemented for teaching robotics by using different types of implicit and explicit data to generate feedback for the teacher concerning competencies and knowledge of the students on the one hand and by supporting collaboration and group formation amongst the students on the other hand. The model is derived from literature and supported by data from different studies.","robotics, feedback, learner model, computer science education","","L@S '20"
"Conference Paper","Lin L,Wang F,Wang F","Research on Learning Resource Recommendation Based on Learner Model","","2023","","","45–50","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2022 5th International Conference on Education Technology Management","Lincoln, United Kingdom","2023","9781450398015","","https://doi.org/10.1145/3582580.3582589;http://dx.doi.org/10.1145/3582580.3582589","10.1145/3582580.3582589","In the era of education big data, personalized learning has become the new normal of digital learning. As an important application direction of personalized learning system, learning resource recommendation is used to solve the problems of ""information overload"" and ""information maze"" caused by massive learning resources. This paper first constructs learner profile data based on learners' learning behavior, and uses GA-K-means algorithm to cluster learners according to the characteristic data of learner model, which effectively solves the cold start problem caused by untimely resource scoring. Finally, a learning resource recommendation method is designed from the three dimensions of consolidation, promotion and expansion, and N resources with the highest degree of fit are recommended to learners. The experimental results show that GA-K-means algorithm is significantly better than the traditional K-means clustering algorithm in stability and effectiveness, and the classification of learner groups is also in line with the actual situation, which can recommend personalized learning resources that meet the cognitive level for students.","learner model, e-learning, learning resource, recommendation algorithm","","ICETM '22"
"Journal Article","He L,Li X,Wang P,Tang J,Wang T","MAN: Memory-Augmented Attentive Networks for Deep Learning-Based Knowledge Tracing","ACM Trans. Inf. Syst.","2023","42","1","","Association for Computing Machinery","New York, NY, USA","","","2023-08","","1046-8188","https://doi.org/10.1145/3589340;http://dx.doi.org/10.1145/3589340","10.1145/3589340","Knowledge Tracing (KT) is the task of modeling a learner’s knowledge state to predict future performance in e-learning systems based on past performance. Deep learning-based methods, such as recurrent neural networks, memory-augmented neural networks, and attention-based neural networks, have recently been used in KT. Such methods have demonstrated excellent performance in capturing the latent dependencies of a learner’s knowledge state on recent exercises. However, these methods have limitations when it comes to dealing with the so-called Skill Switching Phenomenon (SSP), i.e., when learners respond to exercises in an e-learning system, the latent skills in the exercises typically switch irregularly. SSP will deteriorate the performance of deep learning-based approaches for simulating the learner’s knowledge state during skill switching, particularly when the association between the switching skills and the previously learned skills is weak. To address this problem, we propose the Memory-augmented Attentive Network (MAN), which combines the advantages of memory-augmented neural networks and attention-based neural networks. Specifically, in MAN, memory-augmented neural networks are used to model learners’ longer term memory knowledge, while attention-based neural networks are used to model learners’ recent term knowledge. In addition, we design a context-aware attention mechanism that automatically weighs the tradeoff between these two types of knowledge. With extensive experiments on several e-learning datasets, we show that MAN effectively improve predictive accuracies of existing state-of-the-art DLKT methods.","deep learning, E-learning, multi-head attention mechanism, memory-augmented neural network, knowledge tracing","",""
"Conference Paper","Spaulding S,Breazeal C","Affect and Inference in Bayesian Knowledge Tracing with a Robot Tutor","","2015","","","219–220","Association for Computing Machinery","New York, NY, USA","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","Portland, Oregon, USA","2015","9781450333184","","https://doi.org/10.1145/2701973.2702720;http://dx.doi.org/10.1145/2701973.2702720","10.1145/2701973.2702720","In this paper, we present work to construct a robotic tutoring system that can assess student knowledge in real time during an educational interaction. Like a good human teacher, the robot draws on multimodal data sources to infer whether students have mastered language skills. Specifically, the model extends the standard Bayesian Knowledge Tracing algorithm to incorporate an estimate of the student's affective state (whether he/she is confused, bored, engaged, smiling, etc.) in order to predict future educational performance. We propose research to answer two questions: First, does augmenting the model with affective information improve the computational quality of inference? Second, do humans display more prominent affective signals in an interaction with a robot, compared to a screen-based agent? By answering these questions, this work has the potential to provide both algorithmic and human-centered motivations for further development of robotic systems that tightly integrate affect understanding and complex models of inference with interactive, educational robots.","Bayesian knowledge tracing, affective computing, socially assistive robots, tutoring","","HRI'15 Extended Abstracts"
"Conference Paper","Zhang M,Zhu X,Zhang C,Qian W,Pan F,Zhao H","Counterfactual Monotonic Knowledge Tracing for Assessing Students' Dynamic Mastery of Knowledge Concepts","","2023","","","3236–3246","Association for Computing Machinery","New York, NY, USA","Proceedings of the 32nd ACM International Conference on Information and Knowledge Management","Birmingham, United Kingdom","2023","","","https://doi.org/10.1145/3583780.3614827;http://dx.doi.org/10.1145/3583780.3614827","10.1145/3583780.3614827","As the core of the Knowledge Tracking (KT) task, assessing students' dynamic mastery of knowledge concepts is crucial for both offline teaching and online educational applications. Since students' mastery of knowledge concepts is often unlabeled, existing KT methods focus on predicting students' responses to practices. However, purely predicting student responses without imposing specific constraints on hidden concept mastery values does not guarantee the accuracy of these intermediate values as concept mastery values. To address this issue, we propose a principled approach called Counterfactual Monotonic Knowledge Tracing (CMKT), which builds on the implicit paradigm described above by using a counterfactual assumption to constrain the evolution of students' mastery of knowledge concepts. Specifically, CMKT first assesses students' knowledge concept mastery value based on their historical practice sequences. Then, CMKT sets the answer of the most recent practice as the opposite of the actual answer and, based on this counterfactual answer, assesses the student's corresponding counterfactual knowledge mastery value. During the model training process, CMKT constrains the update of the student's knowledge states by ensuring that the two types of knowledge mastery values of students satisfy a fundamental educational theory, the monotonicity theory, to provide specific semantics for the assessed mastery values by the model. Finally, extensive experiments on five datasets demonstrate the superiority of CMKT over baseline models.","educational data mining, knowledge tracing, counterfactual monotonicity, students' dynamic mastery of concepts","","CIKM '23"
"Conference Paper","Kickmeier-Rust MD,Ginon B,Johnson MD,Türker A","Lea's Box' Persuadable Open Learner Model: A Case Study in the Field of Speed Reading Training","","2018","","","355–356","Association for Computing Machinery","New York, NY, USA","Proceedings of the 26th Conference on User Modeling, Adaptation and Personalization","Singapore, Singapore","2018","9781450355896","","https://doi.org/10.1145/3209219.3209257;http://dx.doi.org/10.1145/3209219.3209257","10.1145/3209219.3209257","Learner models are a key element of many intelligent computer-based assessment and training approaches. Oftentimes, these models, the processes, and evidences are hidden from the learners and even teachers. Open learner models (OLM) are intended to make the underlying logic of a model as well as the evidences that contributed to a certain student appraisal transparent to its users. Furthermore, they are intended to support learning in a formative sense, aiming to help learners to self-monitor, plan, focus, and work independently as well as to communicate and negotiate appraisals with peers and teachers. We present a use case where Lea's OLM uses evidence from a speed-reading training application, to build the model. Learners use a persuasion function to interact with the system and maintain the OLM. The study showed that students are able to use it efficiently in order to make their model more accurate. We argue that persuasion, and other interactive maintenance features, are a strong approach to improve a transparent and accurate learner modelling, specifically when the underlying evidences are manifold and from multiple, partially unclear sources. Moreover, we found that the possibility to interact with the system on an individual basis and to have the possibility to intervene in the process is a strong means of making educational systems more personalized","competency-based approach, learner model persuasion, learning analytics, open learner model","","UMAP '18"
"Conference Paper","David YB,Segal A,Gal Ykobi","Sequencing Educational Content in Classrooms Using Bayesian Knowledge Tracing","","2016","","","354–363","Association for Computing Machinery","New York, NY, USA","Proceedings of the Sixth International Conference on Learning Analytics & Knowledge","Edinburgh, United Kingdom","2016","9781450341905","","https://doi.org/10.1145/2883851.2883885;http://dx.doi.org/10.1145/2883851.2883885","10.1145/2883851.2883885","Despite the prevalence of e-learning systems in schools, most of today's systems do not personalize educational data to the individual needs of each student. This paper proposes a new algorithm for sequencing questions to students that is empirically shown to lead to better performance and engagement in real schools when compared to a baseline approach. It is based on using knowledge tracing to model students' skill acquisition over time, and to select questions that advance the student's learning within the range of the student's capabilities, as determined by the model. The algorithm is based on a Bayesian Knowledge Tracing (BKT) model that incorporates partial credit scores, reasoning about multiple attempts to solve problems, and integrating item difficulty. This model is shown to outperform other BKT models that do not reason about (or reason about some but not all) of these features. The model was incorporated into a sequencing algorithm and deployed in two classes in different schools where it was compared to a baseline sequencing algorithm that was designed by pedagogical experts. In both classes, students using the BKT sequencing approach solved more difficult questions and attributed higher performance than did students who used the expert-based approach. Students were also more engaged using the BKT approach, as determined by their interaction time and number of log-ins to the system, as well as their reported opinion. We expect our approach to inform the design of better methods for sequencing and personalizing educational content to students that will meet their individual learning needs.","","","LAK '16"
"Conference Paper","MacHardy Z,Pardos ZA","Toward the Evaluation of Educational Videos Using Bayesian Knowledge Tracing and Big Data","","2015","","","347–350","Association for Computing Machinery","New York, NY, USA","Proceedings of the Second (2015) ACM Conference on Learning @ Scale","Vancouver, BC, Canada","2015","9781450334112","","https://doi.org/10.1145/2724660.2728690;http://dx.doi.org/10.1145/2724660.2728690","10.1145/2724660.2728690","Along with the advent of MOOCs and other online learning platforms such as Khan Academy, the role of online education has continued to grow in relation to that of traditional on-campus instruction. Rather than tackle the problem of evaluating large educational units such as entire online courses, this paper approaches a smaller problem: exploring a framework for evaluating more granular educational units, in this case, short educational videos. We have chosen to leverage an adaptation of traditional Bayesian Knowledge Tracing (BKT), intended to incorporate the usage of video content in addition to assessment activity. By exploring the change in predictive error when alternately including or omitting video activity, we suggest a metric for determining the relevance of videos to associated assessments. To validate our hypothesis and demonstrate the application of our proposed methods we use data obtained from the popular Khan Academy website.","online education, knowledge tracing, instructional technology, educational videos, bayesian inference","","L@S '15"
"Conference Paper","Bhatt S,Zhao J,Thille C,Zimmaro D,Gattani N","Evaluating Bayesian Knowledge Tracing for Estimating Learner Proficiency and Guiding Learner Behavior","","2020","","","357–360","Association for Computing Machinery","New York, NY, USA","Proceedings of the Seventh ACM Conference on Learning @ Scale","Virtual Event, USA","2020","9781450379519","","https://doi.org/10.1145/3386527.3406746;http://dx.doi.org/10.1145/3386527.3406746","10.1145/3386527.3406746","Open navigation online learning systems allow learners to choose the next learning activity. These systems can be instrumented to provide learners with feedback to help them choose the next learning activity. One type of feedback is providing an estimate of the learner's current skill proficiency. A learner can then choose to skip the remaining learning activities for that skill after achieving proficiency in that skill. In this paper, we investigate whether predicting proficiency and communicating it to learners can save time for learners within a course. We evaluate the accuracy of the BKT based proficiency pre- diction framework for learner's proficiency prediction which considers one attempt per question. We extend the proficiency prediction framework to include multiple attempts at individual questions and show that it is more accurate in proficiency prediction than BKT based proficiency prediction framework. We discuss the potential implications of attempt enhanced framework on the learners' behavior for open navigation on- line learning systems.","mastery prediction, learner behavior analysis, baysian knowledge tracing, knowledge tracing","","L@S '20"
"Conference Paper","Lee HS,Gweon GH,Dorsey C,Tinker R,Finzer W,Damelin D,Kimball N,Pallant A,Lord T","How Does Bayesian Knowledge Tracing Model Emergence of Knowledge about a Mechanical System?","","2015","","","171–175","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fifth International Conference on Learning Analytics And Knowledge","Poughkeepsie, New York","2015","9781450334174","","https://doi.org/10.1145/2723576.2723587;http://dx.doi.org/10.1145/2723576.2723587","10.1145/2723576.2723587","An interactive learning task was designed in a game format to help high school students acquire knowledge about a simple mechanical system involving a car moving on a ramp. This ramp game consisted of five challenges that addressed individual knowledge components with increasing difficulty. In order to investigate patterns of knowledge emergence during the ramp game, we applied the Monte Carlo Bayesian Knowledge Tracing (BKT) algorithm to 447 game segments produced by 64 student groups in two physics teachers' classrooms. Results indicate that, in the ramp game context, (1) the initial knowledge and guessing parameters were significantly highly correlated, (2) the slip parameter was interpretable monotonically, (3) low guessing parameter values were associated with knowledge emergence while high guessing parameter values were associated with knowledge maintenance, and (4) the transition parameter showed the speed of knowledge emergence. By applying the k-means clustering to ramp game segments represented in the three dimensional space defined by guessing, slip, and transition parameters, we identified seven clusters of knowledge emergence. We characterize these clusters and discuss implications for future research as well as for instructional game design.","physics learning, Bayesian knowledge tracing, game-based learning","","LAK '15"
"Conference Paper","Bull S,Ginon B,Boscolo C,Johnson M","Introduction of Learning Visualisations and Metacognitive Support in a Persuadable Open Learner Model","","2016","","","30–39","Association for Computing Machinery","New York, NY, USA","Proceedings of the Sixth International Conference on Learning Analytics & Knowledge","Edinburgh, United Kingdom","2016","9781450341905","","https://doi.org/10.1145/2883851.2883853;http://dx.doi.org/10.1145/2883851.2883853","10.1145/2883851.2883853","This paper describes open learner models as visualisations of learning for learners, with a particular focus on how information about their learning can be used to help them reflect on their skills, identify gaps in their skills, and plan their future learning. We offer an approach that, in addition to providing visualisations of their learning, allows learners to propose changes to their learner model. This aims to help improve the accuracy of the learner model by taking into account student viewpoints on their learning, while also promoting learner reflection on their learning as part of a discussion of the content of their learner model. This aligns well with recent calls for learning analytics for learners. Building on previous research showing that learners will use open learner models, we here investigate their initial reactions to open learner model features to identify the likelihood of uptake in contexts where an open learner model is offered on an optional basis. We focus on university students' perceptions of a range of visualisations and their stated preferences for a facility to view evidence for the learner model data and to propose changes to the values.","persuading the learner model, learning analytics for learners, open learner models, visual learning analytics","","LAK '16"
"Conference Paper","Zhang M,Zhu X,Zhang C,Pan F,Qian W,Zhao H","No Length Left Behind: Enhancing Knowledge Tracing for Modeling Sequences of Excessive or Insufficient Lengths","","2023","","","3226–3235","Association for Computing Machinery","New York, NY, USA","Proceedings of the 32nd ACM International Conference on Information and Knowledge Management","Birmingham, United Kingdom","2023","","","https://doi.org/10.1145/3583780.3614988;http://dx.doi.org/10.1145/3583780.3614988","10.1145/3583780.3614988","Knowledge tracing (KT) aims to predict students' responses to practices based on their historical question-answering behaviors. However, most current KT methods focus on improving overall AUC, leaving ample room for optimization in modeling sequences of excessive or insufficient lengths. As sequences get longer, computational costs will increase exponentially. Therefore, KT methods usually truncate sequences to an acceptable length, which makes it difficult for models on online service systems to capture complete historical practice behaviors of students with too long sequences. Conversely, modeling students with short practice sequences using most KT methods may result in overfitting due to limited observation samples. To address the above limitations, we propose a model called Sequence-Flexible Knowledge Tracing (SFKT). Specifically, to flexibly handle long sequences, SFKT introduces a total-term encoder to effectively model complete historical practice behaviors of students at an affordable computational cost. Additionally, to improve the prediction accuracy of students with short practice sequences, we introduce a contrastive learning task and data augmentation schema to improve the generality of modeling short sequences by constructing more learning objectives. Extensive experimental results show that SFKT achieves significant improvements over multiple benchmarks, demonstrating the value of exploring the modeling of sequences of excessive or insufficient lengths. Our code is available at https://github.com/zmy-9/SFKT.","long and short sequence modeling, knowledge tracing, self-supervised learning, educational data mining","","CIKM '23"
"Conference Paper","Al-Hmouz A,Shen J,Yan J,Al-Hmouz R","Enhanced Learner Model for Adaptive Mobile Learning","","2010","","","783–786","Association for Computing Machinery","New York, NY, USA","Proceedings of the 12th International Conference on Information Integration and Web-Based Applications & Services","Paris, France","2010","9781450304214","","https://doi.org/10.1145/1967486.1967614;http://dx.doi.org/10.1145/1967486.1967614","10.1145/1967486.1967614","Personalisation and learner modelling are becoming more important in the area of mobile learning applications, taking into consideration learners' interests, preferences and contextual information. Students nowadays are able to learn anywhere and at any time. Mobile learning application content is one of several factors within various contexts that play an important role in the success of the adaptation process. The vast amount of data involved in any successful adaptation process creates complexity and poses serious challenges. This paper focuses on how to model the learner and all possible contexts in an extensible way that can be used for personalisation in mobile learning. The enhanced learner modelling structure to be used in a mobile learning system is proposed. The proposed structure provides personalisation by adopting a hybrid approach combining two machine learning techniques.","","","iiWAS '10"
"Conference Paper","Gusukuma L","A Misconception Driven Student Model to Author Feedback","","2018","","","266–267","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2018 ACM Conference on International Computing Education Research","Espoo, Finland","2018","9781450356282","","https://doi.org/10.1145/3230977.3231015;http://dx.doi.org/10.1145/3230977.3231015","10.1145/3230977.3231015","Getting novice programmers over initial misconceptions is difficult because learning programming is difficult. Practice is one of the best ways for novices to learn. However, in the absence of feedback contextualized to instruction and focused on misconceptions, misconceptions become a difficult hurdle. To improve feedback, I present the Misconception-Driven Student Model (MDSM). MDSM is a cognitive model that lends itself to a framework to scalably deliver Misconception-Driven Feedback (MDF). I show MDF's impact through a quasi-experimental study that indicates that MDF significantly supports programming skill development. I plan on verifying these results by running another experimental study.","misconception, immediate feedback, student model, cs education","","ICER '18"
"Conference Paper","Argasinski JK,Lipp N","Enhancing VR Based Serious Games and Simulations Design: Bayesian Knowledge Tracing and Pattern-Based Approaches","","2023","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 29th ACM Symposium on Virtual Reality Software and Technology","Christchurch, New Zealand","2023","","","https://doi.org/10.1145/3611659.3616900;http://dx.doi.org/10.1145/3611659.3616900","10.1145/3611659.3616900","This paper explores how Bayesian Knowledge Tracing (BKT) can be integrated with a pattern-based approach to enhance the development of virtual reality (VR) based serious games and simulations. These technologies allow for the prediction of user progress and the utilization of Artificial Intelligence (AI) methods to tailor difficulty levels based on individual needs. By combining BKT, pattern-based mechanics, and affective feedback, comprehensive data on user interactions, skills, and emotional states can be collected. This data enables the estimation of learners’ knowledge levels and the prediction of their progress.","design patterns, simulations, serious games, virtual reality, Bayesian Knowledge Tracing","","VRST '23"
"Conference Paper","Yang S,Zhang T,Mao S,Yu G,Sun Y","MAKT: A Knowledge Tracing Model Based on Meta Path and Attention Mechanism","","2022","","","70–74","Association for Computing Machinery","New York, NY, USA","Proceedings of the 5th International Conference on Computer Science and Software Engineering","Guilin, China","2022","9781450397780","","https://doi.org/10.1145/3569966.3569987;http://dx.doi.org/10.1145/3569966.3569987","10.1145/3569966.3569987","With the deep integration of artificial intelligence technology and education, the traditional educational pattern has changed hugely. And the adaptive learning based on automatically tracing the knowledge status of students at various stages has attracted much attention. As a key technology, knowledge tracing has become an important research. Although deep learning has been used in knowledge tracing and promoted certain performance improvement, it still has drawbacks. First, current researches consider less the explicit representation of meta path between users, exercise items and knowledge points, ignoring some of the higher-order information. Secondly, the effect of higher-order information of knowledge points on prediction is ignored. Therefore, we proposes a meta-path based four-way co-attention mechanism model MAKT to inversely infer the unobservable knowledge cognitive proficiency of learners. Based on meta path, the MAKT model integrates instance information and higher-order information between nodes to effectively enhance the representation of user, exercise item and knowledge points. The effectiveness of the model was demonstrated in tests on a real data set.","neural networks, heterogeneous information network, meta path","","CSSE '22"
"Conference Paper","Gweon GH,Lee HS,Dorsey C,Tinker R,Finzer W,Damelin D","Tracking Student Progress in a Game-like Learning Environment with a Monte Carlo Bayesian Knowledge Tracing Model","","2015","","","166–170","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fifth International Conference on Learning Analytics And Knowledge","Poughkeepsie, New York","2015","9781450334174","","https://doi.org/10.1145/2723576.2723608;http://dx.doi.org/10.1145/2723576.2723608","10.1145/2723576.2723608","The Bayesian Knowledge Tracing (BKT) model is a popular model used for tracking student progress in learning systems such as an intelligent tutoring system. However, the model is not free of problems. Well-recognized problems include the identifiability problem and the empirical degeneracy problem. Unfortunately, these problems are still poorly understood and how they should be dealt with in practice is unclear. Here, we analyze the mathematical structure of the BKT model, identify a source of the difficulty, and construct a simple Monte Carlo BKT model to analyze the problem in real data. Using the student activity data obtained from the ramp task module at the Concord Consortium, we find that the Monte Carlo BKT analysis is capable of detecting the identifiability problem and the empirical degeneracy problem, and, more generally, gives an excellent summary of the student learning data. In particular, the student activity monitoring parameter M emerges as the central parameter.","Bayesian knowledge tracing, Monte Carlo, educational data mining","","LAK '15"
"Conference Paper","Ennouamani S,Mahani Z","A Comparative Study of the Learner Model in Adaptive Mobile Learning Systems","","2019","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2nd International Conference on Networking, Information Systems & Security","Rabat, Morocco","2019","9781450366458","","https://doi.org/10.1145/3320326.3320351;http://dx.doi.org/10.1145/3320326.3320351","10.1145/3320326.3320351","Currently, scientific researches in the field of e-learning in general and m-learning in particular are oriented towards learning platforms where learner's expectations, motivation, learning styles, habits and needs are increasingly taken into consideration. This research direction enables developers to build a model of goals, preferences and knowledge of each individual user in order to adapt the learning to his/her needs and characteristics. For this purpose, we present in this paper a comparative study of the existing learner models in adaptive m-learning systems that consider a combination of learner's characteristics and context in order to provide each learner with the most suitable learning content and format of presentation. We end our paper by suggesting a future proposal after criticizing the related works.","E-Learning, Adaptive Computing, Learner Model, Context, Mobile Learning Applications","","NISS19"
"Conference Paper","Zheliazkova I,Kolev R","A Three-Level Learner's Model for the Needs of an Integrated Environment for Individual Planned Teaching","","2004","","","1–6","Association for Computing Machinery","New York, NY, USA","Proceedings of the 5th International Conference on Computer Systems and Technologies","Rousse, Bulgaria","2004","9789549641387","","https://doi.org/10.1145/1050330.1050422;http://dx.doi.org/10.1145/1050330.1050422","10.1145/1050330.1050422","The learner's knowledge, skills, psychological characteristics, and preferred style of learning have been used for individualization of teaching in different generations of computer-based systems. A survey indicates that the problem of the learner modeling in the intelligent distributed teaching and learning environments is still opened. In the present paper a three-level learner's model for the needs of an integrated environment for individual planned teaching is discussed.","learner's model, individual planned teaching, integrated environment","","CompSysTech '04"
"Conference Paper","Law CY,Grundy J,Cain A,Vasa R,Cummaudo A","User Perceptions of Using an Open Learner Model Visualisation Tool for Facilitating Self-Regulated Learning","","2017","","","55–64","Association for Computing Machinery","New York, NY, USA","Proceedings of the Nineteenth Australasian Computing Education Conference","Geelong, VIC, Australia","2017","9781450348232","","https://doi.org/10.1145/3013499.3013502;http://dx.doi.org/10.1145/3013499.3013502","10.1145/3013499.3013502","Ways to encourage self-regulated learning have become a hot topic in higher education. In this research study, we explored users' perceptions regarding the uptake and effective use of an open learner model visualisation prototype tool -- Doubtfire++, in facilitating student self-regulated learning supporting Task-oriented Portfolio teaching and learning. We investigated students' perceptions of setting appropriate goals, monitoring performance and reflecting on learning through the use of the visualisation tool to support students in becoming self-regulated learners. Data was collected from 134 users using an online survey questionnaire. Results show that Doubtfire++ positively impacted users' perceptions of setting appropriate goals, monitoring performance and reflecting on learning. User role, experience using Doubtfire++, frequency of using Doubtfire++ and different teaching units significantly impacted respondents' perceptions whereas gender and familiarity with information visualisation techniques had no impact on respondents' perceptions. The results indicate that the approach can facilitate student self-regulated learning, especially for those new to Task-oriented Portfolio teaching and learning of programming units.","Education, self-regulated learning, information visualisation, constructive alignment, outcome-based learning, open learner model","","ACE '17"
"Conference Paper","Schodde T,Bergmann K,Kopp S","Adaptive Robot Language Tutoring Based on Bayesian Knowledge Tracing and Predictive Decision-Making","","2017","","","128–136","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction","Vienna, Austria","2017","9781450343367","","https://doi.org/10.1145/2909824.3020222;http://dx.doi.org/10.1145/2909824.3020222","10.1145/2909824.3020222","In this paper, we present an approach to adaptive language tutoring in child-robot interaction. The approach is based on a dynamic probabilistic model that represents the inter-relations between the learner's skills, her observed behaviour in tutoring interaction, and the tutoring action taken by the system. Being implemented in a robot language tutor, the model enables the robot tutor to trace the learner's knowledge and to decide which skill to teach next and how to address it in a game-like tutoring interaction. Results of an evaluation study are discussed demonstrating how participants in the adaptive tutoring condition successfully learned foreign language words.","Bayesian knowledge tracing, education, decision making, assistive robotics, language tutoring","","HRI '17"
"Journal Article","Wei F,Moritz SH,Parvez SM,Blank GD","A Student Model for Object-Oriented Design and Programming","J. Comput. Sci. Coll.","2005","20","5","260–273","Consortium for Computing Sciences in Colleges","Evansville, IN, USA","","","2005-05","","1937-4771","","","""Objects-first"" is an increasingly popular strategy for teaching object-oriented programming by introducing the concepts of objects, classes, and instances before procedural elements of a programming language. Learning object-oriented design and programming is a challenging task for many beginning students. We represent CIMEL ITS, which is an intelligent tutoring system that provides one-on-one tutoring to help beginners learn object-oriented analysis and design, using elements of UML before implementing any code. We also present a three-layered Student Model which supports adaptive tutoring by inferring the problem-specific knowledge state from student solutions, the historical knowledge state of the student and cognitive reasons about why the student makes an error.","","",""
"Conference Paper","Barria-Pineda J,Guerra-Hollstein J,Brusilovsky P","A Fine-Grained Open Learner Model for an Introductory Programming Course","","2018","","","53–61","Association for Computing Machinery","New York, NY, USA","Proceedings of the 26th Conference on User Modeling, Adaptation and Personalization","Singapore, Singapore","2018","9781450355896","","https://doi.org/10.1145/3209219.3209242;http://dx.doi.org/10.1145/3209219.3209242","10.1145/3209219.3209242","Guiding students to the learning activities that are most appropriate for their current level of knowledge is one of the goals that adaptive educational systems tried to achieve during the last decades. Recently, several attempts have been made to use Open Learner Models (OLM) as a tool for achieving this goal. While the original goal of OLM is to help students reflect about their own learning process, extending OLM with navigation support functionality enables students to take immediate actions towards improving their knowledge. In this work, we attempted to extend the navigation support functionality of OLM by developing a fine-grained OLM that offers student knowledge visualization on both topic and concept levels. The fine-grained OLM enables students to directly explore connections between their knowledge and available learning activities, making an informed decision about their next learning steps. To assess the impact of the new type of OLM, we evaluated several versions of it in a classroom study, while also comparing it with data from our earlier studies that featured a coarse-grained OLM. Our results suggest that the fine-grained OLM considerably impacts student choice of learning activities, making student learning more efficient. We also found that the specific design features of fine-grained OLM could affect students' confidence and persistence while selecting and attempting the learning activities.","open learner models, computer science education, self-regulated learning, information visualization","","UMAP '18"
"Conference Paper","Nguyen CD,Vo KD,Bui DB,Nguyen DT","An Ontology-Based IT Student Model in an Educational Social Network","","2011","","","379–382","Association for Computing Machinery","New York, NY, USA","Proceedings of the 13th International Conference on Information Integration and Web-Based Applications and Services","Ho Chi Minh City, Vietnam","2011","9781450307840","","https://doi.org/10.1145/2095536.2095609;http://dx.doi.org/10.1145/2095536.2095609","10.1145/2095536.2095609","User modeling helps information systems know about their user behavior to provide better services. An educational social network, called SoNITS, has been developed for IT students. This paper introduces an ontology-based student model that is used in SoNITS. Issues about constructing and managing student models are discussed. Applications that utilize these user models are also discussed.","ontology, information technology, user modeling, social network","","iiWAS '11"
"Conference Paper","He Y,Hu X,Xu Z,Sun,Guangzhong","KT-XL: A Knowledge Tracing Model for Predicting Learning Performance Based on Transformer-XL","","2020","","","175–179","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM Turing Celebration Conference - China","Hefei, China","2020","9781450375344","","https://doi.org/10.1145/3393527.3393557;http://dx.doi.org/10.1145/3393527.3393557","10.1145/3393527.3393557","With the development of artificial intelligence (AI) technology, online teaching systems have become intellectualized. Knowledge tracing is an important task of intelligent teaching system. The goal of knowledge tracing is to trace students' knowledge status based on their past performance. It is widely used for predicting students' performance and building knowledge graph, which plays an important role in constructing adaptive (personalized) teaching systems. Previous models can not deal with subjective problems, and the performance is somewhat poor when input exercise sequences are long. In this paper, we propose a knowledge tracing model for subjective problems based on Transformer-XL, which can predict students' performance of a specific exercise. Specifically, we introduce a recurrence mechanism to the model to capture longer-term dependency and achieve better performance on both short and long sequences. Experiments on multiple real-world data sets and synthetic data sets show that our model performs better in predicting students' performance than state of the art models.","recurrence mechanism, online education, self-attention, knowledge tracing","","ACM TURC '20"
"Conference Paper","Pardos ZA,Heffernan NT","KT-IDEM: Introducing Item Difficulty to the Knowledge Tracing Model","","2011","","","243–254","Springer-Verlag","Berlin, Heidelberg","Proceedings of the 19th International Conference on User Modeling, Adaption, and Personalization","Girona, Spain","2011","9783642223617","","","","Many models in computer education and assessment take into account difficulty. However, despite the positive results of models that take difficulty in to account, knowledge tracing is still used in its basic form due to its skill level diagnostic abilities that are very useful to teachers. This leads to the research question we address in this work: Can KT be effectively extended to capture item difficulty and improve prediction accuracy? There have been a variety of extensions to KT in recent years. One such extension was Baker's contextual guess and slip model. While this model has shown positive gains over KT in internal validation testing, it has not performed well relative to KT on unseen in-tutor data or post-test data, however, it has proven a valuable model to use alongside other models. The contextual guess and slip model increases the complexity of KT by adding regression steps and feature generation. The added complexity of feature generation across datasets may have hindered the performance of this model. Therefore, one of the aims of our work here is to make the most minimal of modifications to the KT model in order to add item difficulty and keep the modification limited to changing the topology of the model. We analyze datasets from two intelligent tutoring systems with KT and a model we have called KT-IDEM (Item Difficulty Effect Model) and show that substantial performance gains can be achieved with this minor modification that incorporates item difficulty.","data mining, Bayesian networks, knowledge tracing, item difficulty, user modeling","","UMAP'11"
"Conference Paper","Kump B,Seifert C,Beham G,Lindstaedt SN,Ley T","Seeing What the System Thinks You Know: Visualizing Evidence in an Open Learner Model","","2012","","","153–157","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2nd International Conference on Learning Analytics and Knowledge","Vancouver, British Columbia, Canada","2012","9781450311113","","https://doi.org/10.1145/2330601.2330640;http://dx.doi.org/10.1145/2330601.2330640","10.1145/2330601.2330640","User knowledge levels in adaptive learning systems can be assessed based on user interactions that are interpreted as Knowledge Indicating Events (KIE). Such an approach makes complex inferences that may be hard to understand for users, and that are not necessarily accurate. We present MyExperiences, an open learner model designed for showing the users the inferences about them, as well as the underlying data. MyExperiences is one of the first open learner models based on tree maps. It constitutes an example of how research into open learner models and information visualization can be combined in an innovative way.","knowledge indicating events, visual learning analytics, open learner model","","LAK '12"
"Conference Paper","Guerra J,Hosseini R,Somyurek S,Brusilovsky P","An Intelligent Interface for Learning Content: Combining an Open Learner Model and Social Comparison to Support Self-Regulated Learning and Engagement","","2016","","","152–163","Association for Computing Machinery","New York, NY, USA","Proceedings of the 21st International Conference on Intelligent User Interfaces","Sonoma, California, USA","2016","9781450341370","","https://doi.org/10.1145/2856767.2856784;http://dx.doi.org/10.1145/2856767.2856784","10.1145/2856767.2856784","We present the Mastery Grids system, an intelligent interface for online learning content that combines open learner modeling (OLM) and social comparison features. We grounded the design of Mastery Grids in self-regulated learning and learning motivation theories, as well as in our past work in social comparison, OLM, and adaptive navigation support. The force behind the interface is the combination of adaptive navigation functionality with the mastery-oriented aspects of OLM and the performance-oriented aspects of social comparison. We examined different configurations of Mastery Grids in two classroom studies and report the results of analysis of log data and survey responses. The results show how Mastery Grids interacts with different factors, like gender and achievement-goal orientation, and ultimately, its impact on student engagement, performance, and motivation.","achievement-goal orientation, social comparison, open learner model, self-regulated learning","","IUI '16"
"Conference Paper","Chaplot DS,Rhim E,Kim J","Personalized Adaptive Learning Using Neural Networks","","2016","","","165–168","Association for Computing Machinery","New York, NY, USA","Proceedings of the Third (2016) ACM Conference on Learning @ Scale","Edinburgh, Scotland, UK","2016","9781450337267","","https://doi.org/10.1145/2876034.2893397;http://dx.doi.org/10.1145/2876034.2893397","10.1145/2876034.2893397","Adaptive learning is the core technology behind intelligent tutoring systems, which are responsible for estimating student knowledge and providing personalized instruction to students based on their skill level. In this paper, we present a new adaptive learning system architecture, which uses Artificial Neural Network to construct the Learner Model, which automatically models relationship between different concepts in the curriculum and beats Knowledge Tracing in predicting student performance. We also propose a novel method for selecting items of optimal difficulty, personalized to student's skill level and learning rate, which decreases their learning time by 26.5% as compared to standard pre-defined curriculum sequence item selection policy.","neural networks, instructional model, personalized item selection, learner model, adaptive learning, student model","","L@S '16"
"Conference Paper","Huang Y,Yudelson M,Han S,He D,Brusilovsky P","A Framework for Dynamic Knowledge Modeling in Textbook-Based Learning","","2016","","","141–150","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization","Halifax, Nova Scotia, Canada","2016","9781450343688","","https://doi.org/10.1145/2930238.2930258;http://dx.doi.org/10.1145/2930238.2930258","10.1145/2930238.2930258","Various e-learning systems that provide electronic textbooks are gathering data on large numbers of student reading interactions. This data can potentially be used to model student knowledge acquisition. However, reading activity is often overlooked in canonical student modeling. Prior studies modeling learning from reading either estimate student knowledge at the end of all reading activities, or use quiz performance data with expert-crafted knowledge components (KCs). In this work, we demonstrate that the dynamic modeling of student knowledge is feasible and that automatic text analysis can be applied to save expert effort. We propose a data-driven approach for dynamic student modeling in textbook-based learning. We formulate the problem of modeling learning from reading as a reading-time prediction problem, reconstruct existing popular student models (such as Knowledge Tracing) and explore two automatic text analysis approaches (bag-of-words-based and latent semantic-based) to build the KC model. We evaluate the proposed framework using a dataset collected from a Human-Computer Interaction course. Results show that our approach for reading modeling is plausible; the proposed Knowledge Tracing-based student model reliably outperforms baselines and the latent semantic-based approach can be a promising way to construct a KC model. Serving as the first step to model dynamic knowledge in textbook-based learning, our framework can be applied to a broader context of open-corpus personalized learning.","reading, performance factor analysis, latent topic modeling, learner model, text analysis, knowledge tracing, additive factor model, textbook-based learning","","UMAP '16"
"Conference Paper","Long T,Liu Y,Shen J,Zhang W,Yu Y","Tracing Knowledge State with Individual Cognition and Acquisition Estimation","","2021","","","173–182","Association for Computing Machinery","New York, NY, USA","Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval","Virtual Event, Canada","2021","9781450380379","","https://doi.org/10.1145/3404835.3462827;http://dx.doi.org/10.1145/3404835.3462827","10.1145/3404835.3462827","Knowledge tracing, which dynamically estimates students' learning states by predicting their performance on answering questions, is an essential task in online education. One typical solution for knowledge tracing is based on Recurrent Neural Networks (RNNs), which represent students' knowledge states with the hidden states of RNNs. Such type of methods normally assumes that students have the same cognition level and knowledge acquisition sensitivity on the same question. Thus, they (i) predict students' responses by referring to their knowledge states and question representations, and (ii) update the knowledge states according to the question representations and students' responses. No explicit cognition level or knowledge acquisition sensitivity is considered in the above two processes. However, in real-world scenarios, students have different understandings on a question and have various knowledge acquisition after they finish the same question. In this paper, we propose a novel model called Individual Estimation Knowledge Tracing (IEKT), which estimates the students' cognition on the question before response prediction and assesses their knowledge acquisition sensitivity on the questions before updating the knowledge state. In the experiments, we compare IEKT with 11 knowledge tracing baselines on four benchmark datasets, and the results show IEKT achieves the state-of-the-art performance.","cognition, knowledge acquisition sensitivity, reinforcement learning, knowledge tracing","","SIGIR '21"
"Conference Paper","Chan KI,Tse R,Lei PI","Tracing Students' Learning Performance on Multiple Skills Using Bayesian Methods","","2022","","","84–89","Association for Computing Machinery","New York, NY, USA","Proceedings of the 6th International Conference on Education and Multimedia Technology","Guangzhou, China","2022","9781450396455","","https://doi.org/10.1145/3551708.3556202;http://dx.doi.org/10.1145/3551708.3556202","10.1145/3551708.3556202","Knowledge tracing (KT) is a research field of growing importance in technology enhanced education. It models students’ mastery levels of skills and predicts their performance in question answering through an Intelligent Tutoring System (ITS). Traditionally, Bayesian methods like Bayesian Knowledge Tracing (BKT) and Weakest Knowledge Tracing (WKT) apply Hidden Markov Model to model the latent learning process of individual skills. With the advent of recent advances in Deep Learning (DL), DL based KT methods achieve better prediction performance by exploiting the temporal dependencies between consecutive exercises on different skills. However, Bayesian methods are still valuable with a simpler, more intuitive and interpretable model of learning.This paper proposes a new Bayesian method called Corrigible Knowledge Tracing (CKT) which assumes students can learn from mistakes in answering multi-skill questions. In addition, the combinations of high occurrence skills are considered, so that integrated abilities are more fully recognised. In evaluation, the harmonic mean is suggested for combining the predicted probabilities, and accuracy is chosen to be the performance metric. The proposed method is compared with both Bayesian methods and DL approaches by using the conventional question-solving records from a modern large-scale educational data mining dataset called EdNet. Experiment results show that the performance of CKT is on par with state-of-the-art DL approaches. The overall improvement from WKT to the proposed method is substantial.","Student Modelling, Language Learning, Education, Students Performance, Educational Data Mining (EDM), Bayesian Knowledge Tracing (BKT), Weakest Knowledge Tracing (WKT), Corrigible Knowledge Tracing (CKT), Prediction, Intelligent Tutoring System (ITS), Knowledge Tracing (KT)","","ICEMT '22"
"Conference Paper","Jin Z,Ma K,Liu K,Ji K","Exercises Recommendation in Adaptive Learning System","","2019","","","97–100","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2nd International Conference on Big Data Technologies","Jinan, China","2019","9781450371926","","https://doi.org/10.1145/3358528.3358556;http://dx.doi.org/10.1145/3358528.3358556","10.1145/3358528.3358556","The adaptive learning system develops gradually, but most attention is paid to the construction of student model and domain model. In this paper, a recommendation algorithm based on students' current knowledge level is proposed to match suitable exercises and avoid homogenization of learning content for all students, for the purpose of achieving so-called ""adaptative"". It is worth noting that the learning system recommendation is different from the general recommendation. Not only the method, the evaluation standard of recommendation result is also different. We should not simply recommend to students the exercises they must or must not mastered, but recommend to them the learning resources they should have within the range of their abilities according to the theory of proximal development zone. We also use the bayesian knowledge tracing model to judge students' mastery of knowledge as the evaluation standard of this algorithm.","Recommendation System, Singular Value Decomposition, Adaptive Learning, Bayesian Knowledge Tracing","","ICBDT '19"
"Conference Paper","Shin D,Shim Y,Yu H,Lee S,Kim B,Choi Y","SAINT+: Integrating Temporal Features for EdNet Correctness Prediction","","2021","","","490–496","Association for Computing Machinery","New York, NY, USA","LAK21: 11th International Learning Analytics and Knowledge Conference","Irvine, CA, USA","2021","9781450389358","","https://doi.org/10.1145/3448139.3448188;http://dx.doi.org/10.1145/3448139.3448188","10.1145/3448139.3448188","We propose SAINT+, a successor of SAINT which is a Transformer based knowledge tracing model that separately processes exercise information and student response information. Following the architecture of SAINT, SAINT+ has an encoder-decoder structure where the encoder applies self-attention layers to a stream of exercise embeddings, and the decoder alternately applies self-attention layers and encoder-decoder attention layers to streams of response embeddings and encoder output. Moreover, SAINT+ incorporates two temporal feature embeddings into the response embeddings: elapsed time, the time taken for a student to answer, and lag time, the time interval between adjacent learning activities. We empirically evaluate the effectiveness of SAINT+ on EdNet, the largest publicly available benchmark dataset in the education domain. Experimental results show that SAINT+ achieves state-of-the-art performance in knowledge tracing with an improvement of 1.25% in area under receiver operating characteristic curve compared to SAINT, the current state-of-the-art model in EdNet dataset.","Transformer, Education, Personalized Learning, Deep Learning, Knowledge Tracing","","LAK21"
"Conference Paper","Huang Y,Guerra-Hollstein J,Barria-Pineda J,Brusilovsky P","Learner Modeling for Integration Skills","","2017","","","85–93","Association for Computing Machinery","New York, NY, USA","Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization","Bratislava, Slovakia","2017","9781450346351","","https://doi.org/10.1145/3079628.3079677;http://dx.doi.org/10.1145/3079628.3079677","10.1145/3079628.3079677","Complex skill mastery requires not only acquiring individual basic component skills, but also practicing integrating such basic skills. However, traditional approaches to knowledge modeling, such as Bayesian knowledge tracing, only trace knowledge of each decomposed basic component skill. This risks early assertion of mastery or ineffective remediation failing to address skill integration. We introduce a novel integration-level approach to model learners' knowledge and provide fine-grained diagnosis: a Bayesian network based on a new kind of knowledge graph with progressive integration skills. We assess the value of such a model from multifaceted aspects: performance prediction, parameter plausibility, expected instructional effectiveness, and real-world recommendation helpfulness. Our experiments based on a Java programming tutor show that proposed model significantly improves two popular multiple-skill knowledge tracing models on all these four aspects.","skill integration, knowledge tracing, bayesian network, programming patterns, learner modeling","","UMAP '17"
"Conference Paper","Shen S,Huang Z,Liu Q,Su Y,Wang S,Chen E","Assessing Student's Dynamic Knowledge State by Exploring the Question Difficulty Effect","","2022","","","427–437","Association for Computing Machinery","New York, NY, USA","Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval","Madrid, Spain","2022","9781450387323","","https://doi.org/10.1145/3477495.3531939;http://dx.doi.org/10.1145/3477495.3531939","10.1145/3477495.3531939","Knowledge Tracing (KT), which aims to assess students' dynamic knowledge states when practicing on various questions, is a fundamental research task for offering intelligent services in online learning systems. Researchers have devoted significant efforts to developing KT models with impressive performance. However, in existing KT methods, the related question difficulty level, which directly affects students' knowledge state in learning, has not been effectively explored and employed. In this paper, we focus on exploring the question difficulty effect on learning to improve student's knowledge state assessment and propose the DIfficulty Matching Knowledge Tracing (DIMKT) model. Specifically, we first explicitly incorporate the difficulty level into the question representation. Then, to establish the relation between students' knowledge state and the question difficulty level during the practice process, we accordingly design an adaptive sequential neural network in three stages: (1) measuring students' subjective feelings of the question difficulty before practice; (2) estimating students' personalized knowledge acquisition while answering questions of different difficulty levels; (3) updating students' knowledge state in varying degrees to match the question difficulty level after practice. Finally, we conduct extensive experiments on real-world datasets, and the results demonstrate that DIMKT outperforms state-of-the-art KT models. Moreover, DIMKT shows superior interpretability by exploring the question difficulty effect when making predictions. Our codes are available at https://github.com/shshen-closer/DIMKT.","question difficulty effect, data mining, user modeling, adaptive learning, knowledge tracing","","SIGIR '22"
"Conference Paper","Yu J,Lu M,Zhong Q,Yao Z,Tu S,Liao Z,Li X,Li M,Hou L,Zheng HT,Li J,Tang J","MoocRadar: A Fine-Grained and Multi-Aspect Knowledge Repository for Improving Cognitive Student Modeling in MOOCs","","2023","","","2924–2934","Association for Computing Machinery","New York, NY, USA","Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval","Taipei, Taiwan","2023","9781450394086","","https://doi.org/10.1145/3539618.3591898;http://dx.doi.org/10.1145/3539618.3591898","10.1145/3539618.3591898","Student modeling, the task of inferring a student's learning characteristics through their interactions with coursework, is a fundamental issue in intelligent education. Although the recent attempts from knowledge tracing and cognitive diagnosis propose several promising directions for improving the usability and effectiveness of current models, the existing public datasets are still insufficient to meet the need for these potential solutions due to their ignorance of complete exercising contexts, fine-grained concepts, and cognitive labels. In this paper, we present MoocRadar, a fine-grained, multi-aspect knowledge repository consisting of 2,513 exercise questions, 5,600 knowledge concepts, and over 12 million behavioral records. Specifically, we propose a framework to guarantee a high-quality and comprehensive annotation of fine-grained concepts and cognitive labels. The statistical and experimental results indicate that our dataset provides the basis for the future improvements of existing methods. Moreover, to support the convenient usage for researchers, we release a set of tools for data querying, model adaption, and even the extension of our repository, which are now available at https://github.com/THU-KEG/MOOC-Radar.","concept mining, student modeling, knowledge tracing, datasets","","SIGIR '23"
"Conference Paper","Sun X,Zhao X,Ma Y,Yuan X,He F,Feng J","Muti-Behavior Features Based Knowledge Tracking Using Decision Tree Improved DKVMN","","2019","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM Turing Celebration Conference - China","Chengdu, China","2019","9781450371582","","https://doi.org/10.1145/3321408.3322847;http://dx.doi.org/10.1145/3321408.3322847","10.1145/3321408.3322847","Knowledge tracing is a significant research topic in student modeling. It is a task to model students' mastery level of knowledge points by mining their historical exercise performance. Literature has shown that Dynamic Key-Value Memory Networks (DKVMN) which has been proposed to handle the knowledge tracing task generally outperform traditional methods. However, through our experimentation, we have noticed a problem in the DKVMN model that it ignored behavior features collected by intelligence tutoring system (ITS) but only regard the exercise and the correctness as input. Behavior features, such as the response time, the hint request and the number of attempt, can be used to capture the student's learning behavior information and are very helpful in modeling the student's knowledge status. Therefore, the performance of the model can be improved. This work aims to improve the performance of the DKVMN model by incorporating more features to the input. More specifically, we apply decision tree classifier to preprocess the behavior features, which is an effective way to capture how the student deviates from others in the exercise. The predicted response concatenated with the exercise tag to train a DKVMN model, which can output the probability that a student will answer the exercise correctly. The experiment results show that our adapted DKVMN model, incorporating more combinations of behavior features can effectively improve accuracy. On the ASSISTments 2009 education dataset, the AUC value of our experiment is eight percent higher than the original DKVMN model.","deep learning, knowledge tracing, decision tree, dynamic key-value memory networks","","ACM TURC '19"
"Conference Paper","Guerra-Hollstein J,Barria-Pineda J,Schunn CD,Bull S,Brusilovsky P","Fine-Grained Open Learner Models: Complexity Versus Support","","2017","","","41–49","Association for Computing Machinery","New York, NY, USA","Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization","Bratislava, Slovakia","2017","9781450346351","","https://doi.org/10.1145/3079628.3079682;http://dx.doi.org/10.1145/3079628.3079682","10.1145/3079628.3079682","Open Learner Models (OLM) show the learner model to users to assist their self-regulated learning by, for example, helping prompt reflection, facilitating planning and supporting navigation. OLMs can show different levels of detail of the underlying learner model, and can also structure the information differently. As a result, a trade-off may exist between the potential for better support for learning and the complexity of the information shown. This paper investigates students' perceptions about whether offering more and richer information in an OLM will result in more effective support for their self-regulated learning. In a first study, questionnaire responses relating to designs for six visualisations of varying complexity led to the implementation of three variations on one of the designs. A second controlled study involved students interacting with these variations. The study revealed that the most useful variation for searching for suitable learning material was a visualisation combining a basic coloured grid, an extended bar chart-like visualisation indicating related concepts, and a learning gauge.","user study, open learner model, navigation support","","UMAP '17"
"Conference Paper","Chen ZH,Chou CY,Deng YC,Chan TW","Animal Companions as Motivators for Teammates Helping Each Other Learn","","2005","","","43–47","International Society of the Learning Sciences","Taipei, Taiwan","Proceedings of Th 2005 Conference on Computer Support for Collaborative Learning: Learning 2005: The next 10 Years!","","2005","9780805857825","","","","This paper describes and discusses the design rationales of a system called My-Pet-Our-Pet that intends to realize an approach to using simulated animal companions to encourage students to help each other learn. A class of students is divided into several teams. Every student keeps her own individual animal companion, called My-Pet. An important component of animal companion is the student model of its master that supports self-reflection in different perspectives. Also, every team has a team animal companion, called Our-Pet, being kept by all the members of the team collaboratively. Our-Pet has a collective student model composed by all the student models of the team members. The design of Our-Pet help set a team goal through participating a competition game among Our-Pets of different teams, support collective reflections among team members, and shed light for the team how to help each other. We are currently conducting an experimental trail of the system in an elementary school where every student in the class has a Tablet PC.","student model, learning companion, team animal companion, active student model, open student model","","CSCL '05"
"Conference Paper","Dias Pereira dos Santos A","Smart Technology for Supporting Dance Education","","2017","","","335–338","Association for Computing Machinery","New York, NY, USA","Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization","Bratislava, Slovakia","2017","9781450346351","","https://doi.org/10.1145/3079628.3079709;http://dx.doi.org/10.1145/3079628.3079709","10.1145/3079628.3079709","My PhD project sits in the design space that investigates how smart technology can support dance education. My aim is to design, implement and evaluate a conceptual and technological solution that captures students' movement using wearable devices and help dance teachers and students enhance their awareness and promote reflection regarding dance skills acquisition using automated personalised feedback (charts, tables, text, etc.). I will explore how to acquire movement data that can represent key aspects of social dance learning, and how to use these data to support of students and teachers. For this, I created a mobile app that records students' movement while they are practicing dance exercises and creates a dance learner model. The learner model's features are exposed through the Open Learner Model to students and their teachers in order to support reflection and increase awareness. With the proposed work I expect to generate a deeper understanding of the aspects of the dance learner model which can be used to promote personalization and adaptation, and positively impact dance learning.","automatic feedback, motor learning, wearable devices, dance education, open learner model","","UMAP '17"
"Conference Paper","Abyaa A,Idrissi MK,Bennani S","An Adult Learner's Knowledge Model Based on Ontologies and Rule Reasoning","","2017","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the Mediterranean Symposium on Smart City Application","Tangier, Morocco","2017","9781450352116","","https://doi.org/10.1145/3175628.3175656;http://dx.doi.org/10.1145/3175628.3175656","10.1145/3175628.3175656","One of the biggest challenges of Adaptive e-learning systems is learner modelling. The learner model should represent the learner's characteristics as faithfully as possible in order to provide adaptive learning. Among these characteristics, the learner's knowledge is considered to be the core characteristic of the learner model, as adaptive e-learning systems are centered on the learner's knowledge, since acquiring « knowledge » about a specific domain or concept is considered the main goal of learning and instruction. In this paper, we propose a novel adult learner's knowledge model using ontologies and rule reasoning, by trying to define the different components that construct the learner's knowledge in an exhaustive yet a simple way. The proposed model takes into account different elements of the learner's knowledge, such as the different knowledge types and categories, the learner's prior knowledge accumulated through his/her experiences, his/her misconceptions, errors and the previously learned but forgotten knowledge.","learner model, ontology, adaptive learning, rule modelling, adult learner, OWL","","SCAMS '17"
"Conference Paper","Ostrow K,Donnelly C,Adjei S,Heffernan N","Improving Student Modeling Through Partial Credit and Problem Difficulty","","2015","","","11–20","Association for Computing Machinery","New York, NY, USA","Proceedings of the Second (2015) ACM Conference on Learning @ Scale","Vancouver, BC, Canada","2015","9781450334112","","https://doi.org/10.1145/2724660.2724667;http://dx.doi.org/10.1145/2724660.2724667","10.1145/2724660.2724667","Student modeling within intelligent tutoring systems is a task largely driven by binary models that predict student knowledge or next problem correctness (i.e., Knowledge Tracing (KT)). However, using a binary construct for student assessment often causes researchers to overlook the feedback innate to these platforms. The present study considers a novel method of tabling an algorithmically determined partial credit score and problem difficulty bin for each student's current problem to predict both binary and partial next problem correctness. This study was conducted using log files from ASSISTments, an adaptive mathematics tutor, from the 2012-2013 school year. The dataset consisted of 338,297 problem logs linked to 15,253 unique student identification numbers. Findings suggest that an efficiently tabled model considering partial credit and problem difficulty performs about as well as KT on binary predictions of next problem correctness. This method provides the groundwork for modifying KT in an attempt to optimize student modeling.","student modeling, next problem correctness, problem difficulty, tabling method, knowledge tracing, partial credit","","L@S '15"
"Conference Paper","Abdi S,Khosravi H,Sadiq S","Modelling Learners in Adaptive Educational Systems: A Multivariate Glicko-Based Approach","","2021","","","497–503","Association for Computing Machinery","New York, NY, USA","LAK21: 11th International Learning Analytics and Knowledge Conference","Irvine, CA, USA","2021","9781450389358","","https://doi.org/10.1145/3448139.3448189;http://dx.doi.org/10.1145/3448139.3448189","10.1145/3448139.3448189","The Elo rating system has been recognised as an effective method for modelling students and items within adaptive educational systems. A common characteristic across Elo-based learner models is that they are not sensitive to the lag time between two consecutive interactions of a student within the system. Implicitly, this characteristic assumes that students do not learn or forget between two consecutive interactions. However, this assumption seems insufficient in the context of adaptive learning systems where students could have improved their mastery through practising outside of the system or that their mastery may be declined due to forgetting. In this paper, we extend the existing works on the use of rating systems for modelling learners in adaptive educational systems by proposing a new learner model called MV-Glicko that builds on the Glicko rating system. MV-Glicko is sensitive to the lag time between two consecutive interactions of a student within the system and models it as a parameter that captures the confidence of the system in the current inferred rating. We apply MV-Glicko on three public data sets and three data sets obtained from an adaptive learning system and provide evidence that MV-Glicko outperforms other conventional models in estimating students’ knowledge mastery.","Glicko rating system, knowledge tracing, Adaptive learning, learner modelling","","LAK21"
"Conference Paper","Tang S,McBride E,Gogel H,Pardos ZA","Item Ordering Effects with Qualitative Explanations Using Online Adaptive Tutoring Data","","2015","","","313–316","Association for Computing Machinery","New York, NY, USA","Proceedings of the Second (2015) ACM Conference on Learning @ Scale","Vancouver, BC, Canada","2015","9781450334112","","https://doi.org/10.1145/2724660.2728682;http://dx.doi.org/10.1145/2724660.2728682","10.1145/2724660.2728682","Online computer adaptive learning is increasingly being used in classrooms as a way to provide guided learning for students. Such tutors have the potential to provide tailored feedback based on specific student needs and misunderstandings. Bayesian knowledge tracing (BKT) is used to model student knowledge when knowledge is assumed to be changing throughout a single assessment period; in contrast, traditional Item Response Theory (IRT) models assume student knowledge to be constant within an assessment period. The basic BKT model assumes that the chance a student transitions from ""not knowing"" to ""knowing"" after each item is the same, and problems are considered learning opportunities. It could be the case, however, that learning is actually context sensitive, where students' learning might be improved when the items and their associated tutoring content are delivered to the student in a particular order. In this paper, we use BKT models to find such context sensitive transition probabilities from real data delivered by an online tutoring system, ASSISTments. After empirically deriving orderings that lead to better learning, we qualitatively analyze the items and their tutoring content to uncover any mechanisms that might explain why such orderings are modeled to have higher learning potential.","bayesian knowledge tracing, item difficulty, item ordering","","L@S '15"
"Conference Paper","Botelho A,Wan H,Heffernan N","The Prediction of Student First Response Using Prerequisite Skills","","2015","","","39–45","Association for Computing Machinery","New York, NY, USA","Proceedings of the Second (2015) ACM Conference on Learning @ Scale","Vancouver, BC, Canada","2015","9781450334112","","https://doi.org/10.1145/2724660.2724675;http://dx.doi.org/10.1145/2724660.2724675","10.1145/2724660.2724675","A large amount of research in the field of educational data analytics has focused primarily on student next problem correctness. Although the prediction of such information is useful in assessing current student performance, it is better for teachers and instructors to place attention on student knowledge over a longer period of time. Several researchers have articulated that it is important to predict aspects that are more meaningful, inspiring our work here to utilize the large amounts of student data available to derive more substantial predictions over student knowledge. Our goal in this paper is to utilize prerequisite information to better predict student knowledge quantitatively as a subsequent skill is begun. Learning systems like ASSISTments and Khan Academy already record such prerequisite information, and can therefore be used to construct a method of prediction as described in this paper. Using these inter-skill relationships, our method estimates students' initial knowledge based on performance on each prerequisite skill. We compare our method with the standard Knowledge Tracing (KT) model and majority class in terms of the predictive accuracy of students' first responses on subsequent skills. Our results support our method as a viable means of representing student prerequisite knowledge in a subsequent skill, leading to results that outperform the majority class and that are comparably superior to KT by providing more definitive student knowledge estimates without sacrificing predictive accuracy.","initial knowledge, first response prediction, subsequent skills, prerequisite, predicting student knowledge, mastery speed, knowledge tracing","","L@S '15"
"Conference Paper","Gusukuma L,Bart AC,Kafura D,Ernst J","Misconception-Driven Feedback: Results from an Experimental Study","","2018","","","160–168","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2018 ACM Conference on International Computing Education Research","Espoo, Finland","2018","9781450356282","","https://doi.org/10.1145/3230977.3231002;http://dx.doi.org/10.1145/3230977.3231002","10.1145/3230977.3231002","The feedback given to novice programmers can be substantially improved by delivering advice focused on learners' cognitive misconceptions contextualized to the instruction. Building on this idea, we present Misconception-Driven Feedback (MDF); MDF uses a cognitive student model and program analysis to detect mistakes and uncover underlying misconceptions. To evaluate the impact of MDF on student learning, we performed a quasi-experimental study of novice programmers that compares conventional run-time and output check feedback against MDF over three semesters. Inferential statistics indicates MDF supports significantly accelerated acquisition of conceptual knowledge and practical programming skills. Additionally, we present descriptive analysis from the study indicating the MDF student model allows for complex analysis of student mistakes and misconceptions that can suggest improvements to the feedback, the instruction, and to specific students.","misconception, immediate feedback, student model, cs education","","ICER '18"
"Conference Paper","Bhatt S,Zhao J,Thille C,Zimmaro D,Gattani N","A Novel Approach for Knowledge State Representation and Prediction","","2020","","","353–356","Association for Computing Machinery","New York, NY, USA","Proceedings of the Seventh ACM Conference on Learning @ Scale","Virtual Event, USA","2020","9781450379519","","https://doi.org/10.1145/3386527.3406745;http://dx.doi.org/10.1145/3386527.3406745","10.1145/3386527.3406745","Online learning systems with open navigation allow learners to select the next learning activity in order to achieve desired mastery. To help learners make an informed choice regarding the next learning activity, we propose to represent and communicate the learner's knowledge state as the average success rate in the course for each skill, rather than as the probability of correctly answering the next question. We first show that we can accurately estimate the proposed knowledge state. We then show that the proposed attention-based model to estimate the knowledge state requires fewer parameters, provides actionable information to the learners, and achieves equivalent or better accuracy compared to RNN (Recurrent Neural Network) based models.","knowledge state, knowledge tracing, attention based knowledge tracing.","","L@S '20"
"Conference Paper","Abyaa A,Idrissi MK,Bennani S","Predicting the Learner's Personality from Educational Data Using Supervised Learning","","2018","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 12th International Conference on Intelligent Systems: Theories and Applications","Rabat, Morocco","2018","9781450364621","","https://doi.org/10.1145/3289402.3289519;http://dx.doi.org/10.1145/3289402.3289519","10.1145/3289402.3289519","Differences in the learners' personality have an impact on their learning outcomes and achievements. Therefore, there is a need to automatically predict and identify their personalities in an unobtrusive way, and build the learner model accordingly. In this paper, we try to identify the learner's personality dimensions, according to the big five personality model, using educational data features in order to develop an automatic classifier that predicts the learner's personality discreetly based on his/her traces in an online learning system. We applied seven different supervised learning classification algorithms, using personality scores for each dimension (high or low) as target values, and analyzed the results. The findings were encouraging and revealed that most of Big Five personality dimensions can in fact be predicted using mainly educational data features, which could have an added value on unobtrusive dynamic learner modelling.","Adaptive learning, learner model, personality, big five, supervised learning","","SITA'18"
"Conference Paper","Ramírez Luelmo SI,El Mawas N,Heutte J","Towards Open Learner Models Including the Flow State","","2020","","","305–310","Association for Computing Machinery","New York, NY, USA","Adjunct Publication of the 28th ACM Conference on User Modeling, Adaptation and Personalization","Genoa, Italy","2020","9781450379502","","https://doi.org/10.1145/3386392.3399295;http://dx.doi.org/10.1145/3386392.3399295","10.1145/3386392.3399295","Lifelong Learning encompasses vast learning opportunities and MOOCs are a learning environment that can be up to the challenge if current modeling challenges are addressed. Studies have shown the importance of modeling the learner for a more personal and tailored learning experience in MOOC. Furthermore, Open Learner Models have proven their added value in facilitating learner's follow-up and course content personalization. However, while modeling the learner's knowledge is a common practice, modeling the learner's psychological state is a relegated concern within the community. This is despite the myriad of scientific evidence backing up the importance and repercussion of the learner's psychological state during and on the learning process.Flow is a psychological state characterized by total immersion in a task and a state of optimal performance. Programmers often refer to it as ""being in the zone"". It reliably correlates favorable learning metrics, such as motivation and engagement, among others. The aim of this paper is to propose a functional and technical architecture (comprising a Domain Model, a Flow Model, and an Open Learner Model for MOOC in a Lifelong Learning context) accounting for the learner's Flow state. This work is dedicated to MOOC designers/providers, pedagogical engineers, psychology, and education researchers who meet difficulties to incorporate and account for the Flow psychological state in a MOOC.","learner model, flow state, domain model, autotelic experience, lifelong learning, MOOC","","UMAP '20 Adjunct"
"Conference Paper","Durán E,Amandi A","Collaborative Student Profile to Support Assistance in CSCL Environment","","2008","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2008 Euro American Conference on Telematics and Information Systems","Aracaju, Brazil","2008","9781595939883","","https://doi.org/10.1145/1621087.1621125;http://dx.doi.org/10.1145/1621087.1621125","10.1145/1621087.1621125","An effective collaboration in learning environments involves a set of skills that students must learn and cultivate. Detecting the contexts in which students apply these skills allows learning environments to offer personalized assistance during the learning process. In this paper a Collaborative Profile, as part of a student model, is introduced. This profile captures collaborative skills of a student working in a group. To build the Collaborative Profile a Web Usage Mining Approach is applied and collaborative behaviour patterns are detected automatically, identifying contexts in which student's skills are evident. This profile is designed to offer additional information to improve personalized assistance in collaborative learning environment.","student model, collaborative learning, personalization, collaborative skills, distance learning","","EATIS '08"
"Conference Paper","Roijers DM,Jeuring J,Feelders A","Probability Estimation and a Competence Model for Rule Based E-Tutoring Systems","","2012","","","255–258","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2nd International Conference on Learning Analytics and Knowledge","Vancouver, British Columbia, Canada","2012","9781450311113","","https://doi.org/10.1145/2330601.2330663;http://dx.doi.org/10.1145/2330601.2330663","10.1145/2330601.2330663","In this paper, we present a student model for rule based e-tutoring systems. This model describes both properties of rewrite rules (difficulty and discriminativity) and of students (start competence and learning speed). The model is an extension of the two-parameter logistic ogive function of Item Response Theory. We show that the model can be applied even to relatively small datasets. We gather data from students working on problems in the logic domain, and show that the model estimates of rule difficulty correspond well to expert opinions. We also show that the estimated start competence corresponds well to our expectations based on the previous experience of the students in the logic domain. We point out that this model can be used to inform students about their competence and learning, and teachers about the students and the difficulty and discriminativity of the rules.","data mining, learning analytics, student model","","LAK '12"
"Conference Paper","Bouarab-Dahmani F,Si-Mohammed M,Comparot C,Charrel PJ","Learners Automated Evaluation with the ODALA Approach","","2009","","","98–103","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2009 ACM Symposium on Applied Computing","Honolulu, Hawaii","2009","9781605581668","","https://doi.org/10.1145/1529282.1529303;http://dx.doi.org/10.1145/1529282.1529303","10.1145/1529282.1529303","We present in this paper ODALA approach (Ontology-Driven Auto-evaluation for e-Learning Approach) for an automated evaluation of the learners state of knowledge. The context considered is Computer Based Human Learning Environnement (CBHLE) in a self-learning by doing mode. This approach, that we put in work and test in the setting of a self-learning system for an algorithmic language, is founded on the representation of the teaching domain as domain ontology on the one hand and on errors classification and detection on the other hand. The evaluation process that we recommend is structured in four stages, starting from the learner solution form analysis (that consists at this step of our research to a lexico-syntactic analysis) and finish with the update of the learner model, while passing by a semantic analysis and a marking process.After a brief introduction of the main aspects raising of the CBHLE domain to which we refer here, we develop our approach of the learners evaluation problem, while especially insisting on its independence of the teaching domain and on the possibility to take in account answers to open questions, freely built by the learner. We also present, at the end, the results of the algorithmic self-learning system development, where the main stages of our evaluation approach are implemented.","self-learning, evaluation, learner model, error diagnosis, learners marking, distant learning","","SAC '09"
"Conference Paper","Zimmerman NL,Baker RS","Mining Knowledge Components from Many Untagged Questions","","2017","","","566–567","Association for Computing Machinery","New York, NY, USA","Proceedings of the Seventh International Learning Analytics & Knowledge Conference","Vancouver, British Columbia, Canada","2017","9781450348706","","https://doi.org/10.1145/3027385.3029462;http://dx.doi.org/10.1145/3027385.3029462","10.1145/3027385.3029462","An ongoing study is being run to ensure that the McGraw-Hill Education LearnSmart platform teaches students as efficiently as possible. The first step in doing so is to identify what Knowledge Components (KCs) exist in the content; while the content is tagged by experts, these tags need to be re-calibrated periodically.LearnSmart courses are organized into chapters corresponding to those found in a textbook; each chapter can have anywhere from about a hundred to a few thousand questions. The KC extraction algorithms proposed by Barnes [1] and Desmarais et al [3] are applied on a chapter-by-chapter basis. To assess the ability of each mined q matrix to describe the observed learning, the PFA model of Pavlik et al [4] is fitted to it and a cross-validated AUC is calculated. The models are assessed based on whether PFA's predictions of student correctness are accurate.Early results show that both algorithms do a reasonable job of describing student progress, but q matrices with very different numbers of KCs fit observed data similarly well. Consequently, further consideration is required before automated extraction is practical in this context.","knowledge components, data mining, knowledge tracing","","LAK '17"
"Conference Paper","Van Der Lubbe L,Van Borkulo S","The Design of a High School Computer Science Learning Platform Based on Student Modelling: Facilitating Classes without a Qualified Computer Science Teacher in the Netherlands","","2023","","","59–61","Association for Computing Machinery","New York, NY, USA","Proceedings of the 11th Computer Science Education Research Conference","Leiden, Netherlands","2023","9781450397476","","https://doi.org/10.1145/3569173.3569182;http://dx.doi.org/10.1145/3569173.3569182","10.1145/3569173.3569182","Dutch secundary schools struggle to find computer science teachers, and employed computer science teachers are retiring. Co-Teach Informatica facilitates computer science education for schools that do not have a qualified teacher. To facilitate their education, an innovative learning platform will be developed. Aside from offering learning materials, exercises and communication with teaching assistants, the platform will support learners and teachers by giving them insight in the learning progress of the learners. Using a knowledge graph with connected learning goals and activities, a student model can be build. This poster introduces the design and research plans for this project. The first experiment will take place in the beginning of 2023, when high school learners will use a prototype of the platform for multiple weeks.","computer science, secundary education, student model, learning platform","","CSERC '22"
"Conference Paper","Liu D,Qu X,Dong J,Nan G,Zhou P,Xu Z,Chen L,Yan H,Cheng Y","Filling the Information Gap between Video and Query for Language-Driven Moment Retrieval","","2023","","","4190–4199","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st ACM International Conference on Multimedia","Ottawa ON, Canada","2023","","","https://doi.org/10.1145/3581783.3612038;http://dx.doi.org/10.1145/3581783.3612038","10.1145/3581783.3612038","This paper addresses the challenging task of language-driven moment retrieval. Previous methods are typically trained to localize the target moment corresponding to a single sentence query in a complicated video. However, this specific moment generally delivers richer contents than the query, i.e., the semantics of one query may miss certain object details or actions in the complex foreground-background visual contents. Such information imbalance between two modalities makes it difficult to finely align their representations. To this end, instead of training with a single query, we propose to utilize the diversity and complementarity among different queries corresponding to the same video moment for enriching the textual semantics. Specifically, we develop a Teacher-Student Moment Retrieval (TSMR) framework to fill this cross-modal information gap. A teacher model is trained to not only encode a certain query but also capture extra complementary queries to aggregate contextual semantics for obtaining more comprehensive moment-related query representations. Since the additional queries are inaccessible during inference, we further introduce an adaptive knowledge distillation mechanism to train a student model with a single query input by selectively absorbing the knowledge from the teacher model. In this manner, the student model is more robust to the cross-modal information gap during the moment retrieval guided by a single query. Experimental results on two benchmarks demonstrate the effectiveness of our proposed method.","teacher-student model, language-driven moment retrieval, information imbalance","","MM '23"
"Conference Paper","Dias Pereira dos Santos A,Yacef K,Martinez-Maldonado R","Let's Dance: How to Build a User Model for Dance Students Using Wearable Technology","","2017","","","183–191","Association for Computing Machinery","New York, NY, USA","Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization","Bratislava, Slovakia","2017","9781450346351","","https://doi.org/10.1145/3079628.3079673;http://dx.doi.org/10.1145/3079628.3079673","10.1145/3079628.3079673","Motor skill learning is an area where wearable technology and user modelling can be synergistically combined for providing support. In this paper, we explore how a simple accelerometer sensor can be used to capture motion data associated with critical aspects of learning in the context of social dancing. We developed a prototype mobile app that tracks students' motion data whilst they practise dance exercises. This paper describes a set of features, such as rhythm duration, consistency and body motion, which can be automatically tracked and included into a dance student model. These dancing features can be presented back to the students as feedback, in the form of i) summaries, ii) visualisations or iii) narratives. We illustrate the feasibility and potential of modelling these features through a study with beginner students taking dance classes during three weeks.","open learner model, motor learning, wearable devices, dance education, automatic feedback","","UMAP '17"
"Conference Paper","Seffrin HM,Rubi GL,Jaques PA","A Dynamic Bayesian Network for Inference of Learners' Algebraic Knowledge","","2014","","","235–240","Association for Computing Machinery","New York, NY, USA","Proceedings of the 29th Annual ACM Symposium on Applied Computing","Gyeongju, Republic of Korea","2014","9781450324694","","https://doi.org/10.1145/2554850.2555062;http://dx.doi.org/10.1145/2554850.2555062","10.1145/2554850.2555062","An Intelligent Tutoring System (ITS) is an educational software that provides personal assistance for students, allowing them to learn at their own pace. This is possible because ITSs are able to map the learners' knowledge to create a student model. Most of the tutors use a Bayesian Network (BN) to perform this task, due to their ability to deal with uncertain data. However, classic static BNs are unable to model data, such as the student's knowledge, that changes over time. Dynamic Bayesian Networks (DBN) are an interesting option in this case, because they are a special type of BN that reasons over time. This paper presents an architecture of DBN that aims at inferring student's algebraic knowledge. This network was constructed based on a concept map, which was developed with the goal of structuring the algebraic knowledge, i. e. defining relationships among concepts. The proposed DBN was evaluated with the help of an expert in order to verify the ability of the network to predict the student's knowledge on the application of operations to solve 1st degree equations. This DBN is being integrated into an web-based ITS for algebra learning.","intelligent tutoring system, algebra, student model, dynamic bayesian network","","SAC '14"
"Conference Paper","Al-Rajhi L,Salama R,Gamalel-Din S","Personalized Intelligent Assessment Model for Measuring Initial Students Abilities","","2014","","","41–48","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2014 Workshop on Interaction Design in Educational Environments","Albacete, Spain","2014","9781450330343","","https://doi.org/10.1145/2643604.2643606;http://dx.doi.org/10.1145/2643604.2643606","10.1145/2643604.2643606","In adaptive e-learning systems attention is focused on adjusting the learning material to the needs of the individual student. There are differences in the properties of each individual such as differences in skills, prior knowledge, ... etc. These characteristics must be measured to display the content that is suitable to individual needs of student. There are different e-assessment models that are appropriate for discovering the prior knowledge and skills. The main objective of this research is to build an e-assessment model for Personal and Intelligent Assessment using Test (PIAT) to facilitate the evaluation process and measure the students' proficiency with more accuracy and store it in the student's profile for later use in the process of adapting content material to individual student needs. On one hand the model can help the instructors to develop the test by determining the objectives, creation and reuse of the test items. On the other hand the model can provide a personal test environment to the student. It generates the appropriate questions in an adaptive way, based on the student's model. The PIAT model is based on two theories. The first theory is Revised Bloom's Taxonomy (RBT) and the second theory is Felder-Silverman Learning Style Model (FSLSM).","Computer Based Testing, Student Model, Learning Styles, Bloom's Taxonomy, Personalized Intelligent Assessment","","IDEE '14"
"Conference Paper","Barria-Pineda J,Guerra J,Huang Y,Brusilovsky P","Concept-Level Knowledge Visualization For Supporting Self-Regulated Learning","","2017","","","141–144","Association for Computing Machinery","New York, NY, USA","Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion","Limassol, Cyprus","2017","9781450348935","","https://doi.org/10.1145/3030024.3038262;http://dx.doi.org/10.1145/3030024.3038262","10.1145/3030024.3038262","Mastery Grids is an intelligent interface that provides access to different kinds of practice content for an introductory programming course. A distinctive feature of the interface is a parallel topic-level visualization of student progress and the progress of their peers. This contribution presents an extended version of the original system that features a fine-grained visualization of student knowledge on the level of the detailed concepts that are associated with the course. The student model is based on a Bayesian-network which is built using students performance history in the learning activities.","open student model, information visualization, student modeling, social comparison, competency visualization","","IUI '17 Companion"
"Conference Paper","Qu D,Wu S","A Competition-Oriented Student Team Building Method","","2019","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM Turing Celebration Conference - China","Chengdu, China","2019","9781450371582","","https://doi.org/10.1145/3321408.3322859;http://dx.doi.org/10.1145/3321408.3322859","10.1145/3321408.3322859","There are plenty of important academic competitions, but traditional student team building ways usually only rely on some first-class students or have strong randomness. To choose more appropriate students and improve overall students' ability, we propose a competition-oriented student team building method. We first construct a campus big data platform to collect students' behavior data, including students' theory behavior and practice behavior. It can also collect the competition data. We second model competitions and students with a six-tuple property based on the data from the platform respectively. A corresponding utility function is then designed for each property in student's model to denote the student's income in this property for attending a competition. Furthermore, a team utility function is developed to denote the income of all involved students. Finally, we apply PSO to build appropriate teams which maximizes the student utility and team utility. Experiment Results demonstrate that our proposed method has better performance, in terms of team utility and student ability, than other methods. Moreover, it balances the difference of the whole students' ability.","utility function, competition model, team building, student model","","ACM TURC '19"
"Conference Paper","Mostafavi B,Eagle M,Barnes T","Towards Data-Driven Mastery Learning","","2015","","","270–274","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fifth International Conference on Learning Analytics And Knowledge","Poughkeepsie, New York","2015","9781450334174","","https://doi.org/10.1145/2723576.2723622;http://dx.doi.org/10.1145/2723576.2723622","10.1145/2723576.2723622","We have developed a novel data-driven mastery learning system to improve learning in complex procedural problem solving domains. This new system was integrated into an existing logic proof tool, and assigned as homework in a deductive logic course. Student performance and dropout were compared across three systems: The Deep Thought logic tutor, Deep Thought with integrated hints, and Deep Thought with our data-driven mastery learning system. Results show that the data-driven mastery learning system increases mastery of target tutor-actions, improves tutor scores, and lowers the rate of tutor dropout over Deep Thought, with or without provided hints.","knowledge tracing, data-driven mastery learning, problem selection, logic proof","","LAK '15"
"Conference Paper","Espinosa ML,Sánchez NM,García Valdivia ZZ","Concept Maps and Case-Based Reasoning: A Perspective for the Intelligent Teaching/Learning Systems","","2007","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2007 Euro American Conference on Telematics and Information Systems","Faro, Portugal","2007","9781595935984","","https://doi.org/10.1145/1352694.1352697;http://dx.doi.org/10.1145/1352694.1352697","10.1145/1352694.1352697","The use of present pedagogical methods and Information and Communication Technologies produce a new quality that favors the task of generating, transmitting and sharing knowledge. That is the case of the pedagogical effect that produces the use of the Concept Maps, which are considered a learning technique as a way to increase meaningful learning in the sciences. It is also used for the knowledge management as an aid to personalize the learning process, to exchange knowledge, and to learn how to learn. Concept Mapping provides a framework for making this internal knowledge explicit in a visual form that can easily be examined and shared. Concept Maps are relevant since they can be retrieved or adapted to new problems. In the other hand, Case-Based Reasoning as a technique in Artificial Intelligence plays an important role in knowledge retrieval and reuse of memories. In this paper the authors present a new approach to elaborate Intelligent Teaching/Learning Systems, where the techniques of Concept Maps and Artificial Intelligence are combined, using the Case-Based Reasoning as theoretical framework for the Student Model. The proposed model has been implemented in the computational system HESEI, which has been successfully used in the teaching/learning process by laymen in the Computer Science field.","case based reasoning, concept maps, student model, intelligent teaching/learning systems","","EATIS '07"
"Conference Paper","Gamalel-Din SA","An Intelligent Etutor-Student Adaptive Interaction Framework","","2012","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 13th International Conference on Interacción Persona-Ordenador","Elche, Spain","2012","9781450313148","","https://doi.org/10.1145/2379636.2379648;http://dx.doi.org/10.1145/2379636.2379648","10.1145/2379636.2379648","Many educators believe that the most effective means for teaching is through one-on-one interactions with students. This research's hypothesis is that better learning results would be achieved by adapting the e-tutor interaction with its individual student user. eTutor-Student interaction in this research is based on adapting the content and presentation of the learning material to the student based on his/her learning model---The student model. In other words, eTutor should adapt and personalize the teaching strategy for each student; something that is not easy to achieve without the aid of an intelligent system with a comprehensive knowledgebase. This article presents one essential component of our research on adaptive e-learning---namely, a framework of a Smart Cognitive Augmented Learning Object Repository (SCALOR) engine that augments the concepts of learning styles onto Hypermedia Learning Objects, which together with a Smart domain knowledge ontology compose the Smart e-Learning Knowledgebase (SELK). SELK is at the core of the personalization of the eTutor-Student interaction for a more efficient and effective learning process. Evaluation results for this framework proved the hypothesis.","cognitive model, adaptive e-learning, learning style, student model, etutor-student interaction, domain ontology","","INTERACCION '12"
"Conference Paper","Ma B,Hettiarachchi GP,Fukui S,Ando Y","Each Encounter Counts: Modeling Language Learning and Forgetting","","2023","","","79–88","Association for Computing Machinery","New York, NY, USA","LAK23: 13th International Learning Analytics and Knowledge Conference","Arlington, TX, USA","2023","9781450398657","","https://doi.org/10.1145/3576050.3576062;http://dx.doi.org/10.1145/3576050.3576062","10.1145/3576050.3576062","Language learning applications usually estimate the learner’s language knowledge over time to provide personalized practice content for each learner at the optimal timing. However, accurately predicting language knowledge or linguistic skills is much more challenging than math or science knowledge, as many language tasks involve memorization and retrieval. Learners must memorize a large number of words and meanings, which are prone to be forgotten without practice. Although a few studies consider forgetting when modeling learners’ language knowledge, they tend to apply traditional models, consider only partial information about forgetting, and ignore linguistic features that may significantly influence learning and forgetting. This paper focuses on modeling and predicting learners’ knowledge by considering their forgetting behavior and linguistic features in language learning. Specifically, we first explore the existence of forgetting behavior and cross-effects in real-world language learning datasets through empirical studies. Based on these, we propose a model for predicting the probability of recalling a word given a learner’s practice history. The model incorporates key information related to forgetting, question formats, and semantic similarities between words using the attention mechanism. Experiments on two real-world datasets show that the proposed model improves performance compared to baselines. Moreover, the results indicate that combining multiple types of forgetting information and item format improves performance. In addition, we find that incorporating semantic features, such as word embeddings, to model similarities between words in a learner’s practice history and their effects on memory also improves the model.","Knowledge tracing, Forgetting behavior, Language learning, Educational data mining","","LAK2023"
"Conference Paper","Maestro-Prieto JA,Simon-Hurtado A","The Pedagogical Model of SIAL: An Adaptive and Open-Ended Intelligent Tutoring System for First Order Logic","","2018","","","21–26","Association for Computing Machinery","New York, NY, USA","Proceedings of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education","Larnaca, Cyprus","2018","9781450357074","","https://doi.org/10.1145/3197091.3197100;http://dx.doi.org/10.1145/3197091.3197100","10.1145/3197091.3197100","This paper describes the Pedagogical Model of an Intelligent Tutoring System (ITS) for learning Computational Logic: SIAL. This ITS teaches classical refutation by resolution concepts. SIAL is a Model-Based System as its Domain Model is an Automated Theorem Prover (ATP) for First Order Logic (FOL). This allows SIAL to perform an accurate error diagnosis process while, at the same time, accepting several equivalent valid solutions to the same problem. This feature adds a general open-ended solution capability to SIAL which facilitates the adaptation to the students' way of thinking and allows them to explore and take their own decisions (and make their own mistakes). The Pedagogical Model of SIAL takes advantage of the error diagnosis capabilities of the Domain Model to offer a learner-adaptive tutorial action, according to the user cognitive profile. An example of the knowledge involved in the assessment of the next tutorial action based on the student model, and how SIAL adapts its behaviour to the student's assessed cognitive capabilities, is included. Some data obtained after a period of use of SIAL is also presented.","Student Model, First Order Logic, Intelligent Tutoring System, Pedagogical Model, Artificial Intelligence","","ITiCSE 2018"
"Conference Paper","Schodde T,Kopp S","Adaptive Robot Second Language Tutoring for Children","","2018","","","317–318","Association for Computing Machinery","New York, NY, USA","Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","Chicago, IL, USA","2018","9781450356152","","https://doi.org/10.1145/3173386.3176906;http://dx.doi.org/10.1145/3173386.3176906","10.1145/3173386.3176906","Empirical evidence has demonstrated that learning with and from a physically present, interactive robot can be more effective than learning from classical on-screen media [6, 8]. In the L2TOR project wework on using the robot Nao to support second language learning, a problem that becomes increasingly important nowadays.We focus on preschool children in the age of 5-6yr, for whom it is crucial to develop adequate knowledge of the academic language as later educational success builds on it [4, 7].","assistive robotics, knowledge tracing, education, predictive decision making, language tutoring","","HRI '18"
"Conference Paper","Zhao J,Thille C,Zimmaro D","Data Mining for Discovering Cognitive Models of Learning","","2022","","","130–139","Association for Computing Machinery","New York, NY, USA","Proceedings of the 5th International Conference on Advances in Artificial Intelligence","Virtual Event, United Kingdom","2022","9781450390699","","https://doi.org/10.1145/3505711.3505729;http://dx.doi.org/10.1145/3505711.3505729","10.1145/3505711.3505729","A cognitive model is a descriptive account or computational representation of human thinking about a given concept, skill, or domain. A cognitive model of learning, includes both a way of organizing knowledge within a subject area and an account of how humans develop accurate and complete knowledge of that subject area. Learning designers engage in a variety of practices to unpack knowledge from subject matter experts and novices to develop cognitive models of learning and use those models to guide the design of instruction or instructional technologies. Traditional approaches to eliciting and organizing knowledge, such as conducting a cognitive task analysis (CTA) [14] with experts and novices, are labor-intensive and require specific expertise that many learning designers do not have. However, learning data generated from learners’ interaction with courses, can provide insight into how humans think and develop knowledge. As a continued effort, we extend the framework presented in our earlier work [17] to discover and refine cognitive models of learning with learning data. The framework includes 1. a Variational Autoencoder (VAE) and a Gaussian Mixture Model (GMM) that models and clusters cognitive learning patterns; 2. a multidimensional measure that quantifies validity and reliability of the discovered cognitive models of learning; 3. a topic-based solution that interprets the cognitive models from a linguistic perspective; and 4. a simulation-based analysis for both accuracy measures and course refinement insights. We demonstrate the end-to-end solution with two applications and four case studies that are deployed in an openly navigated learning system in a workforce learning environment. We also report the usefulness of the discovered cognitive models of learning with subject matter expert evaluation.","human-computer interaction, cognitive model of learning, knowledge tracing, natural language processing, behavior modeling","","ICAAI '21"
"Journal Article","Liu S,Liu S,Yang Z,Sun J,Shen X,Li Q,Zou R,Du S","Heterogeneous Evolution Network Embedding with Temporal Extension for Intelligent Tutoring Systems","ACM Trans. Inf. Syst.","2023","","","","Association for Computing Machinery","New York, NY, USA","","","2023-08","","1046-8188","https://doi.org/10.1145/3617828;http://dx.doi.org/10.1145/3617828","10.1145/3617828","Graph embedding (GE) aims to acquire low-dimensional node representations while maintaining the graph’s structural and semantic attributes. Intelligent tutoring systems (ITS) signify a noteworthy achievement in the fusion of AI and education. Utilizing GE to model ITS can elevate their performance in predictive and annotation tasks. Current GE techniques, whether applied to heterogeneous or dynamic graphs, struggle to efficiently model ITS data. The GEs within ITS should retain their semidynamic, independent, and smooth characteristics. This paper introduces a heterogeneous evolution network (HEN) for illustrating entities and relations within an ITS. Additionally, we introduce a temporal extension graph neural network (TEGNN) to model both evolving and static nodes within the HEN. In the TEGNN framework, dynamic nodes are initially improved over time through temporal extension (TE), providing an accurate depiction of each learner’s implicit state at each time step. Subsequently, we propose a stochastic temporal pooling (STP) strategy to estimate the embedding sets of all evolving nodes. This effectively enhances model efficiency and usability. Following this, a heterogeneous aggregation network is devised to proficiently extract heterogeneous features from the HEN. This network employs both node-level and relation-level attention mechanisms to craft aggregated node features. To emphasize the superiority of TEGNN, we perform experiments on several real ITS datasets and show that our method significantly outperforms the state-of-the-art approaches. The experiments validate that TE serves as an efficient framework for modeling temporal information in GE, and STP not only accelerates the training process but also enhances the resultant accuracy.","knowledge tracing, heterogeneous information network, intelligent education, dynamic graph, graph embedding","Just Accepted",""
"Conference Paper","Guerra J","Open Social Learner Models for Self-Regulated Learning and Learning Motivation","","2016","","","329–332","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization","Halifax, Nova Scotia, Canada","2016","9781450343688","","https://doi.org/10.1145/2930238.2930375;http://dx.doi.org/10.1145/2930238.2930375","10.1145/2930238.2930375","Open Learner Models (OLM) have demonstrated a multitude of benefits supporting metacognition and engaging learners. Although researchers have study different representations of OLM, a broader view that situates OLM in Self-Regulated Learning (SRL) is missing. An important element in SRL that can bring a better understanding of these tools and their effects concerns to learning motivation theories. In this work I connect these aspects and propose to study the effects of OLM and motivational factors drawn from learning motivation theories. To account for a broader spectrum of OLM representations, I proposed to explore the addition of social information and different levels of granularity in the OLM. I propose to evaluate different designs and then to evaluate the resulting interface in field studies. With the proposed work I expect to gain a deeper understanding of the effects of OLM tools which can be used to guide the development of better tools, better personalization and adaptive mechanisms, better use of such tools in supporting Self-Regulated Learning, and ultimately impact positively in learning.","learning motivation, open learner model","","UMAP '16"
"Conference Paper","Brusilovsky P","Intelligent Interfaces for Open Social Student Modeling","","2017","","","1","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2017 ACM Workshop on Intelligent Interfaces for Ubiquitous and Smart Learning","Limassol, Cyprus","2017","9781450349048","","https://doi.org/10.1145/3038535.3038545;http://dx.doi.org/10.1145/3038535.3038545","10.1145/3038535.3038545","In this talk I will introduce the emerging technology of Open Social Student Modeling (OSSM) and review several projects performed in our research lab to investigate the potential of OSSM. OSSM is a recent extension of Open Student Modeling (OSM), a popular technology in the area of personalized learning systems. While in traditional personalized systems, student models were hidden ""under the hood"" and used to personalize the educational process; open student modeling introduced the ability to view and modify the state of students' own knowledge to support reflection, self-organized learning, and system transparency. Open Social Student Modeling takes this idea one step further by allowing students to explore each other's models or an aggregated model of the class. The idea to make OSM social was originally suggested and explored by Bull [1; 2]. Over the last few years, our team explored several approaches to present OSSM in a highly visual form and evaluated these approaches in a sequence of classroom and lab studies. I will present a summary of this work introducing such systems as QuizMap [3], Progressor [4], and Mastery Grids [5] and reviewing most interesting research evidence collected by the studies.","student model, open student model, personalized learning","","SmartLearn '17"
"Conference Paper","Lin C,Shen S,Chi M","Incorporating Student Response Time and Tutor Instructional Interventions into Student Modeling","","2016","","","157–161","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization","Halifax, Nova Scotia, Canada","2016","9781450343688","","https://doi.org/10.1145/2930238.2930291;http://dx.doi.org/10.1145/2930238.2930291","10.1145/2930238.2930291","Bayesian Knowledge Tracing (BKT) is one of the most widely adopted student-modeling methods. It uses performance (incorrect,correct) to infer student knowledge state (unlearned, learned). However, performance can be noisy and thus we explored another type of observations -- student response time. Furthermore, we proposed Intervention Bayesian Knowledge Tracing (Intervention-BKT) which can incorporate multiple types of instructional interventions into the conventional BKT model. Our results show that for next-step performance predictions, Intervention-BKT is more effective than BKT; whereas to predict students' post-test scores, including student response time would yield better result than using performance alone.","hidden Markov model, student modeling, input output hidden Markov model, response time","","UMAP '16"
"Conference Paper","Andaloussi KS,Capus L,Berrada I","Adaptive Educational Hypermedia Systems: Current Developments and Challenges","","2017","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2nd International Conference on Big Data, Cloud and Applications","Tetouan, Morocco","2017","9781450348522","","https://doi.org/10.1145/3090354.3090448;http://dx.doi.org/10.1145/3090354.3090448","10.1145/3090354.3090448","E-learning systems represent an interesting alternative to procure students appropriate customized instruction. Among these systems, adaptive educational hypermedia systems offer a personalized learning that is considered as the activation key of learners motivation, allowing them to learn more efficiently. The numerous existing systems generally integrate three models: learner, domain and adaptation. But, how are these models built and what are the challenges for designers and developers? To answer this question, a study of 50 adaptive educational hypermedia systems was conducted, by comparing each of the three models. This paper presents the results of these comparisons and discusses them. Limits are also highlighted and some avenues of solution are proposed. This is the first step of a research work aimed at offering directions for developing new systems that better meet learners' needs.","domain model, Educational hypermedia system, learner model, adaptation","","BDCA'17"
"Conference Paper","Shah A,Liu J,Stephens-Martinez K,Rodger SH","The CS1 Reviewer App: Choose Your Own Adventure or Choose for Me!","","2021","","","331–337","Association for Computing Machinery","New York, NY, USA","Proceedings of the 26th ACM Conference on Innovation and Technology in Computer Science Education V. 1","Virtual Event, Germany","2021","9781450382144","","https://doi.org/10.1145/3430665.3456333;http://dx.doi.org/10.1145/3430665.3456333","10.1145/3430665.3456333","We present the CS1 Reviewer App - an online tool for an introductory Python course that allows students to solve customized problem sets on many concepts in the course. Currently, the app's questions focus on code tracing by presenting a block of Python code and asking students to predict the output of the code. The tool tracks a student's response history to maintain a ""mastery level"" that represents a student's knowledge of a concept. We also provide an option of answering auto-generated quizzes based on the student's mastery across concepts. As a result, the tool provides students a choice between creating their own learning experience or leveraging our question selection algorithm. The app is supported on traditional webpages and mobile devices, providing a convenient way for students to study a variety of concepts. Students in the CS1 course at Duke University used this tool during the Spring and Fall 2020 semesters. In this paper, we explore trends in usage, feedback and suggestions from students, and avenues of future work based on student experiences.","auto-generated questions, intelligent tutoring system, adaptive learning, auto-generated quizzes, CS1, knowledge tracing","","ITiCSE '21"
"Conference Paper","El Zein D,da Costa Pereira C","User’s Knowledge and Information Needs in Information Retrieval Evaluation","","2022","","","170–178","Association for Computing Machinery","New York, NY, USA","Proceedings of the 30th ACM Conference on User Modeling, Adaptation and Personalization","Barcelona, Spain","2022","9781450392075","","https://doi.org/10.1145/3503252.3531325;http://dx.doi.org/10.1145/3503252.3531325","10.1145/3503252.3531325","The existing evaluation measures for information retrieval algorithms still lack awareness about the user’s cognitive aspects and their dynamics. They often consider an isolated query-document environment and ignore the user’s previous knowledge and his/her motivation behind the query. The retrieval algorithms and evaluation measures that account for those factors limit the result’s relevance to one search session, one query, or one search goal. We present a novel evaluation measure that overcomes this limitation. The framework measures the relevance of a result/document by examining its content and assessing the possible learning outcomes, for a specific user. Hence not all documents are relevant to all users. The proposed evaluation measure rewards the results’ content for their novelty with respect to what the user already knows and what has been previously proposed. The results are also rewarded for their contribution to achieving the search goals/needs. We demonstrate the efficiency of the measure by comparing it to the knowledge gain reported by 361 crowd-sourced users searching the Web across 10 different topics.","Evaluation, Personalisation, Knowledge Delta, Search goals, Knowledge Tracing, Knowledge Acquisition, Search as Learning","","UMAP '22"
"Conference Paper","Ziegenbein N,Friedman J,Moringen A","Monitoring the Learning Progress in Piano Playing with Hidden Markov Models","","2022","","","335–341","Association for Computing Machinery","New York, NY, USA","Adjunct Proceedings of the 30th ACM Conference on User Modeling, Adaptation and Personalization","Barcelona, Spain","2022","9781450392327","","https://doi.org/10.1145/3511047.3537666;http://dx.doi.org/10.1145/3511047.3537666","10.1145/3511047.3537666","Monitoring a learner’s performance during practice plays an important role in scaffolding. It helps with scheduling suitable practice exercises and, by doing so, sustains learner motivation and steady learning progress while moving through the curriculum. In this paper we present our approach for monitoring the learning progress of students learning to play piano with Hidden Markov Models. First, we present and implement the so-called practice modes, practice units that are derived from the original task by reducing its complexity and focusing on one or several relevant task dimensions. Second, for each practice mode, a Hidden Markov Model is trained to predict whether the player is in the Mastered or NonMastered latent state regarding the current task and practice mode.","Piano Playing, Human-in-the-loop, Knowledge Tracing, Hidden Markov Model, Intelligent Tutoring and Monitoring System","","UMAP '22 Adjunct"
"Journal Article","Schodde T,Hoffmann L,Stange S,Kopp S","Adapt, Explain, Engage—A Study on How Social Robots Can Scaffold Second-Language Learning of Children","J.  Hum. -Robot Interact.","2019","9","1","","Association for Computing Machinery","New York, NY, USA","","","2019-12","","","https://doi.org/10.1145/3366422;http://dx.doi.org/10.1145/3366422","10.1145/3366422","Social robots are increasingly applied to support children’s learning, but how a robot can foster (or may hinder) learning is still not fully clear. One technique used by teachers is scaffolding, temporarily assisting learners to achieve new skills or levels of understanding they would not reach on their own. We ask if and how a social robot can be utilized to scaffold second-language learning of children at kindergarten age (4--7 years). Specifically, we explore an adapt-and-explain scaffolding strategy in which a robot acts as a peer-like tutor who dynamically adapts its behavior or the learning tasks to the cognitive and affective state of the child, and provides verbal explanations of these adaptations. An evaluation study with 40 children shows that children benefit from the learning adaptation and that the explanations have a positive effect especially for slower learners. Further, in 76% of all cases the robot managed to “re-engage” children who started to disengage from the learning interaction, helping them to achieve an overall higher learning gain. These findings demonstrate that a social robot equipped with suitable scaffolding mechanisms can increase engagement and learning, especially when being adaptive to the individual behavior and states of a child learner.","engagement, transparency, scaffolding, open learner model, Adaptive robot tutoring","",""
"Conference Paper","Benedetto L,Cappelli A,Turrin R,Cremonesi P","R2DE: A NLP Approach to Estimating IRT Parameters of Newly Generated Questions","","2020","","","412–421","Association for Computing Machinery","New York, NY, USA","Proceedings of the Tenth International Conference on Learning Analytics & Knowledge","Frankfurt, Germany","2020","9781450377126","","https://doi.org/10.1145/3375462.3375517;http://dx.doi.org/10.1145/3375462.3375517","10.1145/3375462.3375517","The main objective of exams consists in performing an assessment of students' expertise on a specific subject. Such expertise, also referred to as skill or knowledge level, can then be leveraged in different ways (e.g., to assign a grade to the students, to understand whether a student might need some support, etc.). Similarly, the questions appearing in the exams have to be assessed in some way before being used to evaluate students. Standard approaches to questions' assessment are either subjective (e.g., assessment by human experts) or introduce a long delay in the process of question generation (e.g., pretesting with real students). In this work we introduce R2DE (which is a Regressor for Difficulty and Discrimination Estimation), a model capable of assessing newly generated multiple-choice questions by looking at the text of the question and the text of the possible choices. In particular, it can estimate the difficulty and the discrimination of each question, as they are defined in Item Response Theory. We also present the results of extensive experiments we carried out on a real world large scale dataset coming from an e-learning platform, showing that our model can be used to perform an initial assessment of newly created questions and ease some of the problems that arise in question generation.","item response theory, knowledge tracing, latent traits estimation, learning analytics, educational data mining, natural language processing","","LAK '20"
"Journal Article","Strukova S,Ruipérez-Valiente JA,Mármol FG","Adapting Knowledge Inference Algorithms to Measure Geometry Competencies through a Puzzle Game","ACM Trans. Knowl. Discov. Data","2023","18","1","","Association for Computing Machinery","New York, NY, USA","","","2023-09","","1556-4681","https://doi.org/10.1145/3614436;http://dx.doi.org/10.1145/3614436","10.1145/3614436","The rapid technological evolution of the last years has motivated students to develop capabilities that will prepare them for an unknown future in the 21st century. In this context, many teachers intend to optimise the learning process, making it more dynamic and exciting through the introduction of gamification. Thus, this article focuses on a data-driven assessment of geometry competencies, which are essential for developing problem-solving and higher-order thinking skills. Our main goal is to adapt, evaluate and compare Bayesian Knowledge Tracing (BKT), Performance Factor Analysis (PFA), Elo, and Deep Knowledge Tracing (DKT) algorithms applied to the data of a geometry game named Shadowspect, in order to predict students’ performance by means of several classifier metrics. We analysed two algorithmic configurations, with and without prioritisation of Knowledge Components (KCs) – the skills needed to complete a puzzle successfully, and we found Elo to be the algorithm with the best prediction power with the ability to model the real knowledge of students. However, the best results are achieved without KCs because it is a challenging task to differentiate between KCs effectively in game environments. Our results prove that the above-mentioned algorithms can be applied in formal education to improve teaching, learning, and organisational efficiency.","data mining, data-driven evaluation, capabilities, competencies, Computational social science","",""
"Conference Paper","Hansen CJ,Wasson B,Skretting H,Netteland G,Hirnstein M","When Learning is High Stake","","2017","","","564–565","Association for Computing Machinery","New York, NY, USA","Proceedings of the Seventh International Learning Analytics & Knowledge Conference","Vancouver, British Columbia, Canada","2017","9781450348706","","https://doi.org/10.1145/3027385.3029461;http://dx.doi.org/10.1145/3027385.3029461","10.1145/3027385.3029461","Firefighter learning is high stake. They need to maintain certain competence levels related to physical, mental, and firefighting and rescue skills in order to provide the public with a high level of emergency service. Fire and Rescue Services need to maintain an overview of the current competences of their personnel and to react when there is a competence gap. This poster presents our approach to using competence modelling, learner models, learning analytics, and visualisations in order provide insight into competence status and development on the individual, team, and organisation level, and to provide early-alerts and automated messages to instructors responsible for planning training activities, as well as to team leaders responsible for making decisions about teams in high stakes situations.","open learner model, learning analytics, visualization, competence development","","LAK '17"
"Conference Paper","Jones A,Bull S,Castellano G","Open Learner Modelling with a Robotic Tutor","","2015","","","237–238","Association for Computing Machinery","New York, NY, USA","Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts","Portland, Oregon, USA","2015","9781450333184","","https://doi.org/10.1145/2701973.2702713;http://dx.doi.org/10.1145/2701973.2702713","10.1145/2701973.2702713","This paper describes research to explore how personalisation in a robot tutor using an open leaner model (OLM) based approach impacts on effectiveness of children's learning. An OLM is a visualisation of inferred knowledge state. We address the feasibility of using social robotics to present an OLM to a learner. Results to date indicate that a robotic tutor can increase trust in explanations of an OLM over text based representations. We outline the remaining work to create and evaluate an autonomous robotic tutor that will use an OLM to scaffold reflection.","adaptive social robotics, open learner model, robotic tutors","","HRI'15 Extended Abstracts"
"Conference Paper","Pelánek R,Řihák J","Experimental Analysis of Mastery Learning Criteria","","2017","","","156–163","Association for Computing Machinery","New York, NY, USA","Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization","Bratislava, Slovakia","2017","9781450346351","","https://doi.org/10.1145/3079628.3079667;http://dx.doi.org/10.1145/3079628.3079667","10.1145/3079628.3079667","A common personalization approach in educational systems is mastery learning. A key step in this approach is a criterion that determines whether a learner has achieved mastery. We thoroughly analyze several mastery criteria for the basic case of a single well-specified knowledge component. For the analysis we use experiments with both simulated and real data. The results show that the choice of data sources used for mastery decision and setting of thresholds are more important than the choice of a learner modeling technique. We argue that a simple exponential moving average method is a suitable technique for mastery criterion and propose techniques for the choice of a mastery threshold.","exponential moving average, mastery learning, bayesian knowledge tracing, learner modeling","","UMAP '17"
"Conference Paper","Baker RS,Pardos ZA,Gowda SM,Nooraei BB,Heffernan NT","Ensembling Predictions of Student Knowledge within Intelligent Tutoring Systems","","2011","","","13–24","Springer-Verlag","Berlin, Heidelberg","Proceedings of the 19th International Conference on User Modeling, Adaption, and Personalization","Girona, Spain","2011","9783642223617","","","","Over the last decades, there have been a rich variety of approaches towards modeling student knowledge and skill within interactive learning environments. There have recently been several empirical comparisons as to which types of student models are better at predicting future performance, both within and outside of the interactive learning environment. However, these comparisons have produced contradictory results. Within this paper, we examine whether ensemble methods, which integrate multiple models, can produce prediction results comparable to or better than the best of nine student modeling frameworks, taken individually. We ensemble model predictions within a Cognitive Tutor for Genetics, at the level of predicting knowledge action-by-action within the tutor. We evaluate the predictions in terms of future performance within the tutor and on a paper post-test. Within this data set, we do not find evidence that ensembles of models are significantly better. Ensembles of models perform comparably to or slightly better than the best individual models, at predicting future performance within the tutor software. However, the ensembles of models perform marginally significantly worse than the best individual models, at predicting post-test performance.","student modeling, cognitive tutor, Bayesian knowledge-tracing, performance factors analysis, ensemble methods","","UMAP'11"
"Conference Paper","Ashoori M,Miao C,Cai Y","Socializing Pedagogical Agents for Personalization in Virtual Learning Environments","","2007","","","346–349","IEEE Computer Society","USA","Proceedings of the 2007 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology - Workshops","","2007","9780769530284","","","","Personalization in virtual learning environments is the system ability to provide individualization and a set of personalized services such as personalized content management, learner model, or adaptive instant interaction. The intelligent agent technology has potential regarding the creation of such personalized, adaptive and interactive elearning applications. However, most of the available solutions have so far focused on porting existing courses with traditional teaching methods onto the virtual environments, making them available in an attractive animated interface without any fine-tuning and adaptation to the learner needs. This paper proposes a novel market-inspired collaboration model where the agents are self-interested autonomic elements collaborate to achieve a comprehensive learner model. Mentor agent makes decisions on top of a Dempster-Shafer belief accumulation to help student whenever she believes student has lost the clues and needs help. Proposed architecture is validated by applying on a sample agent augmented virtual environment designed to engageand motivate students at the lower secondary level in Singapore. Extensive experiments illustrate the effectiveness of the proposed interaction model where students have found the mentor agent as believable as a virtual teacher.","Pedagogical AgentPersonalizationVirtual EnvironmentAgent Augmented System","","WI-IATW '07"
"Conference Paper","Emerson A,Sawyer R,Azevedo R,Lester J","Gaze-Enhanced Student Modeling for Game-Based Learning","","2018","","","63–72","Association for Computing Machinery","New York, NY, USA","Proceedings of the 26th Conference on User Modeling, Adaptation and Personalization","Singapore, Singapore","2018","9781450355896","","https://doi.org/10.1145/3209219.3209238;http://dx.doi.org/10.1145/3209219.3209238","10.1145/3209219.3209238","Recent advances in eye-tracking technologies have introduced the opportunity to incorporate gaze into student modeling. Creating student models that leverage gaze information holds significant promise for game-based learning environments. This paper introduces a gaze-enhanced student modeling framework that incorporates student eye tracking to dynamically predict students' performance in a game-based learning environment for microbiology education, CRYSTAL ISLAND. The gaze-enhanced student modeling framework was investigated in a study comparing a gaze-enhanced student model with a baseline student model that does not utilize student eye-tracking. Results of a study conducted with 65 college students interacting with the CRYSTAL ISLAND game-based learning environment indicate that the gaze-enhanced student model significantly outperforms the baseline model in dynamically predicting student problem-solving performance. The findings suggest that incorporating gaze into student modeling can contribute to a new generation of student models for game-based learning environments.","gaze, student modeling, game-based learning","","UMAP '18"
"Conference Paper","Zhou T,Sheng H,Howley I","Assessing Post-Hoc Explainability of the BKT Algorithm","","2020","","","407–413","Association for Computing Machinery","New York, NY, USA","Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society","New York, NY, USA","2020","9781450371100","","https://doi.org/10.1145/3375627.3375856;http://dx.doi.org/10.1145/3375627.3375856","10.1145/3375627.3375856","As machine intelligence is increasingly incorporated into educational technologies, it becomes imperative for instructors and students to understand the potential flaws of the algorithms on which their systems rely. This paper describes the design and implementation of an interactive post-hoc explanation of the Bayesian Knowledge Tracing algorithm which is implemented in learning analytics systems used across the United States. After a user-centered design process to smooth out interaction design difficulties, we ran a controlled experiment to evaluate whether the interactive or static version of the explainable led to increased learning. Our results reveal that learning about an algorithm through an explainable depends on users' educational background. For other contexts, designers of post-hoc explainables must consider their users' educational background to best determine how to empower more informed decision-making with AI-enhanced systems.","interpretability of algorithms, communicating algorithmic systems, evaluation of xai systems, post-hoc explanations, explainable ai","","AIES '20"
"Conference Paper","Luo X,Wei X,Zhang J","Game-Based Learning Model Using Fuzzy Cognitive Map","","2009","","","67–76","Association for Computing Machinery","New York, NY, USA","Proceedings of the First ACM International Workshop on Multimedia Technologies for Distance Learning","Beijing, China","2009","9781605587578","","https://doi.org/10.1145/1631111.1631123;http://dx.doi.org/10.1145/1631111.1631123","10.1145/1631111.1631123","Fuzzy Cognitive Map (FCM) can be used to design game-based learning systems because it has the excellent ability of concept representation and reasoning. However, it can not (1) get new knowledge from existing data and (2) correct false transcendental knowledge by itself, which mars the game-based learning ability. This paper utilizes Hebbian learning rule to solve the first problem and uses unbalance degree to solve the second problem. As a result, the improved FCM has the ability of self-learning from both existing data and priori knowledge, and is more suitable for a game-based learning system. Based on the improved FCM, a novel game-based learning model is proposed, including a teacher submodel, a learner submodel and a set of learning mechanisms. The teacher submodel has the standard answers which can be deduced from the improved FCM. The learner submodel is bulit and adjusted according to the teacher's FCM, which reflects the learner's learning process. The learning mechanisms compute the difference between the outputs of the teacher submodel and the learner submodel, and control the whole game learning process according to the difference. Based on the proposed model, an automobile driving learning system is developed to prove the effectiveness of the proposed model. Extensive experimental results demonstrate our model validity in terms of controlling the learning process and the guiding learners learning.","fuzzy cognitive map, concept learning, learning mechanism, learner model, game-based learning, teacher model","","MTDL '09"
"Conference Paper","Burrell CJ","Learning Object Oriented Programming: Unique Visualizations of Individuals Learning Styles, Activities and the Programs Produced","","2008","","","339","Association for Computing Machinery","New York, NY, USA","Proceedings of the 13th Annual Conference on Innovation and Technology in Computer Science Education","Madrid, Spain","2008","9781605580784","","https://doi.org/10.1145/1384271.1384381;http://dx.doi.org/10.1145/1384271.1384381","10.1145/1384271.1384381","Constructing new knowledge when learning to program is acknowledged as a difficult process. This poster displays visual models constructed from pre-course questionnaires and the activities and programs produced by novices when taking the first steps in programming. Case study and experimental methods were used to develop these individualized, ""student learning models"" in an attempt to identify and understand individual differences. A micro-world environment was developed to capture data associated with writing and running programs. Visualizations derived display the resulting learner models which can assist in understanding the developing knowledge state of individuals with the potential of providing a contribution to tutorial support.","computing education, learner model, data visualization, novice, micro-world, programming","","ITiCSE '08"
"Journal Article","Burrell CJ","Learning Object Oriented Programming: Unique Visualizations of Individuals Learning Styles, Activities and the Programs Produced","SIGCSE Bull.","2008","40","3","339","Association for Computing Machinery","New York, NY, USA","","","2008-06","","0097-8418","https://doi.org/10.1145/1597849.1384381;http://dx.doi.org/10.1145/1597849.1384381","10.1145/1597849.1384381","Constructing new knowledge when learning to program is acknowledged as a difficult process. This poster displays visual models constructed from pre-course questionnaires and the activities and programs produced by novices when taking the first steps in programming. Case study and experimental methods were used to develop these individualized, ""student learning models"" in an attempt to identify and understand individual differences. A micro-world environment was developed to capture data associated with writing and running programs. Visualizations derived display the resulting learner models which can assist in understanding the developing knowledge state of individuals with the potential of providing a contribution to tutorial support.","computing education, novice, learner model, data visualization, programming, micro-world","",""
"Conference Paper","Madge C,Brightmore J,Kicikoglu D,Althani F,Bartle R,Chamberlain J,Kruschwitz U,Poesio M","LingoTowns: A Virtual World For Natural Language Annotation and Language Learning","","2022","","","57–62","Association for Computing Machinery","New York, NY, USA","Extended Abstracts of the 2022 Annual Symposium on Computer-Human Interaction in Play","Bremen, Germany","2022","9781450392112","","https://doi.org/10.1145/3505270.3558323;http://dx.doi.org/10.1145/3505270.3558323","10.1145/3505270.3558323","In this paper we introduce LingoTowns, a new gwap platform targeting language learners. LingoTowns provides a unified experience integrating games for multiple aspects of lexical and grammatical experience in a single virtual world, whilst simultaneously collecting judgements. Both LingoTowns and its constituent games are designed to provide more engagement to the players/ learners than normal gwaps. The platform also incorporates knowledge tracing methods ensuring that the players’ progress in terms of understanding of grammatical concepts is tracked both at the individual game level and overall.","Virtual Worlds, Educational Games, Games With A Purpose","","CHI PLAY '22"
"Conference Paper","Gusukuma L,Bart AC,Kafura D","Pedal: An Infrastructure for Automated Feedback Systems","","2020","","","1061–1067","Association for Computing Machinery","New York, NY, USA","Proceedings of the 51st ACM Technical Symposium on Computer Science Education","Portland, OR, USA","2020","9781450367936","","https://doi.org/10.1145/3328778.3366913;http://dx.doi.org/10.1145/3328778.3366913","10.1145/3328778.3366913","This paper describes Pedal, an innovative approach to the automated creation of feedback given to students in programming classes. Pedal is so named because it supports the PEDAgogical goals of instructors and is an expandable Library of components motivated by these goals. Pedal currently comes with components for type inferencing, flow analysis, pattern matching, and unit testing to provide an instructor with a rich set of resources to use in authoring and prioritizing feedback. The larger vision is the loosely-coupled architecture whose components can be readily expanded or replaced. The Pedal library components are motivated by a study of contemporary automated feedback systems and our own experience. Pedal's components are described and examples are given of Pedal-based feedback from three different introductory classes at two different universities. The integration of Pedal into several programming and autograding environments is briefly described.","cs education, immediate feedback, feedback architecture, student model","","SIGCSE '20"
"Conference Paper","Takami K,Dai Y,Flanagan B,Ogata H","Educational Explainable Recommender Usage and Its Effectiveness in High School Summer Vacation Assignment","","2022","","","458–464","Association for Computing Machinery","New York, NY, USA","LAK22: 12th International Learning Analytics and Knowledge Conference","Online, USA","2022","9781450395731","","https://doi.org/10.1145/3506860.3506882;http://dx.doi.org/10.1145/3506860.3506882","10.1145/3506860.3506882","Explainable recommendations, which provide explanations about why an item is recommended, help to improve the transparency, persuasiveness, and trustworthiness. However, few research in educational technology utilize explainable recommendations. We developed an explanation generator using the parameters from Bayesian knowledge tracing models. We used this educational explainable recommendation system to investigate the effects of explanation on the summer vacation assignment for high school students. Comparing the click counts of recommended quizzes with and without explanations, we found that the number of clicks was significantly higher for quizzes with explanations. Furthermore, system usage pattern mining revealed that students can be divided to three clusters— none, steady and late users. In the cluster of steady users, recommended quizzes with explanations were continuously used. These results suggest the effectiveness of an explainable recommendation system in the field of education.","Explainable recommendation, Effectiveness of explanation, Pattern mining, Long vacation period, A/B test","","LAK22"
"Conference Paper","de Wit J,Schodde T,Willemsen B,Bergmann K,de Haas M,Kopp S,Krahmer E,Vogt P","The Effect of a Robot's Gestures and Adaptive Tutoring on Children's Acquisition of Second Language Vocabularies","","2018","","","50–58","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","Chicago, IL, USA","2018","9781450349536","","https://doi.org/10.1145/3171221.3171277;http://dx.doi.org/10.1145/3171221.3171277","10.1145/3171221.3171277","This paper presents a study in which children, four to six years old, were taught words in a second language by a robot tutor. The goal is to evaluate two ways for a robot to provide scaffolding for students: the use of iconic gestures, combined with adaptively choosing the next learning task based on the child»s past performance. The results show a positive effect on long-term memorization of novel words, and an overall higher level of engagement during the learning activities when gestures are used. The adaptive tutoring strategy reduces the extent to which the level of engagement is diminishing during the later part of the interaction.","education, bayesian knowledge tracing, non-verbal communication, robotics, language tutoring, human-robot interaction","","HRI '18"
"Journal Article","Islam B,Rahman MM,Ahmed T,Ahmed MY,Hasan MM,Nathan V,Vatanparvar K,Nemati E,Kuang J,Gao JA","BreathTrack: Detecting Regular Breathing Phases from Unannotated Acoustic Data Captured by a Smartphone","Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.","2021","5","3","","Association for Computing Machinery","New York, NY, USA","","","2021-09","","","https://doi.org/10.1145/3478123;http://dx.doi.org/10.1145/3478123","10.1145/3478123","Breathing biomarkers, such as breathing rate, fractional inspiratory time, and inhalation-exhalation ratio, are vital for monitoring the user's health and well-being. Accurate estimation of such biomarkers requires breathing phase detection, i.e., inhalation and exhalation. However, traditional breathing phase monitoring relies on uncomfortable equipment, e.g., chestbands. Smartphone acoustic sensors have shown promising results for passive breathing monitoring during sleep or guided breathing. However, detecting breathing phases using acoustic data can be challenging for various reasons. One of the major obstacles is the complexity of annotating breathing sounds due to inaudible parts in regular breathing and background noises. This paper assesses the potential of using smartphone acoustic sensors for passive unguided breathing phase monitoring in a natural environment. We address the annotation challenges by developing a novel variant of the teacher-student training method for transferring knowledge from an inertial sensor to an acoustic sensor, eliminating the need for manual breathing sound annotation by fusing signal processing with deep learning techniques. We train and evaluate our model on the breathing data collected from 131 subjects, including healthy individuals and respiratory patients. Experimental results show that our model can detect breathing phases with 77.33% accuracy using acoustic sensors. We further present an example use-case of breathing phase-detection by first estimating the biomarkers from the estimated breathing phases and then using these biomarkers for pulmonary patient detection. Using the detected breathing phases, we can estimate fractional inspiratory time with 92.08% accuracy, the inhalation-exhalation ratio with 86.76% accuracy, and the breathing rate with 91.74% accuracy. Moreover, we can distinguish respiratory patients from healthy individuals with up to 76% accuracy. This paper is the first to show the feasibility of detecting regular breathing phases towards passively monitoring respiratory health and well-being using acoustic data captured by a smartphone.","Smartphone, Respiratory Diseases, Teacher-Student Model, Breathing, Audio","",""
"Conference Paper","Teruel M,Alonso Alemany L","Co-Embeddings for Student Modeling in Virtual Learning Environments","","2018","","","73–80","Association for Computing Machinery","New York, NY, USA","Proceedings of the 26th Conference on User Modeling, Adaptation and Personalization","Singapore, Singapore","2018","9781450355896","","https://doi.org/10.1145/3209219.3209227;http://dx.doi.org/10.1145/3209219.3209227","10.1145/3209219.3209227","We present a neural architecture to model student behavior in virtual educational environments using purely unsupervised information. A crucial part of this architecture is the optimization of a joint embedding function to represent both students and course elements into a single shared space. This joint representation is more adequate than disjoint representations because it elicits insights on the relations between students and contents. Moreover, the model is trained only with interactions of the student with online learning platforms, without requiring any additional manual labeling by experts. We obtain state-of-the-art results using this approach in two types of task: first, dropout prediction in online courses (MOOCs), and second Knowledge Tracing in Intelligent Tutoring Systems (ITS). We explore how the deep architecture is flexible enough to capture variables related to different phenomena, such as engagement or skill mastery.","interactive learning environments, neural networks, e-learning, representation learning","","UMAP '18"
"Conference Paper","Hocine N","Personalized Serious Games for Self-Regulated Attention Training","","2019","","","251–255","Association for Computing Machinery","New York, NY, USA","Adjunct Publication of the 27th Conference on User Modeling, Adaptation and Personalization","Larnaca, Cyprus","2019","9781450367110","","https://doi.org/10.1145/3314183.3323458;http://dx.doi.org/10.1145/3314183.3323458","10.1145/3314183.3323458","Attention plays an important role in the daily lives of people and especially in learning. It may be influenced by different factors since childhood or during the aging process because of deficits such as Attention Deficit Hyperactivity Disorder (ADHD), which is responsible of learning difficulties. Serious games for attention training may be helpful to develop self-regulation skills in attention training through a personalized game experience. It can provide children with appropriate guidance to develop their self-regulation skills while enhancing their cognitive functions such as attention. The transparency of the user model may help users (both children and tutors) to follow their progression, and to develop their learning strategy. In this paper, a pilot study was conducted to evaluate the assessment step of a developed attention training serious game. The objective was to study whether the transparency of the learner model influences the users' perception of their attention and self-regulate their learning. The primary results of the pilot experiment show that open learner model influences the decision of users on difficulty level preference that may be promising in self-regulated attention training.","self-regulation, attention, personalization, serious games","","UMAP'19 Adjunct"
"Conference Paper","Martori F,Cuadros J,González-Sabaté L","Studying the Relationship between BKT Fitting Error and the Skill Difficulty Index","","2016","","","364–368","Association for Computing Machinery","New York, NY, USA","Proceedings of the Sixth International Conference on Learning Analytics & Knowledge","Edinburgh, United Kingdom","2016","9781450341905","","https://doi.org/10.1145/2883851.2883901;http://dx.doi.org/10.1145/2883851.2883901","10.1145/2883851.2883901","Bayesian Knowledge Tracing (BKT) is one of the most popular knowledge inference models due to its interpretability and ability to infer student knowledge. A proper student modeling can help guide the behavior of a cognitive tutor system and provide insight to researchers on understanding how students learn. Using four different datasets we study the relationship between the error coming from fitting the parameters and the difficulty index of the skills and the effect of the size of the dataset in this relationship. The relationship between the fitting error and the difficulty index can be very easy modeled and might be indicating some problems with BKTs performance. However, large datasets are required to clearly see this connection as there is an important sample size effect.","BKT, BKT-BF, RMSE modeling, difficulty index, educational data mining","","LAK '16"
"Conference Paper","Schneeberger T,Gebhard P,Baur T,André E","PARLEY: A Transparent Virtual Social Agent Training Interface","","2019","","","35–36","Association for Computing Machinery","New York, NY, USA","Proceedings of the 24th International Conference on Intelligent User Interfaces: Companion","Marina del Ray, California","2019","9781450366731","","https://doi.org/10.1145/3308557.3308674;http://dx.doi.org/10.1145/3308557.3308674","10.1145/3308557.3308674","In this demo, we present PARLEY, an interactive system to train difficult social situations in a safe environment with a Virtual Agent. The system realizes different phenomena studied by psychology research that are known to create a natural interaction. Moreover, we include an open learner model to ensure an explainable user experience.","explainable AI, social training system, virtual agents","","IUI '19"
"Conference Paper","Garlatti S,Gilliot JM,Kieffer S,Eneau J,Lameul G,Serrano-Alvarado P,Skaf-Molli H,Desmontils E","Open Learner Models, Trust and Knowledge Management for Life Long Learning","","2018","","","1019","International World Wide Web Conferences Steering Committee","Republic and Canton of Geneva, CHE","Companion Proceedings of the The Web Conference 2018","Lyon, France","2018","9781450356404","","https://doi.org/10.1145/3184558.3193129;http://dx.doi.org/10.1145/3184558.3193129","10.1145/3184558.3193129","","knowledge management, learner autonomy, open learner model, life long learning, ACM proceedings","","WWW '18"
"Conference Paper","Tuti T,Paton C,Winters N","Learning to Represent Healthcare Providers Knowledge of Neonatal Emergency Care: Findings from a Smartphone-Based Learning Intervention Targeting Clinicians from LMICs","","2020","","","320–329","Association for Computing Machinery","New York, NY, USA","Proceedings of the Tenth International Conference on Learning Analytics & Knowledge","Frankfurt, Germany","2020","9781450377126","","https://doi.org/10.1145/3375462.3375479;http://dx.doi.org/10.1145/3375462.3375479","10.1145/3375462.3375479","Modelling healthcare providers' knowledge while they are gaining new concepts is an important step towards supporting self-regulated personalised learning at scale. This is especially important if we are to address health workforce skills development and enhance the subsequent quality of care patients receive in the Global South, where a huge skills gap exists. Rich data about healthcare providers' learning can be captured by their responses to close-ended problems within conjunctive solution space -such as clinical training scenarios for emergency care delivery- on smartphone-based learning interventions which are being proposed as a solution for reducing the healthcare skills gap in this context. Together with sequential data detailing a learner's progress while they are solving a learning task, this provides useful insights into their learning behaviour. Predicting learning or forgetting curves from representations of healthcare providers knowledge is a difficult task, but recent promising machine learning advances have produced techniques capable of learning knowledge representations and overcoming this challenge. In this study, we train a Long Short-Term Memory neural network for predicting learners' future performance and forgetting curves by feeding it sequence embeddings of learning task attempts from healthcare providers from Global South. From this training, the model captures nuanced representations of a healthcare provider's clinical knowledge and their patterns of learning behaviours, predicting their future performance with high accuracy. More significantly, by differentiating reduced performance based on spaced learning, the model can help provide timely warning that helps support healthcare providers to reinforce their self-regulated learning while providing a basis for personalised instructional support to aid improved clinical outcomes from their professional practices.","deep knowledge tracing, forgetting curves, clinical training, emergency care, neonatal care, global health, smartphones","","LAK '20"
"Conference Paper","Barria-Pineda J,Brusilovsky P","Explaining Educational Recommendations through a Concept-Level Knowledge Visualization","","2019","","","103–104","Association for Computing Machinery","New York, NY, USA","Proceedings of the 24th International Conference on Intelligent User Interfaces: Companion","Marina del Ray, California","2019","9781450366731","","https://doi.org/10.1145/3308557.3308690;http://dx.doi.org/10.1145/3308557.3308690","10.1145/3308557.3308690","In this demo paper, we present a visual approach for explaining learning content recommendation in the personalized practice system Mastery Grids. The proposed approach uses a concept-level visualization of student knowledge in Java programming to demonstrate why specific practice content is recommended by the system. The visualized student knowledge is estimated by a Bayesian Knowledge Tracing approach, which traces student problem-solving performance. The visual explanatory components, which show both a fine-grained and aggregated knowledge level, are presented to the students along with textual explanations. The goal of this approach is to display the suitability of each recommended item in the context of a student's current knowledge and goal, i.e., the current topic they are studying.","open learner models, explainability, educational recommendations","","IUI '19"
"Conference Paper","Pardos ZA,Tang M,Anastasopoulos I,Sheel SK,Zhang E","OATutor: An Open-Source Adaptive Tutoring System and Curated Content Library for Learning Sciences Research","","2023","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems","Hamburg, Germany","2023","9781450394215","","https://doi.org/10.1145/3544548.3581574;http://dx.doi.org/10.1145/3544548.3581574","10.1145/3544548.3581574","Despite decades long establishment of effective tutoring principles, no adaptive tutoring system has been developed and open-sourced to the research community. The absence of such a system inhibits researchers from replicating adaptive learning studies and extending and experimenting with various tutoring system design directions. For this reason, adaptive learning research is primarily conducted on a small number of proprietary platforms. In this work, we aim to democratize adaptive learning research with the introduction of the first open-source adaptive tutoring system based on Intelligent Tutoring System principles. The system, we call Open Adaptive Tutor (OATutor), has been iteratively developed over three years with field trials in classrooms drawing feedback from students, teachers, and researchers. The MIT-licensed source code includes three creative commons (CC BY) textbooks worth of algebra problems, with tutoring supports authored by the OATutor project. Knowledge Tracing, an A/B testing framework, and LTI support are included.","open source, OER, content authoring, Adaptive learning, replicable research, intelligent tutoring systems, research through design","","CHI '23"
"Conference Paper","Brusilovsky P","Addictive Links: Engaging Students through Adaptive Navigation Support and Open Social Student Modeling","","2014","","","1075–1076","Association for Computing Machinery","New York, NY, USA","Proceedings of the 23rd International Conference on World Wide Web","Seoul, Korea","2014","9781450327459","","https://doi.org/10.1145/2567948.2580052;http://dx.doi.org/10.1145/2567948.2580052","10.1145/2567948.2580052","Empirical studies of adaptive annotation in the educational context have demonstrated that it can help students to acquire knowledge faster, improve learning outcomes, reduce navigational overhead, and encourage non-sequential navigation. Over the last 8 years we have explored a lesser known effect of adaptive annotation -- its ability to significantly increase student engagement in working with non-mandatory educational content. In the presence of adaptive link annotation, students tend to access significantly more learning content; they stay with it longer, return to it more often and explore a wider variety of learning resources. This talk will present an overview of our exploration of the addictive links effect in many course-long studies, which we ran in several domains (C, SQL and Java programming), for several types of learning content (quizzes, problems, interactive examples). The first part of the talk will review our exploration of a more traditional knowledge-based personalization approach and the second part will focus on more recent studies of social navigation and open social student modeling.","personalized learning, engagement, social learning, open student model, navigation support","","WWW '14 Companion"
"Journal Article","Bai J,Yin C,Zhang J,Wang Y,Dong Y,Rong W,Xiong Z","Adversarial Knowledge Distillation Based Biomedical Factoid Question Answering","IEEE/ACM Trans. Comput. Biol. Bioinformatics","2022","20","1","106–118","IEEE Computer Society Press","Washington, DC, USA","","","2022-03","","1545-5963","https://doi.org/10.1109/TCBB.2022.3161032;http://dx.doi.org/10.1109/TCBB.2022.3161032","10.1109/TCBB.2022.3161032","Biomedical factoid question answering is an essential application for biomedical information sharing. Recently, neural network based approaches have shown remarkable performance for this task. However, due to the scarcity of annotated data which requires intensive knowledge of expertise, training a robust model on limited-scale biomedical datasets remains a challenge. Previous works solve this problem by introducing useful knowledge. It is found that the interaction between question and answer (QA-interaction) is also a kind of knowledge which could help extract answer accurately. This research develops a knowledge distillation framework for biomedical factoid question answering, in which a teacher model as the knowledge source of QA-interaction is designed to enhance the student model. In addition, to further alleviate the problem of limited-scale dataset, a novel adversarial knowledge distillation technique is proposed to robustly distill the knowledge from teacher model to student model by constructing perturbed examples as additional training data. By forcing the student model to mimic the predicted distributions of teacher model on both original examples and perturbed examples, the knowledge of QA-interaction can be learned by student model. We evaluate the proposed framework on the widely used BioASQ datasets, and experimental results have shown the proposed method’s promising potential.","","",""
"Conference Paper","Yang C,Liu J,Shi C","Extract the Knowledge of Graph Neural Networks and Go Beyond It: An Effective Knowledge Distillation Framework","","2021","","","1227–1237","Association for Computing Machinery","New York, NY, USA","Proceedings of the Web Conference 2021","Ljubljana, Slovenia","2021","9781450383127","","https://doi.org/10.1145/3442381.3450068;http://dx.doi.org/10.1145/3442381.3450068","10.1145/3442381.3450068","Semi-supervised learning on graphs is an important problem in the machine learning area. In recent years, state-of-the-art classification methods based on graph neural networks (GNNs) have shown their superiority over traditional ones such as label propagation. However, the sophisticated architectures of these neural models will lead to a complex prediction mechanism, which could not make full use of valuable prior knowledge lying in the data, e.g., structurally correlated nodes tend to have the same class. In this paper, we propose a framework based on knowledge distillation to address the above issues. Our framework extracts the knowledge of an arbitrary learned GNN model (teacher model), and injects it into a well-designed student model. The student model is built with two simple prediction mechanisms, i.e., label propagation and feature transformation, which naturally preserves structure-based and feature-based prior knowledge, respectively. In specific, we design the student model as a trainable combination of parameterized label propagation and feature transformation modules. As a result, the learned student can benefit from both prior knowledge and the knowledge in GNN teachers for more effective predictions. Moreover, the learned student model has a more interpretable prediction process than GNNs. We conduct experiments on five public benchmark datasets and employ seven GNN models including GCN, GAT, APPNP, SAGE, SGC, GCNII and GLP as the teacher models. Experimental results show that the learned student model can consistently outperform its corresponding teacher model by on average. Code and data are available at https://github.com/BUPT-GAMMA/CPF","Label Propagation, Knowledge Distillation, Graph Neural Networks","","WWW '21"
"Conference Paper","Tang J,Wang K","Ranking Distillation: Learning Compact Ranking Models With High Performance for Recommender System","","2018","","","2289–2298","Association for Computing Machinery","New York, NY, USA","Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","London, United Kingdom","2018","9781450355520","","https://doi.org/10.1145/3219819.3220021;http://dx.doi.org/10.1145/3219819.3220021","10.1145/3219819.3220021","We propose a novel way to train ranking models, such as recommender systems, that are both effective and efficient. Knowledge distillation (KD) was shown to be successful in image recognition to achieve both effectiveness and efficiency. We propose a KD technique for learning to rank problems, called ranking distillation (RD). Specifically, we train a smaller student model to learn to rank documents/items from both the training data and the supervision of a larger teacher model. The student model achieves a similar ranking performance to that of the large teacher model, but its smaller model size makes the online inference more efficient. RD is flexible because it is orthogonal to the choices of ranking models for the teacher and student. We address the challenges of RD for ranking problems. The experiments on public data sets and state-of-the-art recommendation models showed that RD achieves its design purposes: the student model learnt with RD has less than an half size of the teacher model while achieving a ranking performance similar tothe teacher model and much better than the student model learnt without RD.","knowledge transfer, learning to rank, recommender system, model compression","","KDD '18"
"Conference Paper","Hsiao IH,Bakalov F,Brusilovsky P,König-Ries B","Open Social Student Modeling: Visualizing Student Models with Parallel Introspectiveviews","","2011","","","171–182","Springer-Verlag","Berlin, Heidelberg","Proceedings of the 19th International Conference on User Modeling, Adaption, and Personalization","Girona, Spain","2011","9783642223617","","","","This paper explores a social extension of open student modeling that we call open social student modeling. We present a specific implementation of this approach that uses parallel IntrospectiveViews to visualize models representing student progress with QuizJET parameterized self-assessment questions for Java programming. The interface allows visualizing not only the student's own model, but also displaying parallel views on the models of their peers and the cumulative model of the entire class or group. The system was evaluated in a semester-long classroom study. While the use of the system was non-mandatory, the parallel IntrospectiveViews interface caused an increase in all of the usage parameters in comparison to a regular portal-based access, which allowed the student to achieve a higher success rate in answering the questions. The collected data offer some evidence that a combination of traditional personalized guidance with social guidance was more effective than personalized guidance alone.","open student model, parameterized self-assessment, visualization, open user model","","UMAP'11"
"Conference Paper","Ali BA,Majd S,Marie-Hélène A,Elsa N","Recommendation of Pedagogical Resources within a Learning Ecosystem","","2017","","","14–21","Association for Computing Machinery","New York, NY, USA","Proceedings of the 9th International Conference on Management of Digital EcoSystems","Bangkok, Thailand","2017","9781450348959","","https://doi.org/10.1145/3167020.3167023;http://dx.doi.org/10.1145/3167020.3167023","10.1145/3167020.3167023","With the current development of Information and Communication Technologies (ICT), organizations deal with great amount of information coming from many systems. Identifying a resource of relevant information to a specific context becomes a real challenge. In the course of our work we are interested in recommendation of pedagogical resources within a learning ecosystem. We have chosen to model a learning ecosystem as a system of information systems (SoIS). In this SoIS we introduce a resource recommender system. This system is based on users' votes (learners, teachers), and the similarity between the description of pedagogical resources and the learners' profile. In our approach, we take into account the willingness to collaborate. Therefore, we exploit a collaboration model that supports learning ecosystem to answer the demand for questions such as, who collaborates with whom, how, when, why, on what and where, etc. The work presented in this paper is focused on at recommendation of pedagogical resources within a learning ecosystem.","Resource Model, System of Information Systems, Learning Ecosystems, Learner Model, Recommender System., Voting System","","MEDES '17"
"Journal Article","Tu YH,Du J,Lee CH","Speech Enhancement Based on Teacher–Student Deep Learning Using Improved Speech Presence Probability for Noise-Robust Speech Recognition","IEEE/ACM Trans. Audio, Speech and Lang. Proc.","2019","27","12","2080–2091","IEEE Press","","","","2019-12","","2329-9290","https://doi.org/10.1109/TASLP.2019.2940662;http://dx.doi.org/10.1109/TASLP.2019.2940662","10.1109/TASLP.2019.2940662","In this paper, we propose a novel teacher-student learning framework for the preprocessing of a speech recognizer, leveraging the online noise tracking capabilities of improved minima controlled recursive averaging IMCRA and deep learning of nonlinear interactions between speech and noise. First, a teacher model with deep architectures is built to learn the target of ideal ratio masks IRMs using simulated training pairs of clean and noisy speech data. Next, a student model is trained to learn an improved speech presence probability by incorporating the estimated IRMs from the teacher model into the IMCRA approach. The student model can be compactly designed in a causal processing mode having no latency with the guidance of a complex and noncausal teacher model. Moreover, the clean speech requirement, which is difficult to meet in real-world adverse environments, can be relaxed for training the student model, implying that noisy speech data can be directly used to adapt the regression-based enhancement model to further improve speech recognition accuracies for noisy speech collected in such conditions. Experiments on the CHiME-4 challenge task show that our best student model with bidirectional gated recurrent units BGRUs can achieve a relative word error rate WER reduction of 18.85% for the real test set when compared to unprocessed system without acoustic model retraining. However, the traditional teacher model degrades the performance of the unprocessed system in this case. In addition, the student model with a deep neural network DNN in causal mode having no latency yields a relative WER reduction of 7.94% over the unprocessed system with 670 times less computing cycles when compared to the BGRU-equipped student model. Finally, the conventional speech enhancement and IRM-based deep learning method destroyed the ASR performance when the recognition system became more powerful. While our proposed approach could still improve the ASR performance even in the more powerful recognition system.","","",""
"Conference Paper","Lin L,Wang F","Adaptive Learning System Based on Knowledge Graph","","2023","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 9th International Conference on Education and Training Technologies","Macau, China","2023","9781450399593","","https://doi.org/10.1145/3599640.3599647;http://dx.doi.org/10.1145/3599640.3599647","10.1145/3599640.3599647","Since the rapid development of ""Internet+Education"" , various artificial intelligence technologies have been applied to teaching and learning. The development of technology has brought great impetus and potential to education. Based on the background of big data, how to use AI technology to mine valuable information in massive data to meet the adaptive learning needs of learners is an important topic that deserves attention and research. This paper builds learner ontology and course knowledge ontology, links learning resources to course knowledge ontology to build domain knowledge graph, designs and implements an adaptive learning system based on knowledge graph, including learner model, domain knowledge model, adaptive learning engine and interactive interface. Finally, Pellet inference engine is used to infer the designed SWRL rules. The result shows that the adaptive learning system proposed in this paper can recommend appropriate learning paths according to the learners' learning status, and present personalized learning resources.","recommendation, Adaptive learning system, personalized learning, knowledge graph, ontology construction","","ICETT '23"
"Conference Paper","Zhao J,Thille C,Gattani N,Zimmaro D","A Novel Framework for Discovering Cognitive Models of Learning","","2021","","","271–274","Association for Computing Machinery","New York, NY, USA","Proceedings of the Eighth ACM Conference on Learning @ Scale","Virtual Event, Germany","2021","9781450382151","","https://doi.org/10.1145/3430895.3460156;http://dx.doi.org/10.1145/3430895.3460156","10.1145/3430895.3460156","A cognitive model is a descriptive account or computational representation of human thinking about a given concept, skill, or domain. A cognitive model of learning, includes both a way of organizing knowledge within a subject area and an account of how humans develop accurate and complete knowledge of that subject area. Learning designers engage in a variety of practices to unpack knowledge from subject matter experts and novices to develop cognitive models of learning and use those models to guide the design of instruction or instructional technologies. Traditional approaches to eliciting and organizing knowledge, such as conducting a cognitive task analysis (CTA) [10] with experts and novices, are labor-intensive and require specific expertise that many learning designers do not have. However, learning data generated from learners' interaction with the courses, reveal how humans think about and develop knowledge. We propose a novel framework that uses learning data to discover and refine cognitive models of learning. The framework includes a Variational Autoencoder (VAE) module and a Gaussian Mixture Model (GMM) module. We provide one case study in a corporate setting to demonstrate the effectiveness of the proposed framework compared to other approaches.","human-computer interaction, cognitive modeling, variational autoencoder, human-in-the-loop, knowledge tracing simulation","","L@S '21"
"Conference Paper","Huang Y,Yang X,Xu C","Multimodal Global Relation Knowledge Distillation for Egocentric Action Anticipation","","2021","","","245–254","Association for Computing Machinery","New York, NY, USA","Proceedings of the 29th ACM International Conference on Multimedia","Virtual Event, China","2021","9781450386517","","https://doi.org/10.1145/3474085.3475327;http://dx.doi.org/10.1145/3474085.3475327","10.1145/3474085.3475327","In this paper, we consider the task of action anticipation on egocentric videos. Previous methods ignore explicit modeling of the global context relation among past and future actions, which is not an easy task due to the vacancy of unobserved videos. To solve this problem, we propose a Multimodal Global Relation Knowledge Distillation (MGRKD) framework to distill the knowledge learned from full videos to improve the action anticipation task on partially observed videos. The proposed MGRKD has a teacher-student learning strategy, where either the teacher or student model has three branches of global relation graph networks (GRGN) to explore the pairwise relations between past and future actions based on three kinds of features (i.e., RGB, motion or object). The teacher model has a similar architecture with the student model, except that the teacher model uses true feature of the future video snippet to build the graph in GRGN while the student model uses a progressive GRU to predict an initialized node feature of future snippet in GRGN. Through the teacher-student learning strategy, the discriminative features and relation knowledge of the past and future actions learned in the teacher model can be distilled to the student model. The experiments on two egocentric video datasets EPIC-Kitchens and EGTEA Gaze+ show that the proposed framework achieves state-of-the-art performances.","egocentric action anticipation, graph network, knowledge distillation","","MM '21"
"Conference Paper","Eagle M,Corbett A,Stamper J,McLaren BM,Baker R,Wagner A,MacLaren B,Mitchell A","Predicting Individual Differences for Learner Modeling in Intelligent Tutors from Previous Learner Activities","","2016","","","55–63","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization","Halifax, Nova Scotia, Canada","2016","9781450343688","","https://doi.org/10.1145/2930238.2930255;http://dx.doi.org/10.1145/2930238.2930255","10.1145/2930238.2930255","This study examines how accurately individual student differences in learning can be predicted from prior student learning activities. Bayesian Knowledge Tracing (BKT) predicts learner performance well and has often been employed to implement cognitive mastery. Standard BKT individualizes parameter estimates for knowledge components, but not for learners. Studies have shown that individualizing parameters for learners improves the quality of BKT fits and can lead to very different (and potentially better) practice recommendations. These studies typically derive best-fitting individualized learner parameters from learner performance in existing data logs, making the methods difficult to deploy in actual tutor use. In this work, we examine how well BKT parameters in a tutor lesson can be individualized based on learners' prior performance in reading instructional text, taking a pretest, and completing an earlier tutor lesson. We find that best-fitting individual difference estimates do not directly transfer well from one tutor lesson to another, but that predictive models incorporating variables extracted from prior reading, pretest and tutor activities perform well, when compared to a standard BKT model and a model with best-fitting individualized parameter estimates.","genetics, student modeling, BKT, machine learning","","UMAP '16"
"Conference Paper","Pardos ZA,Xu Y","Improving Efficacy Attribution in a Self-Directed Learning Environment Using Prior Knowledge Individualization","","2016","","","435–439","Association for Computing Machinery","New York, NY, USA","Proceedings of the Sixth International Conference on Learning Analytics & Knowledge","Edinburgh, United Kingdom","2016","9781450341905","","https://doi.org/10.1145/2883851.2883949;http://dx.doi.org/10.1145/2883851.2883949","10.1145/2883851.2883949","Models of learning in EDM and LAK are pushing the boundaries of what can be measured from large quantities of historical data. When controlled randomization is present in the learning platform, such as randomized ordering of problems within a problem set, natural quasi-randomized controlled studies can be conducted, post-hoc. Difficulty and learning gain attribution are among factors of interest that can be studied with secondary analyses under these conditions. However, much of the content that we might like to evaluate for learning value is not administered as a random stimulus to students but instead is being self-selected, such as a student choosing to seek help in the discussion forums, wiki pages, or other pedagogically relevant material in online courseware. Help seekers, by virtue of their motivation to seek help, tend to be the ones who have the least knowledge. When presented with a cohort of students with a bi-modal or uniform knowledge distribution, this can present problems with model interpretability when a single point estimation is used to represent cohort prior knowledge. Since resource access is indicative of a low knowledge student, a model can tend towards attributing the resources with low or negative learning gain in order to better explain performance given the higher average prior point estimate. In this paper we present several individualized prior strategies and demonstrate how learning efficacy attribution validity and prediction accuracy improve as a result. Level of education attained, relative past assessment performance, and the prior per student cold start heuristic were employed and compared as prior knowledge individualization strategies.","self-directed learning, Bayesian knowledge tracing, prior knowledge, efficacy attribution, self-selection bias, education, individualization, massive open online courses (MOOCs)","","LAK '16"
"Conference Paper","Lee Y,Kim KE","Dual Correction Strategy for Ranking Distillation in Top-N Recommender System","","2021","","","3186–3190","Association for Computing Machinery","New York, NY, USA","Proceedings of the 30th ACM International Conference on Information & Knowledge Management","Virtual Event, Queensland, Australia","2021","9781450384469","","https://doi.org/10.1145/3459637.3482093;http://dx.doi.org/10.1145/3459637.3482093","10.1145/3459637.3482093","Knowledge Distillation (KD), which transfers the knowledge of a well-trained large model (teacher) to a small model (student), has become an important area of research for practical deployment of recommender systems. Recently, Relaxed Ranking Distillation (RRD) has shown that distilling the ranking information in the recommendation list significantly improves the performance. However, the method still has limitations in that 1) it does not fully utilize the prediction errors of the student model, which makes the training not fully efficient, and 2) it only distills the user-side ranking information, which provides an insufficient view under the sparse implicit feedback. This paper presents Dual Correction strategy for Distillation (DCD), which transfers the ranking information from the teacher model to the student model in a more efficient manner. Most importantly, DCD uses the discrepancy between the teacher model and the student model predictions to decide which knowledge to be distilled. By doing so, DCD essentially provides the learning guidance tailored to ""correcting"" what the student model has failed to accurately predict. This process is applied for transferring the ranking information from the user-side as well as the item-side to address sparse implicit user feedback. Our experiments show that the proposed method outperforms the state-of-the-art baselines, and ablation studies validate the effectiveness of each component.","retrieval efficiency, learning to rank, recommender system, knowledge distillation, model compression","","CIKM '21"
"Conference Paper","Morgan B,Hampton AJ,Cai Z,Tackett A,Wang L,Hu X,Graesser AC","Electronixtutor Integrates Multiple Learning Resources to Teach Electronics on the Web","","2018","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fifth Annual ACM Conference on Learning at Scale","London, United Kingdom","2018","9781450358866","","https://doi.org/10.1145/3231644.3231691;http://dx.doi.org/10.1145/3231644.3231691","10.1145/3231644.3231691","ElectronixTutor is a new Intelligent Tutoring System for electronics that integrates multiple intelligent learning resources, including AutoTutor, Dragoon, LearnForm, ASSISTments, and BEETLE-II, as well as Point & Query hotspots on diagrams and numerous text documents on the subject of electronics. ElectronixTutor's student model contains a set of electronics knowledge components (e.g., ""transistor behavior""), each of which are taught by multiple learning resources. ElectronixTutor also features a recommender system, which suggests topics and resources for the student to try based on the student model. ElectronixTutor uses a Moodle interface, and is accessible to anyone via a web browser. Currently, ElectronixTutor is being tested by undergraduate electronics students before supplementing Naval Apprentice Technician Training coursework in the fall of 2018.","dragoon, computer agents, autotutor, STEM education, electronics, intelligent tutoring systems","","L@S '18"
"Conference Paper","Chan KI,Lei PI,Pang PC","A Literature Review on Educational Data Mining with Secondary School Data","","2023","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 9th International Conference on Education and Training Technologies","Macau, China","2023","9781450399593","","https://doi.org/10.1145/3599640.3599659;http://dx.doi.org/10.1145/3599640.3599659","10.1145/3599640.3599659","This paper presents a literature review on educational data mining (EDM) with secondary school data, amid other literature reviews mostly focus on the data collected from online learning and higher education. EDM is useful for discovering potential patterns in learning data which is beneficial for enhancing learning contexts within the educational system. This literature review uses secondary schools as a basis and intends to summarise the progress made in applying EDM techniques. We have reviewed 18 relevant papers published between 2008 and 2021, and classified these papers based on application scenarios. We found that there are relatively few corresponding studies on the EDM applications in secondary school data, and the existing studies are mostly on classifying students’ academic success or failure, analysing influence factors, identifying their future directions, and discovering the potential dropout risks. In terms of the algorithms used, a majority of research relies on traditional machine learning methods. Deep learning and existing knowledge tracing models are rarely adopted in such scenarios despite their rapid development. Even though EDM is growing rapidly, its research and applications in secondary schools present a clear research gap. Future EDM research should be broadly extended to secondary school settings to remedy this space.","High School, Schooling Data, Academic Performance, Secondary School, Data Mining, Students’ Performance, Academic Success or Failure, Prediction, Traditional Classroom, Schooling, Literature Review, Machine Learning, Educational Data Mining (EDM)","","ICETT '23"
"Conference Paper","Lan AS,Studer C,Baraniuk RG","Time-Varying Learning and Content Analytics via Sparse Factor Analysis","","2014","","","452–461","Association for Computing Machinery","New York, NY, USA","Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","New York, New York, USA","2014","9781450329569","","https://doi.org/10.1145/2623330.2623631;http://dx.doi.org/10.1145/2623330.2623631","10.1145/2623330.2623631","We propose SPARFA-Trace, a new machine learning-based framework for time-varying learning and content analytics for educational applications. We develop a novel message passing-based, blind, approximate Kalman filter for sparse factor analysis (SPARFA) that jointly traces learner concept knowledge over time, analyzes learner concept knowledge state transitions (induced by interacting with learning resources, such as textbook sections, lecture videos, etc., or the forgetting effect), and estimates the content organization and difficulty of the questions in assessments. These quantities are estimated solely from binary-valued (correct/incorrect) graded learner response data and the specific actions each learner performs (e.g., answering a question or studying a learning resource) at each time instant. Experimental results on two online course datasets demonstrate that SPARFA-Trace is capable of tracing each learner's concept knowledge evolution over time, analyzing the quality and content organization of learning resources, and estimating the question--concept associations and the question difficulties. Moreover, we show that SPARFA-Trace achieves comparable or better performance in predicting unobserved learner responses compared to existing collaborative filtering and knowledge tracing methods.","sparse factor analysis, learning analytics, expectation maximization, personalized learning, kalman filter","","KDD '14"
"Conference Paper","Conati C,Zhao X","Building and Evaluating an Intelligent Pedagogical Agent to Improve the Effectiveness of an Educational Game","","2004","","","6–13","Association for Computing Machinery","New York, NY, USA","Proceedings of the 9th International Conference on Intelligent User Interfaces","Funchal, Madeira, Portugal","2004","9781581138153","","https://doi.org/10.1145/964442.964446;http://dx.doi.org/10.1145/964442.964446","10.1145/964442.964446","Electronic educational games can be highly entertaining, but studies have shown that they do not always trigger learning. To enhance the effectiveness of educational games, we propose intelligent pedagogical agents that can provide individualized instruction integrated with the entertaining nature of the games. In this paper, we describe one such agent, that we have developed for Prime Climb, an educational game on number factorization. The Prime Climb agent relies on a probabilistic student model to generate tailored interventions aimed at helping students learn number factorization through the game. After describing the functioning of the agent and the underlying student model, we report the results of an empirical study that we performed to test the agent's effectiveness.","intelligent agents, user modeling, dynamic Bayesian networks, educational games","","IUI '04"
"Conference Paper","Kang S,Kweon W,Lee D,Lian J,Xie X,Yu H","Distillation from Heterogeneous Models for Top-K Recommendation","","2023","","","801–811","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM Web Conference 2023","Austin, TX, USA","2023","9781450394161","","https://doi.org/10.1145/3543507.3583209;http://dx.doi.org/10.1145/3543507.3583209","10.1145/3543507.3583209","Recent recommender systems have shown remarkable performance by using an ensemble of heterogeneous models. However, it is exceedingly costly because it requires resources and inference latency proportional to the number of models, which remains the bottleneck for production. Our work aims to transfer the ensemble knowledge of heterogeneous teachers to a lightweight student model using knowledge distillation (KD), to reduce the huge inference costs while retaining high accuracy. Through an empirical study, we find that the efficacy of distillation severely drops when transferring knowledge from heterogeneous teachers. Nevertheless, we show that an important signal to ease the difficulty can be obtained from the teacher’s training trajectory. This paper proposes a new KD framework, named HetComp, that guides the student model by transferring easy-to-hard sequences of knowledge generated from the teachers’ trajectories. To provide guidance according to the student’s learning state, HetComp uses dynamic knowledge construction to provide progressively difficult ranking knowledge and adaptive knowledge transfer to gradually transfer finer-grained ranking information. Our comprehensive experiments show that HetComp significantly improves the distillation quality and the generalization of the student model.","Recommender system, Knowledge distillation, Model compression, Easy-to-hard learning","","WWW '23"
"Journal Article","Shen P,Lu X,Li S,Kawai H","Knowledge Distillation-Based Representation Learning for Short-Utterance Spoken Language Identification","IEEE/ACM Trans. Audio, Speech and Lang. Proc.","2020","28","","2674–2683","IEEE Press","","","","2020-09","","2329-9290","https://doi.org/10.1109/TASLP.2020.3023627;http://dx.doi.org/10.1109/TASLP.2020.3023627","10.1109/TASLP.2020.3023627","With successful applications of deep feature learning algorithms, spoken language identification (LID) on long utterances obtains satisfactory performance. However, the performance on short utterances is drastically degraded even when the LID system is trained using short utterances. The main reason is due to the large variation of the representation on short utterances which results in high model confusion. To narrow the performance gap between long, and short utterances, we proposed a teacher-student representation learning framework based on a knowledge distillation method to improve LID performance on short utterances. In the proposed framework, in addition to training the student model on short utterances with their true labels, the internal representation from the output of a hidden layer of the student model is supervised with the representation corresponding to their longer utterances. By reducing the distance of internal representations between short, and long utterances, the student model can explore robust discriminative representations for short utterances, which is expected to reduce model confusion. We conducted experiments on our in-house LID dataset, and NIST LRE07 dataset, and showed the effectiveness of the proposed methods for short utterance LID tasks.","","",""
"Conference Paper","Alday RB","Bayesian Networks in Intelligent Tutoring Systems as an Assessment of Student Performance Using Student Modeling","","2018","","","119–122","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2nd International Conference on Algorithms, Computing and Systems","Beijing, China","2018","9781450365093","","https://doi.org/10.1145/3242840.3242867;http://dx.doi.org/10.1145/3242840.3242867","10.1145/3242840.3242867","This paper developed a model for designing an intelligent tutoring system for any programming language using Bayesian networks. The design model of the tutoring system considers a user model using student model. The Bayesian network was used to assess the current state of knowledge of the student so that the model can adjust and present new knowledge to improve student performance as an outcome in an e-learning environment.","intelligent tutoring system, bayesian networks, student modelling","","ICACS '18"
"Conference Paper","Zhu J,Liu J,Li W,Lai J,He X,Chen L,Zheng Z","Ensembled CTR Prediction via Knowledge Distillation","","2020","","","2941–2958","Association for Computing Machinery","New York, NY, USA","Proceedings of the 29th ACM International Conference on Information & Knowledge Management","Virtual Event, Ireland","2020","9781450368599","","https://doi.org/10.1145/3340531.3412704;http://dx.doi.org/10.1145/3340531.3412704","10.1145/3340531.3412704","Recently, deep learning-based models have been widely studied for click-through rate (CTR) prediction and lead to improved prediction accuracy in many industrial applications. However, current research focuses primarily on building complex network architectures to better capture sophisticated feature interactions and dynamic user behaviors. The increased model complexity may slow down online inference and hinder its adoption in real-time applications. Instead, our work targets at a new model training strategy based on knowledge distillation (KD). KD is a teacher-student learning framework to transfer knowledge learned from a teacher model to a student model. The KD strategy not only allows us to simplify the student model as a vanilla DNN model but also achieves significant accuracy improvements over the state-of-the-art teacher models. The benefits thus motivate us to further explore the use of a powerful ensemble of teachers for more accurate student model training. We also propose some novel techniques to facilitate ensembled CTR prediction, including teacher gating and early stopping by distillation loss. We conduct comprehensive experiments against 12 existing models and across three industrial datasets. Both offline and online A/B testing results show the effectiveness of our KD-based training strategy.","online advertising, model ensemble, recommender systems, ctr prediction, knowledge distillation","","CIKM '20"
"Conference Paper","Mees M,Jay T,Habgood J,Howard-Jones P","Researching Adaptivity for Individual Differences in Numeracy Games","","2017","","","247–253","Association for Computing Machinery","New York, NY, USA","Extended Abstracts Publication of the Annual Symposium on Computer-Human Interaction in Play","Amsterdam, The Netherlands","2017","9781450351119","","https://doi.org/10.1145/3130859.3131315;http://dx.doi.org/10.1145/3130859.3131315","10.1145/3130859.3131315","There is increasing evidence that mathematics video games can play a large role in mathematics education, in support of children's learning. However, despite the interdisciplinary nature of the subject, research in this area has traditionally been fragmented between disciplines. The RAIDING project was conceived to bring together researchers in neuroscience, maths cognition, and game-based learning to develop a maths game that can act as a research platform for furthering knowledge in this field. The game will employ free-to-play design elements, alongside an adaptive learner model to investigate how children learn maths, through a range of empirical studies.","mathematics cognition, analytics, game based learning, adaptivity, free-to-play","","CHI PLAY '17 Extended Abstracts"
"Conference Paper","Chung JW,Kim JY,Moon SM","ShadowTutor: Distributed Partial Distillation for Mobile Video DNN Inference","","2020","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 49th International Conference on Parallel Processing","Edmonton, AB, Canada","2020","9781450388160","","https://doi.org/10.1145/3404397.3404404;http://dx.doi.org/10.1145/3404397.3404404","10.1145/3404397.3404404","Following the recent success of deep neural networks (DNN) on video computer vision tasks, performing DNN inferences on videos that originate from mobile devices has gained practical significance. As such, previous approaches developed methods to offload DNN inference computations for images to cloud servers to manage the resource constraints of mobile devices. However, when it comes to video data, communicating information of every frame consumes excessive network bandwidth and renders the entire system susceptible to adverse network conditions such as congestion. Thus, in this work, we seek to exploit the temporal coherence between nearby frames of a video stream to mitigate network pressure. That is, we propose ShadowTutor, a distributed video DNN inference framework that reduces the number of network transmissions through intermittent knowledge distillation to a student model. Moreover, we update only a subset of the student’s parameters, which we call partial distillation, to reduce the data size of each network transmission. Specifically, the server runs a large and general teacher model, and the mobile device only runs an extremely small but specialized student model. On sparsely selected key frames, the server partially trains the student model by targeting the teacher’s response and sends the updated part to the mobile device. We investigate the effectiveness of ShadowTutor with HD video semantic segmentation. Evaluations show that network data transfer is reduced by 95% on average. Moreover, the throughput of the system is improved by over three times and shows robustness to changes in network bandwidth.","knowledge distillation, video semantic segmentation, distributed inference, Deep neural networks","","ICPP '20"
"Conference Paper","Li X,Qiu Z,Zhao X,Zhang Y,Xing C,Wu X","REST: Drug-Drug Interaction Prediction via Reinforced Student-Teacher Curriculum Learning","","2023","","","1278–1287","Association for Computing Machinery","New York, NY, USA","Proceedings of the 32nd ACM International Conference on Information and Knowledge Management","Birmingham, United Kingdom","2023","","","https://doi.org/10.1145/3583780.3615033;http://dx.doi.org/10.1145/3583780.3615033","10.1145/3583780.3615033","Accurate prediction of drug-drug interaction (DDI) is crucial to achieving effective decision-making in medical treatment for both doctors and patients. Recently, many deep learning based methods have been proposed to learn from drug-related features and conduct DDI prediction. These works have achieved promising results. However, the extreme imbalance of medical data poses a serious problem to DDI prediction, where a small fraction of DDI types occupy the majority training data. A straightforward way is to develop an appropriate policy to sample the data. Due to the high complexity and speciality of medical science, a dynamic learnable policy is required instead of a heuristic, uniform or static one. Therefore, we propose a REinforced Student-Teacher curriculum learning model (REST) for effective sampling to tackle this imbalance problem. Specifically, REST consists of two interactive parts, which are a heterogeneous graph neural network as the student and a reinforced sampler as the teacher. In each interaction, the teacher model takes action to sample an appropriate batch to train the student model according to the student model state while the cumulated improvement in performance of the student model is treated as the reward for policy gradient of the teacher model. The experimental results on two benchmarking datasets have demonstrated the significant effectiveness of our proposed model in DDI prediction, especially for the DDI types with low frequency.","drug-drug interaction, heterogeneous graph neural network, curriculum learning, reinforcement learning","","CIKM '23"
"Conference Paper","Shi H,Wang Z,Lv J,Wang Y,Zhang P,Zhu F,Li Q","Semi-Supervised Learning via Improved Teacher-Student Network for Robust 3D Reconstruction of Stereo Endoscopic Image","","2021","","","4661–4669","Association for Computing Machinery","New York, NY, USA","Proceedings of the 29th ACM International Conference on Multimedia","Virtual Event, China","2021","9781450386517","","https://doi.org/10.1145/3474085.3475527;http://dx.doi.org/10.1145/3474085.3475527","10.1145/3474085.3475527","3D reconstruction of stereo endoscope image, as an enabling technique for varied surgical systems, e.g., medical droids, navigations, etc., suffers from severe overfitting problems due to scarce labels. Semi-supervised learning based on Teacher-Student Network (TSN) is a potential solution, which utilizes a supervised teacher model trained on available labeled data to teach a student model on all images via assigning them pseudo labels. However, TSN often faces a dilemma: if given only few labeled endoscope images, the teacher model will be trained to be defective and induce high-noised pseudo labels, degrading the student model significantly. To solve this, we propose an improved TSN for a robust 3D reconstruction of stereo endoscope image. Specifically, two novel modules are introduced: 1) a semi-supervised teacher model based on adversarial learning to produce mostly correct pseudo labels by forcing a consistency in predictions for both labeled and unlabeled data, and 2) a confidence network to further filter out noisy pseudo labels by estimating a confidence for each prediction of the teacher model. By doing so, the student model is able to distill knowledge from more accurate and noiseless pseudo labels, thus achieving improved performance. Experimental results on two public datasets show that our improved TSN achieves a superior performance than the state-of-the-arts by reducing the averaged disparity error by at least 13.5%.","semi-supervised learning, stereo matching, teacher-student network, endoscopic image","","MM '21"
"Journal Article","Maries A,Kumar A","Concept Maps in Intelligent Tutors for Programming","J. Comput. Sci. Coll.","2007","22","3","54","Consortium for Computing Sciences in Colleges","Evansville, IN, USA","","","2007-01","","1937-4771","","","At Ramapo College of New Jersey, intelligent tutors, called problets, are being developed for programming concepts. We want to integrate concept maps into these tutors. They will be used for discovery learning, active learning, navigation, problem selection and to open the student model.","","",""
"Conference Paper","Seo S,Park S,Jeong C,Kim J","Knowledge Distillation Based Online Learning Methodology Using Unlabeled Data Stream","","2018","","","68–71","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2018 International Conference on Machine Learning and Machine Intelligence","Ha Noi, Viet Nam","2018","9781450365567","","https://doi.org/10.1145/3278312.3278319;http://dx.doi.org/10.1145/3278312.3278319","10.1145/3278312.3278319","In supervised learning, the performance of the learning model decreases with the change of time step due to concept drift caused by overfitting of the training data. As a methodology to mitigate such concept drift, an online learning methodology has been proposed that trains the learning model on continuously input data stream. In this paper, we proposed an online learning methodology in which teacher model continuously trains student model based on knowledge distillation theory. The teacher model generates the output distribution called soft label to make a label for the unlabeled data stream and the student model trained by the unlabeled data stream with the soft label from teacher model. Experimental results show that the proposed method has better performances such as classification accuracy than that of the batch learning model trained by labeled data stream only.","Knowledge Transfer, Knowledge Distillation, Concept Drift, Online Learning","","MLMI '18"
"Journal Article","Frengov A,Kumar A","Open Learner Models in Intelligent Tutoring System","J. Comput. Sci. Coll.","2007","22","3","63","Consortium for Computing Sciences in Colleges","Evansville, IN, USA","","","2007-01","","1937-4771","","","Intelligent tutors called problets are being developed at Ramapo College to help Computer Science I students learn programming by solving problems. Intelligent tutoring systems literature shows that by opening the student model, i.e., a record of the student's progress, the tutoring system may actually enhance and speed up the learning process.","","",""
"Conference Paper","Lyu L,Chen CH","Differentially Private Knowledge Distillation for Mobile Analytics","","2020","","","1809–1812","Association for Computing Machinery","New York, NY, USA","Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","Virtual Event, China","2020","9781450380164","","https://doi.org/10.1145/3397271.3401259;http://dx.doi.org/10.1145/3397271.3401259","10.1145/3397271.3401259","The increasing demand for on-device deep learning necessitates the deployment of deep models on mobile devices. However, directly deploying deep models on mobile devices presents both capacity bottleneck and prohibitive privacy risk. To address these problems, we develop a Differentially Private Knowledge Distillation (DPKD) framework to enable on-device deep learning as well as preserve training data privacy. We modify the conventional Private Aggregation of Teacher Ensembles (PATE) paradigm by compressing the knowledge acquired by the ensemble of teachers into a student model in a differentially private manner. The student model is then trained on both the labeled, public data and the distilled knowledge by adopting a mixed training algorithm. Extensive experiments on popular image datasets, as well as the real implementation on a mobile device show that DPKD can not only benefit from the distilled knowledge but also provide a strong differential privacy guarantee (ε=2$) with only marginal decreases in accuracy.","deep learning, privacy-preserving, knowledge distillation","","SIGIR '20"
"Conference Paper","Liu Z,Yang S,Tang J,Heffernan N,Luckin R","Recent Advances in Multimodal Educational Data Mining in K-12 Education","","2020","","","3549–3550","Association for Computing Machinery","New York, NY, USA","Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","Virtual Event, CA, USA","2020","9781450379984","","https://doi.org/10.1145/3394486.3406471;http://dx.doi.org/10.1145/3394486.3406471","10.1145/3394486.3406471","Recently we have seen a rapid rise in the amount of education data available through the digitization of education. This huge amount of education data usually exhibits in a mixture form of images, videos, speech, texts, etc. It is crucial to consider data from different modalities to build successful applications in AI in education (AIED). This tutorial targets AI researchers and practitioners who are interested in applying state-of-the-art multimodal machine learning techniques to tackle some of the hard-core AIED tasks. These include tasks such as automatic short answer grading, student assessment, class quality assurance, knowledge tracing, etc.In this tutorial, we will comprehensively review recent developments of applying multimodal learning approaches in AIED, with a focus on those classroom multimodal data. Beyond introducing the recent advances of computer vision, speech, natural language processing in education respectively, we will discuss how to combine data from different modalities and build AI driven educational applications on top of these data. More specifically, we will talk about (1) representation learning; (2) algorithmic assessment & evaluation; and (3) personalized feedback. Participants will learn about recent trends and emerging challenges in this topic, representative tools and learning resources to obtain ready-to-use models, and how related models and techniques benefit real-world AIED applications.","multimodal learning, k-12 education, educational data mining","","KDD '20"
"Conference Paper","Brusilovsky P","KnowledgeTree: A Distributed Architecture for Adaptive e-Learning","","2004","","","104–113","Association for Computing Machinery","New York, NY, USA","Proceedings of the 13th International World Wide Web Conference on Alternate Track Papers & Posters","New York, NY, USA","2004","9781581139129","","https://doi.org/10.1145/1013367.1013386;http://dx.doi.org/10.1145/1013367.1013386","10.1145/1013367.1013386","This paper presents KnowledgeTree, an architecture for adaptive E-Learning based on distributed reusable intelligent learning activities. The goal of KnowledgeTree is to bridge the gap between the currently popular approach to Web-based education, which is centered on learning management systems vs. the powerful but underused technologies in intelligent tutoring and adaptive hypermedia. This integrative architecture attempts to address both the component-based assembly of adaptive systems and teacher-level reusability.","student model server, e-learning, learning portal, adaptive content service, content re-use, adaptive web, learning object metadata","","WWW Alt. '04"
"Conference Paper","Liu Z","A Practical Guide to Robust Multimodal Machine Learning and Its Application in Education","","2022","","","1646","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining","Virtual Event, AZ, USA","2022","9781450391320","","https://doi.org/10.1145/3488560.3510010;http://dx.doi.org/10.1145/3488560.3510010","10.1145/3488560.3510010","Recently we have seen a rapid rise in the amount of education data available through the digitization of education. This huge amount of education data usually exhibits in a mixture form of images, videos, speech, texts, etc. It is crucial to consider data from different modalities to build successful applications in AI in education (AIED). This talk targets AI researchers and practitioners who are interested in applying state-of-the-art multimodal machine learning techniques to tackle some of the hard-core AIED tasks. These include tasks such as automatic short answer grading, student assessment, class quality assurance, knowledge tracing, etc.In this talk, I will share some recent developments of successfully applying multimodal learning approaches in AIED, with a focus on those classroom multimodal data. Beyond introducing the recent advances of computer vision, speech, natural language processing in education respectively, I will discuss how to combine data from different modalities and build AI driven educational applications on top of these data. Participants will learn about recent trends and emerging challenges in this topic, representative tools and learning resources to obtain ready-to-use models, and how related models and techniques benefit real-world AIED applications.","online education, multimodal machine learning, ai in education","","WSDM '22"
"Conference Paper","Han J,Zhao T,Zhang C","Deep Distillation Metric Learning","","2020","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM Multimedia Asia","Beijing, China","2020","9781450368414","","https://doi.org/10.1145/3338533.3366560;http://dx.doi.org/10.1145/3338533.3366560","10.1145/3338533.3366560","Due to the emergence of large-scale and high-dimensional data, measuring the similarity between data points becomes challenging. In order to obtain effective representations, metric learning has become one of the most active researches in the field of computer vision and pattern recognition. However, models using trained networks for predictions are often cumbersome and difficult to be deployed. Therefore, in this paper, we propose a novel deep distillation metric learning (DDML) for online teaching in the procedure of learning the distance metric. Specifically, we employ model distillation to transfer the knowledge acquired by the larger model to the smaller model. Unlike the 2-step offline and mutual online manners, we propose to train a powerful teacher model, who transfer the knowledge to a lightweight and generalizable student model and iteratively improved by the feedback from the student model. We show that our method has achieved state-of-the-art results on CUB200-2011 and CARS196 while having advantages in computational efficiency.","metric learning, model distillation, deep learning","","MMAsia '19"
"Conference Paper","Khan FA,Graf S,Weippl ER,Tjoa AM","An Approach for Identifying Affective States through Behavioral Patterns in Web-Based Learning Management Systems","","2009","","","431–435","Association for Computing Machinery","New York, NY, USA","Proceedings of the 11th International Conference on Information Integration and Web-Based Applications & Services","Kuala Lumpur, Malaysia","2009","9781605586601","","https://doi.org/10.1145/1806338.1806418;http://dx.doi.org/10.1145/1806338.1806418","10.1145/1806338.1806418","In a learning environment, the students experience different affective states. Learning environments that takes into account the students' affective state enhance the students' learning, gain and experience. Therefore, it is crucial to provide students with different learning material and activities according to different affective states. To provide learning that considers students' affective states, the primary step is the detection of affective states of a student. In this paper, we present an approach for the detection of affective states from the patterns of students' behavior observed during an online course. By calculating the affective states and then filling that affective state data into the student model of a learning management system a basis for adaptivity is provided.","confusion, independence, adaptive learning systems, effort, confidence, human computer interaction, affective states","","iiWAS '09"
"Conference Paper","Spaulding S,Gordon G,Breazeal C","Affect-Aware Student Models for Robot Tutors","","2016","","","864–872","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems","Singapore, Singapore","2016","9781450342391","","","","Computational tutoring systems, such as educational software or interactive robots, have the potential for great societal benefit. Such systems track and assess students' knowledge via inferential methods, such as the popular Bayesian Knowledge Tracing (BKT) algorithm. However, these methods do not typically draw on the affective signals that human teachers use to assess knowledge, such as indications of discomfort, engagement, or frustration.In this paper we present a novel extension to the BKT model that uses affective data, derived autonomously from video records of children playing an interactive story-telling game with a robot, to infer student knowledge of reading skills. We find that, compared to a control group of children who played the game with only a tablet, children who interacted with an embodied social robot generated stronger affective data signals of engagement and enjoyment during the interaction. We then show that incorporating this affective data into model training improves the quality of the learned knowledge inference models.These results suggest that physically embodied, affect-aware robot tutors can provide more effective and empathic educational experiences for children, and advance both algorithmic and human-centered motivations for further development of systems that tightly integrate affect understanding and complex models of inference with interactive, educational robots.","educational robots, affective computing, child-robot interaction, socially assistive robots","","AAMAS '16"
"Conference Paper","Raj NS,Renumol VG","Architecture of an Adaptive Personalized Learning Environment (APLE) for Content Recommendation","","2018","","","17–22","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2nd International Conference on Digital Technology in Education","Bangkok, Thailand","2018","9781450365994","","https://doi.org/10.1145/3284497.3284503;http://dx.doi.org/10.1145/3284497.3284503","10.1145/3284497.3284503","With the development of sophisticated learning environments and learner-centric didactic approaches, personalized learning is in high demand. Personalization in learning environments occurs when such systems fit the learner profiles, which help in increasing their performance and quality of learning. Personalized learning refers to the pedagogy where the pace of learning, the instructional preferences and the learning objects are optimized as per the needs of each learner. To support customization, recommender systems can be used to recommend appropriate learning objects (LOs) corresponding to the learner attributes. This paper proposes an architecture of an Adaptive Personalized Learning Environment (APLE) and its features. APLE assists the learners by content recommendation and adapts to the learning preferences and performance of the learner. It has three modules such as Learner modelling Unit (LModU), Content Managing Unit (CMU) and Learner Monitoring Unit (LMU). LModU creates a Learner Model (LM) from the learner attributes.The system proposes to represent learner attributes as an ontology and learner modelling using Dynamic Bayesian Networks. The LMU should perform the knowledge assessment of the learner and monitor their changing preferences. CMU got two components, LO Manager and Content Recommendation Engine (CRE). LO Manager is responsible for creating the metadata corresponding to the learning resource following the IEEE LOM specification. CRE is an expert system which will map the learner attribute with the LOs. Currently, the CRE is implemented as a rule-based prediction engine where the rules represent the association between each LOM field with the learner attributes. This on-going research work aims at answering questions regarding the feasibility and effectiveness of mapping LO attributes and learner attributes.","Content Recommendation, Learning Object, Learner Modelling, Personalized Learning","","ICDTE '18"
"Conference Paper","Spaulding S,Shen J,Park H,Breazeal C","Towards Transferrable Personalized Student Models in Educational Games","","2021","","","1245–1253","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems","Virtual Event, United Kingdom","2021","9781450383073","","","","To help facilitate play and learning, game-based educational activities often feature a computational agent as a co-player. Personalizing this agent's behavior to the student player is an active area of research, and prior work has demonstrated the benefits of personalized educational interaction across a variety of domains. A critical research challenge for personalized educational agents is real-time student modeling. Most student models are designed for and trained on only a single task, which limits the variety, flexibility, and efficiency of student player model learning. In this paper we present a research project applying transfer learning methods to student player models over different educational tasks, studying the effects of an algorithmic ""multi-task personalization"" approach on the accuracy and data efficiency of student model learning. We describe a unified robotic game system for studying multi-task personalization over two different educational games, each emphasizing early language and literacy skills such as rhyming and spelling. We present a flexible Gaussian Process-based approach for rapidly learning student models from interactive play in each game, and a method for transferring each game's learned student model to the other via a novel instance-weighting protocol based on task similarity. We present results from a simulation-based investigation of the impact of multi-task personalization, establishing the core viability and benefits of transferrable student models and outlining new questions for future in-person research.","human-robot interaction, user modeling, transfer learning, educational games","","AAMAS '21"
"Conference Paper","Guerra C,Melo FS,Lopes M","Teaching Unknown Learners to Classify via Feature Importance","","2021","","","1524–1526","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems","Virtual Event, United Kingdom","2021","9781450383073","","","","In this work we introduce an interactive machine teaching approach that teaches a classification task to the learner. Our adaptive approach - Feature Importance Teaching (FIT) - does not assume perfect knowledge about the learner, as most machine teaching approaches do. It chooses, online, which sample to show next, as it updates the learner's model based on feedback from the student on the weights attributed to the features. We present simulated results where the student has a different prior knowledge from the one assumed by the teacher. The results have shown that our teaching approach can mitigate this mismatch and lead to a significantly faster learning curve than the ones obtained in conditions where the teacher randomly selects the samples or does not consider this feedback from the student.","interactivity, machine teaching, classification tasks","","AAMAS '21"
"Journal Article","Koedinger KR,McLaughlin EA,Stamper JC","Data-Driven Learner Modeling to Understand and Improve Online Learning: MOOCs and Technology to Advance Learning and Learning Research (Ubiquity Symposium)","Ubiquity","2014","2014","May","","Association for Computing Machinery","New York, NY, USA","","","2014-05","","","https://doi.org/10.1145/2591682;http://dx.doi.org/10.1145/2591682","10.1145/2591682","Advanced educational technologies are developing rapidly and online MOOC courses are becoming more prevalent, creating an enthusiasm for the seemingly limitless data-driven possibilities to affect advances in learning and enhance the learning experience. For these possibilities to unfold, the expertise and collaboration of many specialists will be necessary to improve data collection, to foster the development of better predictive models, and to assure models are interpretable and actionable. The big data collected from MOOCs needs to be bigger, not in its height (number of students) but in its width more meta-data and information on learners' cognitive and self-regulatory states needs to be collected in addition to correctness and completion rates. This more detailed articulation will help open up the black box approach to machine learning models where prediction is the primary goal. Instead, a data-driven learner model approach uses fine grain data that is conceived and developed from cognitive principles to build explanatory models with practical implications to improve student learning.","","",""
"Conference Paper","Jia R,Cao Y,Shi H,Fang F,Liu Y,Tan J","DistilSum: Distilling the Knowledge for Extractive Summarization","","2020","","","2069–2072","Association for Computing Machinery","New York, NY, USA","Proceedings of the 29th ACM International Conference on Information & Knowledge Management","Virtual Event, Ireland","2020","9781450368599","","https://doi.org/10.1145/3340531.3412078;http://dx.doi.org/10.1145/3340531.3412078","10.1145/3340531.3412078","A popular choice for extractive summarization is to conceptualize it as sentence-level classification, supervised by binary labels. While the common metric ROUGE prefers to measure the text similarity, instead of the performance of classifier. For example, BERTSUMEXT, the best extractive classifier so far, only achieves a precision of 32.9% at the top 3 extracted sentences (P@3) on CNN/DM dataset. It is obvious that current approaches cannot model the complex relationship of sentences exactly with 0/1 targets. In this paper, we introduce DistilSum, which contains teacher mechanism and student model. Teacher mechanism produces high entropy soft targets at a high temperature. Our student model is trained with the same temperature to match these informative soft targets and tested with temperature of 1 to distill for ground-truth labels. Compared with large version of BERTSUMEXT, our experimental result on CNN/DM achieves a substantial improvement of 0.99 ROUGE-L score (text similarity) and 3.95 P@3 score (performance of classifier). Our source code will be available on Github.","knowledge distillation, summarization, neural networks","","CIKM '20"
"Conference Paper","Lin Z,Gong Y,Liu X,Zhang H,Lin C,Dong A,Jiao J,Lu J,Jiang D,Majumder R,Duan N","PROD: Progressive Distillation for Dense Retrieval","","2023","","","3299–3308","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM Web Conference 2023","Austin, TX, USA","2023","9781450394161","","https://doi.org/10.1145/3543507.3583421;http://dx.doi.org/10.1145/3543507.3583421","10.1145/3543507.3583421","Knowledge distillation is an effective way to transfer knowledge from a strong teacher to an efficient student model. Ideally, we expect the better the teacher is, the better the student performs. However, this expectation does not always come true. It is common that a strong teacher model results in a bad student via distillation due to the nonnegligible gap between teacher and student. To bridge the gap, we propose PROD, a PROgressive Distillation method, for dense retrieval. PROD consists of a teacher progressive distillation and a data progressive distillation to gradually improve the student. To alleviate catastrophic forgetting, we introduce a regularization term in each distillation process. We conduct extensive experiments on seven datasets including five widely-used publicly available benchmarks: MS MARCO Passage, TREC Passage 19, TREC Document 19, MS MARCO Document, and Natural Questions, as well as two industry datasets: Bing-Rel and Bing-Ads. PROD achieves the state-of-the-art in the distillation methods for dense retrieval. Our 6-layer student model even surpasses most of the existing 12-layer models on all five public benchmarks. The code and models are released in https://github.com/microsoft/SimXNS.","Neural Ranking Models, Dense Retrieval, Knowledge Distillation","","WWW '23"
"Conference Paper","Fu Y,Xie Y,Fu Y,Chen J,Jiang YG","ME-D2N: Multi-Expert Domain Decompositional Network for Cross-Domain Few-Shot Learning","","2022","","","6609–6617","Association for Computing Machinery","New York, NY, USA","Proceedings of the 30th ACM International Conference on Multimedia","Lisboa, Portugal","2022","9781450392037","","https://doi.org/10.1145/3503161.3547995;http://dx.doi.org/10.1145/3503161.3547995","10.1145/3503161.3547995","Recently, Cross-Domain Few-Shot Learning (CD-FSL) which aims at addressing the Few-Shot Learning (FSL) problem across different domains has attracted rising attention. The core challenge of CD-FSL lies in the domain gap between the source and novel target datasets. Though many attempts have been made for CD-FSL without any target data during model training, the huge domain gap makes it still hard for existing CD-FSL methods to achieve very satisfactory results. Alternatively, learning CD-FSL models with few labeled target domain data which is more realistic and promising is advocated in previous work. Thus, in this paper, we stick to this setting and technically contribute a novel Multi-Expert Domain Decompositional Network (ME-D2N). Concretely, to solve the data imbalance problem between the source data with sufficient examples and the auxiliary target data with limited examples, we build our model under the umbrella of multi-expert learning. Two teacher models which can be considered to be experts in their corresponding domain are first trained on the source and the auxiliary target sets, respectively. Then, the knowledge distillation technique is introduced to transfer the knowledge from two teachers to a unified student model. Taking a step further, to help our student model learn knowledge from different domain teachers simultaneously, we further present a novel domain decomposition module that learns to decompose the student model into two domain-related sub-parts. This is achieved by a novel domain-specific gate that learns to assign each filter to only one specific domain in a learnable way. Extensive experiments demonstrate the effectiveness of our method. Codes and models are available at https://github.com/lovelyqian/ME-D2N_for_CDFSL.","multi-expert learning, cross-domain few-shot learning, network decomposition., classification for unbalanced data","","MM '22"
"Conference Paper","Effenberger T,Pelánek R,Čechák J","Exploration of the Robustness and Generalizability of the Additive Factors Model","","2020","","","472–479","Association for Computing Machinery","New York, NY, USA","Proceedings of the Tenth International Conference on Learning Analytics & Knowledge","Frankfurt, Germany","2020","9781450377126","","https://doi.org/10.1145/3375462.3375491;http://dx.doi.org/10.1145/3375462.3375491","10.1145/3375462.3375491","Additive Factors Model is a widely used student model, which is primarily used for refining knowledge component models (Q-matrices). We explore the robustness and generalizability of the model. We explicitly formulate simplifying assumptions that the model makes and we discuss methods for visualizing learning curves based on the model. We also report on an application of the model to data from a learning system for introductory programming; these experiments illustrate possibly misleading interpretation of model results due to differences in item difficulty. Overall, our results show that greater care has to be taken in the application of the model and in the interpretation of results obtained with the model.","student modeling, learning curves, knowledge components, introductory programming","","LAK '20"
"Journal Article","Dittus M,Capra L","Private Peer Feedback as Engagement Driver in Humanitarian Mapping","Proc.  ACM Hum. -Comput.  Interact.","2017","1","CSCW","","Association for Computing Machinery","New York, NY, USA","","","2017-12","","","https://doi.org/10.1145/3134675;http://dx.doi.org/10.1145/3134675","10.1145/3134675","Prior research suggests that public negative feedback on social knowledge sharing platforms can be powerfully demotivating to newcomers, particularly when it involves peer feedback mechanisms such as ratings and commenting systems. What is the impact on newcomer retention when feedback is private, and from a single peer reviewer? We study these effects using the example of the Humanitarian OpenStreetMap Team, a Wikipedia-style social mapping platform where the review process is closer to a teacher-learner model rather than a public peer review. We observe peer feedback for early contributions by 1,300 newcomers, and assess the impact of different classes of feedback, including performance feedback, corrective feedback, and verbal rewards. We find that verbal rewards and immediate feedback can have a powerful effect on newcomer retention. In order to better support such positive engagement effects, we recommend that system designers conceptually distinguish between mechanisms for quality control and for learner feedback.","crowdsourcing, peer feedback, retention, engagement, motivations, crowdmapping, rewards","",""
"Conference Paper","Desmarais MC","Performance Comparison of Item-to-Item Skills Models with the IRT Single Latent Trait Model","","2011","","","75–86","Springer-Verlag","Berlin, Heidelberg","Proceedings of the 19th International Conference on User Modeling, Adaption, and Personalization","Girona, Spain","2011","9783642223617","","","","Assessing a learner's mastery of a set of skills is a fundamental issue in intelligent learning environments. We compare the predictive performance of two approaches for training a learner model with domain data. One is based on the principle of building the model solely from observable data items, such as exercises or test items. Skills modelling is not part of the training phase, but instead dealt with at later stage. The other approach incorporates a single latent skill in the model. We compare the capacity of both approaches to accurately predict item outcome (binary success or failure) from a subset of item outcomes. Three types of item-to-item models based on standard Bayesian modeling algorithms are tested: (1) Naive Bayes, (2) Tree-Augmented Naive Bayes (TAN), and (3) a K2 Bayesian Classifier. Their performance is compared to the widely used IRT-2PL approach which incorporates a single latent skill. The results show that the item-to-item approaches perform as well, or better than the IRT-2PL approach over 4 widely different data sets, but the differences vary considerably among the data sets. We discuss the implications of these results and the issues relating to the practical use of item-to-item models.","TAN, learner models, IRT, Bayesian models","","UMAP'11"
"Conference Paper","Feng Y,Tang X,Wang X,Zhao L","Contrast-Teacher-Student(CTS): A Novel Semi-Supervised Learning Approach for Sleep Staging","","2023","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence","Sanya, China","2023","9781450398336","","https://doi.org/10.1145/3579654.3579726;http://dx.doi.org/10.1145/3579654.3579726","10.1145/3579654.3579726","Semi-supervised learning (SSL) can work well with limited labeled data and enormous unlabeled data. It is suitable for areas such as medical treatment or biological research, whose data is sufficient but the label is high-cost. Unfortunately, few researchers are doing relevant studies. In this paper, we propose Contrast-Teacher- Student(CTS) model, a novel semi-supervised learning approach for physiological signal processing which is important in the diagnosis of some diseases. Our method achieves good performance with only a small amount of labeled data, and our method outperforms the current mainstream semi-supervised learning methods on the public dataset.","Sleep Staging, Semi-supervised Learning, Contrast-Teacher-Student model(CTS), Dropout Method, Adaptive Weight Adjustment","","ACAI '22"
"Journal Article","Liu R,Sisman B,Gao G,Li H","Decoding Knowledge Transfer for Neural Text-to-Speech Training","IEEE/ACM Trans. Audio, Speech and Lang. Proc.","2022","30","","1789–1802","IEEE Press","","","","2022-05","","2329-9290","https://doi.org/10.1109/TASLP.2022.3171974;http://dx.doi.org/10.1109/TASLP.2022.3171974","10.1109/TASLP.2022.3171974","Neural end-to-end text-to-speech (TTS) is superior to conventional statistical methods in many ways. However, the exposure bias problem, that arises from the mismatch between the training and inference process in autoregressive models, remains an issue. It often leads to performance degradation in face of out-of-domain test data. To address this problem, we study a novel decoding knowledge transfer strategy, and propose a multi-teacher knowledge distillation (MT-KD) network for Tacotron2 TTS model. The idea is to pre-train two Tacotron2 TTS teacher models in teacher forcing and scheduled sampling modes, and transfer the pre-trained knowledge to a student model that performs free running decoding. We show that the MT-KD network provides an adequate platform for neural TTS training, where the student model learns to emulate the behaviors of the two teachers, at the same time, minimizing the mismatch between training and run-time inference. Experiments on both Chinese and English data show that MT-KD system consistently outperforms the competitive baselines in terms of naturalness, robustness and expressiveness for in-domain and out-of-domain test data. Furthermore, we show that knowledge distillation outperforms adversarial learning and data augmentation in addressing the exposure bias problem.","","",""
"Conference Paper","Xuan Y,Chen W,Yang S,Xie D,Lin L,Zhuang Y","Distilling Vision-Language Foundation Models: A Data-Free Approach via Prompt Diversification","","2023","","","4928–4938","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st ACM International Conference on Multimedia","Ottawa ON, Canada","2023","","","https://doi.org/10.1145/3581783.3611911;http://dx.doi.org/10.1145/3581783.3611911","10.1145/3581783.3611911","Data-Free Knowledge Distillation (DFKD) has shown great potential in creating a compact student model while alleviating the dependency on real training data by synthesizing surrogate data. However, prior arts are seldom discussed under distribution shifts, which may be vulnerable in real-world applications. Recent Vision-Language Foundation Models, e.g., CLIP, have demonstrated remarkable performance in zero-shot out-of-distribution generalization, yet consuming heavy computation resources. In this paper, we discuss the extension of DFKD to Vision-Language Foundation Models without access to the billion-level image-text datasets. The objective is to customize a student model for distribution-agnostic downstream tasks with given category concepts, inheriting the out-of-distribution generalization capability from the pre-trained foundation models. In order to avoid generalization degradation, the primary challenge of this task lies in synthesizing diverse surrogate images driven by text prompts. Since not only category concepts but also style information are encoded in text prompts, we propose three novel Prompt Diversification methods to encourage image synthesis with diverse styles, namely Mix-Prompt, Random-Prompt, and Contrastive-Prompt. Experiments on out-of-distribution generalization datasets demonstrate the effectiveness of the proposed methods, with Contrastive-Prompt performing the best.","out-of-distribution generalization, vision-language foundation model, data-free knowledge distillation","","MM '23"
"Conference Paper","Peña-Ayala A,Mizoguchi R","Intelligent Decision-Making Approach Based on Fuzzy-Causal Knowledge and Reasoning","","2012","","","534–543","Springer-Verlag","Berlin, Heidelberg","Proceedings of the 25th International Conference on Industrial Engineering and Other Applications of Applied Intelligent Systems: Advanced Research in Applied Artificial Intelligence","Dalian, China","2012","9783642310867","","https://doi.org/10.1007/978-3-642-31087-4_55;http://dx.doi.org/10.1007/978-3-642-31087-4_55","10.1007/978-3-642-31087-4_55","Our intelligent decision-making approach (IDMA) is an instance of cognitive computing. It applies causality as common sense reasoning and fuzzy logic as a representation for qualitative knowledge. Our IDMA collects raw knowledge of humans through psychological models to tailor a knowledge-base (KB). The KB manages different repositories (e.g., cognitive maps (CM) and an ontology) to depict the object of study. The IDMA traces fuzzy-causal inferences to simulate causal behavior and estimate causal outcomes for decision-making. In order to test our approach, it is linked to the sequencing module of an intelligent and adaptive web-based educational system (IAWBES). It is used to provide student-centered education and enhance the students' learning by intelligent and adaptive functionalities. The results reveal users of an experimental group reached 17% of better learning than their peers of the control group.","psychological models, ontology, fuzzy-causal reasoning, knowledge-base, content model, decision-making, student model, cognitive map","","IEA/AIE'12"
"Conference Paper","Liu H,Feng S,Qiao C","A Machine Learning Approach for Understanding the Educational Foci and Technical Solutions of AIED","","2023","","","326–330","Association for Computing Machinery","New York, NY, USA","Proceedings of the Tenth ACM Conference on Learning @ Scale","Copenhagen, Denmark","2023","","","https://doi.org/10.1145/3573051.3596181;http://dx.doi.org/10.1145/3573051.3596181","10.1145/3573051.3596181","This work-in-progress paper employs a machine learning method for the automated analysis of research interests in Artificial Intelligence in Education (AIED) at scale. We aim to analyze the essential techniques and critical educational problems studied by researchers in five AIED-related conferences and journals between 2010 and 2022. We trained and compared different machine learning models and feature extraction techniques to achieve the research objective. After comparing different models and hyperparameter combinations, our classifier achieves an accuracy of 0.87 and Cohen's kappa of 0.80. Based on the classification results, we identified the top 10 most frequent keywords within each category for every four year period over the past 12 years. Using the classifier, the 10,723 keywords from 2,684 articles were classified into three categories: educational foci, technical solutions, and AIED applications. We find that 'natural language processing' and 'machine learning' are the primary technical keywords in AIED research, and 'deep learning' and 'artificial intelligence' are the trending technical keywords since 2017. Meanwhile, 'massive open online courses', 'self-regulated learning', 'feedback', 'collaborative learning', and 'online learning' are the top educational foci in the field over the last 12 years. 'Intelligent tutoring systems', 'educational data mining', 'knowledge tracing', and 'learning analytics' continue to receive attention as AIED applications of sustained interest. This study helps to understand the educational foci and technical solutions of AIED research at scale and provides insights into the future of AIED research.","machine learning, classification, artificial intelligence in education","","L@S '23"
"Conference Paper","Kang S,Hwang J,Kweon W,Yu H","DE-RRD: A Knowledge Distillation Framework for Recommender System","","2020","","","605–614","Association for Computing Machinery","New York, NY, USA","Proceedings of the 29th ACM International Conference on Information & Knowledge Management","Virtual Event, Ireland","2020","9781450368599","","https://doi.org/10.1145/3340531.3412005;http://dx.doi.org/10.1145/3340531.3412005","10.1145/3340531.3412005","Recent recommender systems have started to employ knowledge distillation, which is a model compression technique distilling knowledge from a cumbersome model (teacher) to a compact model (student), to reduce inference latency while maintaining performance. The state-of-the-art methods have only focused on making the student model to accurately imitate the predictions of the teacher model. They have a limitation in that the prediction results incompletely reveal the teacher's knowledge. In this paper, we propose a novel knowledge distillation framework for recommender system, called DE-RRD, which enables the student model to learn from the latent knowledge encoded in the teacher model as well as from the teacher's predictions. Concretely, DE-RRD consists of two methods: 1) Distillation Experts (DE) that directly transfers the latent knowledge from the teacher model. DE exploits ""experts"" and a novel expert selection strategy for effectively distilling the vast teacher's knowledge to the student with limited capacity. 2) Relaxed Ranking Distillation (RRD) that transfers the knowledge revealed from the teacher's prediction with consideration of the relaxed ranking orders among items. Our extensive experiments show that DE-RRD outperforms the state-of-the-art competitors and achieves comparable or even better performance to that of the teacher model with faster inference time.","knowledge distillation, model compression, retrieval efficiency, learning to rank, recommender system","","CIKM '20"
"Conference Paper","Chen G,Chen J,Feng F,Zhou S,He X","Unbiased Knowledge Distillation for Recommendation","","2023","","","976–984","Association for Computing Machinery","New York, NY, USA","Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining","Singapore, Singapore","2023","9781450394079","","https://doi.org/10.1145/3539597.3570477;http://dx.doi.org/10.1145/3539597.3570477","10.1145/3539597.3570477","As a promising solution for model compression, knowledge distillation (KD) has been applied in recommender systems (RS) to reduce inference latency. Traditional solutions first train a full teacher model from the training data, and then transfer its knowledge (iesoft labels ) to supervise the learning of a compact student model. However, we find such a standard distillation paradigm would incur serious bias issue --- popular items are more heavily recommended after the distillation. This effect prevents the student model from making accurate and fair recommendations, decreasing the effectiveness of RS.In this work, we identify the origin of the bias in KD --- it roots in the biased soft labels from the teacher, and is further propagated and intensified during the distillation. To rectify this, we propose a new KD method with a stratified distillation strategy. It first partitions items into multiple groups according to their popularity, and then extracts the ranking knowledge within each group to supervise the learning of the student. Our method is simple and teacher-agnostic --- it works on distillation stage without affecting the training of the teacher model. We conduct extensive theoretical and empirical studies to validate the effectiveness of our proposal. We release our code at: https://github.com/chengang95/UnKD.","knowledge distillation, recommendation, bias and debias","","WSDM '23"
"Conference Paper","Melesko J,Kurilovas E","Semantic Technologies in E-Learning: Learning Analytics and Artificial Neural Networks in Personalised Learning Systems","","2018","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics","Novi Sad, Serbia","2018","9781450354899","","https://doi.org/10.1145/3227609.3227669;http://dx.doi.org/10.1145/3227609.3227669","10.1145/3227609.3227669","The paper presents semantic clustering and artificial neural network (ANN) based learning analytics software agent for personalised adaptive multi-agent learning system. First of all, systematic literature review on application of ANN to personalise learning in Web of Science database was performed. After that, methodology of application of ANN and semantic clustering of learning material in personalised adaptive multi-agent learning system is presented. In the paper, personalisation in multi-agent learning system is based on learning styles model that requires the use of psychological questionnaire to determine student's learning styles. The results of filling in the questionnaire could be incorrect since some students may answer the questionnaire dishonestly, irresponsibly, or make mistakes in self-diagnosis. This results in creation of an incorrect student's model. This causes the system to provide suboptimal learning objects and scenarios to the student. The authors present a model of ANN based learning analytics agent to be used in the system. Proposed agent uses ANN to associate students' learning styles with their real behaviour within the learning environment. The key factor describing the behaviour of students within the system is the learning content they seek out independently. Clustering the visited documents based on semantic content categorizes students into groups. Belonging to a semantic cluster is one of the inputs that can be used to train ANN agent. After training, the agent could identify potentially faulty student models by looking for anomalous behaviour for those learning styles. Such problems can be resolved by providing alternative learning objects or scenarios to the students and observing their choices.1","e-Learning, multagent systems, learning analytics, artificial neural networks, Personalised learning systems","","WIMS '18"
"Conference Paper","Owen VE,Anton G,Baker R","Modeling User Exploration and Boundary Testing in Digital Learning Games","","2016","","","301–302","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization","Halifax, Nova Scotia, Canada","2016","9781450343688","","https://doi.org/10.1145/2930238.2930271;http://dx.doi.org/10.1145/2930238.2930271","10.1145/2930238.2930271","Digital games can be potent problem solving environments which afford discovery learning through thoughtful exploration [1, 2]. As such, game microworlds facilitate self-regulated learning through sandbox elements in which students have agency in individualizing their pathways of interaction [3]. These agency-driven environments can support learning via individual discovery of problem space constraints and solutions, particularly through boundary testing and productive failure [cf. 4]. Thus, modeling of user interaction in digital learning games can provide considerable insight into emergent trajectories of discovery-based progression, in which equally engaged players may interact differently with the system. To this end, this research leverages educational data mining (EDM) [5] to investigate organic player trajectories of thoughtful exploration (around boundary testing and productive failure) in a learning gamespace. We align behavioral coding with log file data to automatically detect sequences of thoughtful exploration (TE) in play. Results include a robust predictive model of event-stream TE, with multiple trajectories of emergent student behavior-offering insight into organic learning pathways through the game-based problem space, and informing iterative design in optimization of user experience and student engagement.","educational data mining, exploration, student model, productive failure, game-based learning, behavior detection, microworlds, classification, serious games","","UMAP '16"
"Conference Paper","Zhang X,Cheng HN","Mining the Patterns of Graduate Students' Self-Regulated Learning Behaviors in a Negotiated Online Academic Reading Assessment","","2019","","","109–114","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2019 3rd International Conference on E-Society, E-Education and E-Technology","Taipei, Taiwan","2019","9781450372305","","https://doi.org/10.1145/3355966.3355977;http://dx.doi.org/10.1145/3355966.3355977","10.1145/3355966.3355977","Online academic reading assessments can test graduate students' reading ability, while the results of tests as a feedback can help students reflect on their own ability, realize their weaknesses, and then take actions to improve their ability. These behaviors form the basis of self-regulated learning ability. In this paper, a negotiated online reading assessment system is developed to provide students with the function of self-assessment and reflection. For designing the system, the authors use the concept of a negotiated learner model, so that students may negotiate with the system and try to reach an agreement. In order to explore the differences in students' learning behaviors in such a system, the authors used the hidden Markov Model to construct the behavioral model of students' self-regulated learning ability. Furthermore, the authors differentiated the negotiation behaviors of students with high and low self-regulated learning ability in the reading assessment system. The results showed that the students in the high and low self-regulated learning ability groups shared the behaviors of peer comparison and retesting. The high self-regulated learning group tended to transit among retesting, peer comparison, test reflection, and self-assessment. The students in the low self-regulated learning group tended to transit among retesting, peer comparison, viewing grades, and self-reflection. The results indicated that the students tended to re-test to negotiate with the system, and that the students in the high self-regulated learning group may reflect on learning through negotiation and further plan their learning strategies.","self-regulated learning, hidden Markov model, negotiated learner models, online reading assessment","","ICSET 2019"
"Conference Paper","DuHadway L,Henderson TC","Laying a Foundation for the Graphical Course Map","","2016","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 13th International Web for All Conference","Montreal, Canada","2016","9781450341387","","https://doi.org/10.1145/2899475.2899486;http://dx.doi.org/10.1145/2899475.2899486","10.1145/2899475.2899486","The learning managements systems (LMS)s that are widely used to provide access to educational opportunities on the Web are limited by a text based, linear presentation of course materials and the standard temporal restrictions in the traditional classroom. Making a fundamental change in how course materials are presented and interfaced with can make educational opportunities available to a broader spectrum of people with diverse abilities and various circumstances. We have developed a graph-based approach to presenting the learning materials of a course using a system called ENABLE [6, 7] with three major goals: (1) facilitate restructuring a set of synchronous classroom materials into a dynamic online system, (2) provide algorithms to analyze and enhance student performance as well as provide insights to the instructor concerning the efficacy of the learning items and their organization, and (3) identify ways to use data from an existing linear, temporal based course presentation to train predictive models for a course that allows individual flexibility in the ordering of the material. This work demonstrates the possibility of presenting course materials in a graphical way that expresses important relations and provides support for manipulating the order and timing of those materials. The graphical course map adds a new approach to making education accessible to people from many different spectrums of ability that respond and interface better with visual representations and those who will benefit from the removal of temporal limitations.","interactive learning environments, student model calibration, accessibility, web-based learning, personalized learning, artificial student agents, graphical course mapping","","W4A '16"
"Journal Article","Chen W,Yu Y,Gai K,Liu J,Choo KK","Time-Efficient Ensemble Learning with Sample Exchange for Edge Computing","ACM Trans. Internet Technol.","2021","21","3","","Association for Computing Machinery","New York, NY, USA","","","2021-06","","1533-5399","https://doi.org/10.1145/3409265;http://dx.doi.org/10.1145/3409265","10.1145/3409265","In existing ensemble learning algorithms (e.g., random forest), each base learner’s model needs the entire dataset for sampling and training. However, this may not be practical in many real-world applications, and it incurs additional computational costs. To achieve better efficiency, we propose a decentralized framework: Multi-Agent Ensemble. The framework leverages edge computing to facilitate ensemble learning techniques by focusing on the balancing of access restrictions (small sub-dataset) and accuracy enhancement. Specifically, network edge nodes (learners) are utilized to model classifications and predictions in our framework. Data is then distributed to multiple base learners who exchange data via an interaction mechanism to achieve improved prediction. The proposed approach relies on a training model rather than conventional centralized learning. Findings from the experimental evaluations using 20 real-world datasets suggest that Multi-Agent Ensemble outperforms other ensemble approaches in terms of accuracy even though the base learners require fewer samples (i.e., significant reduction in computation costs).","Edge computing, ensemble learning, decentralized ensemble learning, Multi-Agent Ensemble","",""
"Conference Paper","Käser T,Klingler S,Gross M","When to Stop? Towards Universal Instructional Policies","","2016","","","289–298","Association for Computing Machinery","New York, NY, USA","Proceedings of the Sixth International Conference on Learning Analytics & Knowledge","Edinburgh, United Kingdom","2016","9781450341905","","https://doi.org/10.1145/2883851.2883961;http://dx.doi.org/10.1145/2883851.2883961","10.1145/2883851.2883961","The adaptivity of intelligent tutoring systems relies on the accuracy of the student model and the design of the instructional policy. Recently an instructional policy has been presented that is compatible with all common student models. In this work we present the next step towards a universal instructional policy. We introduce a new policy that is applicable to an even wider range of student models including DBNs modeling skill topologies and forgetting. We theoretically and empirically compare our policy to previous policies. Using synthetic and real world data sets we show that our policy can effectively handle wheel-spinning students as well as forgetting across a wide range of student models.","instructional policies, wheel-spinning, individualization, noisy data, student modeling","","LAK '16"
"Conference Paper","Folsom-Kovarik JT,Schatz S,Sukthankar G,Nicholson D","What Information Does This Question Convey? Leveraging Help-Seeking Behavior for Improved Modeling in a Simulation-Based Intelligent Tutor","","2010","","","","Society for Computer Simulation International","San Diego, CA, USA","Proceedings of the 2010 Spring Simulation Multiconference","Orlando, Florida","2010","9781450300698","","https://doi.org/10.1145/1878537.1878565;http://dx.doi.org/10.1145/1878537.1878565","10.1145/1878537.1878565","Asking questions is an important help-seeking behavior that many intelligent tutoring systems (ITSs) do not use. Allowing learners to ask questions of an ITS has the potential to improve learning and also to provide a new source of input for ITSs' internal models. In this paper, the different ways an ITS can input questions, answer them, and then use them to update its student model are discussed. A taxonomy of question response for model-based learning environments is proposed, and inquiry modeling, a new framework to let learners ask questions of an ITS with more freedom than existing methods, is described. Inquiry modeling is being developed and tested in a popular military training simulation, the DVTE-CAN.","intelligent tutoring systems, inquiry modeling, student modeling, help-seeking, simulation-based training","","SpringSim '10"
"Conference Paper","Moritz SH,Wei F,Parvez SM,Blank GD","From Objects-First to Design-First with Multimedia and Intelligent Tutoring","","2005","","","99–103","Association for Computing Machinery","New York, NY, USA","Proceedings of the 10th Annual SIGCSE Conference on Innovation and Technology in Computer Science Education","Caparica, Portugal","2005","9781595930248","","https://doi.org/10.1145/1067445.1067475;http://dx.doi.org/10.1145/1067445.1067475","10.1145/1067445.1067475","""Objects-first"" is an increasingly popular strategy for teaching object-oriented programming by introducing the concepts of objects, classes, and instances before procedural elements of a programming language. Still, this approach emphasizes coding rather than other critical aspects of software development, notably problem-solving and design. We propose a ""design-first"" curriculum, which subsumes an objects-first approach into lessons that also introduce object-oriented analysis and design, using elements of UML before implementing any code. We also present CIMEL ITS, an intelligent tutoring system that uses the design-first approach to help students of various learning styles in a CS1 course. It interfaces with an IDE we have chosen specifically to support the design-first curriculum, and CIMEL, multimedia courseware which has been shown to be effective in helping students learn object-oriented programming concepts.","intelligent tutoring system, e-learning, courseware, pedagogy, UML, IDE, student model, Eclipse, objects-first, object-oriented programming, Java in high schools, CS1, Java, CIMEL, multimedia","","ITiCSE '05"
"Journal Article","Moritz SH,Wei F,Parvez SM,Blank GD","From Objects-First to Design-First with Multimedia and Intelligent Tutoring","SIGCSE Bull.","2005","37","3","99–103","Association for Computing Machinery","New York, NY, USA","","","2005-06","","0097-8418","https://doi.org/10.1145/1151954.1067475;http://dx.doi.org/10.1145/1151954.1067475","10.1145/1151954.1067475","""Objects-first"" is an increasingly popular strategy for teaching object-oriented programming by introducing the concepts of objects, classes, and instances before procedural elements of a programming language. Still, this approach emphasizes coding rather than other critical aspects of software development, notably problem-solving and design. We propose a ""design-first"" curriculum, which subsumes an objects-first approach into lessons that also introduce object-oriented analysis and design, using elements of UML before implementing any code. We also present CIMEL ITS, an intelligent tutoring system that uses the design-first approach to help students of various learning styles in a CS1 course. It interfaces with an IDE we have chosen specifically to support the design-first curriculum, and CIMEL, multimedia courseware which has been shown to be effective in helping students learn object-oriented programming concepts.","objects-first, Java, CS1, e-learning, student model, intelligent tutoring system, IDE, object-oriented programming, pedagogy, Java in high schools, CIMEL, courseware, Eclipse, UML, multimedia","",""
"Journal Article","Chen X,Zhang Y,Xu H,Qin Z,Zha H","Adversarial Distillation for Efficient Recommendation with External Knowledge","ACM Trans. Inf. Syst.","2018","37","1","","Association for Computing Machinery","New York, NY, USA","","","2018-12","","1046-8188","https://doi.org/10.1145/3281659;http://dx.doi.org/10.1145/3281659","10.1145/3281659","Integrating external knowledge into the recommendation system has attracted increasing attention in both industry and academic communities. Recent methods mostly take the power of neural network for effective knowledge representation to improve the recommendation performance. However, the heavy deep architectures in existing models are usually incorporated in an embedded manner, which may greatly increase the model complexity and lower the runtime efficiency.To simultaneously take the power of deep learning for external knowledge modeling as well as maintaining the model efficiency at test time, we reformulate the problem of recommendation with external knowledge into a generalized distillation framework. The general idea is to free the complex deep architecture into a separate model, which is only used in the training phrase, while abandoned at test time. In particular, in the training phrase, the external knowledge is processed by a comprehensive teacher model to produce valuable information to teach a simple and efficient student model. Once the framework is learned, the teacher model is abandoned, and only the succinct yet enhanced student model is used to make fast predictions at test time. In this article, we specify the external knowledge as user review, and to leverage it in an effective manner, we further extend the traditional generalized distillation framework by designing a Selective Distillation Network (SDNet) with adversarial adaption and orthogonality constraint strategies to make it more robust to noise information.Extensive experiments verify that our model can not only improve the performance of rating prediction, but also can significantly reduce time consumption when making predictions as compared with several state-of-the-art methods.","distillation network, external knowledge, adversarial training, Recommendation system, personalization","",""
"Conference Paper","Gautam S,Rosson MB,Akgun M","Exploring Potential Contributions of Social Learning to Adaptive Learning Systems","","2023","","","","Association for Computing Machinery","New York, NY, USA","Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems","Hamburg, Germany","2023","9781450394222","","https://doi.org/10.1145/3544549.3585758;http://dx.doi.org/10.1145/3544549.3585758","10.1145/3544549.3585758","Adaptive learning systems aim to emulate how skilled educators seek to provide every student the best possible learning experience. We investigate how such systems might be enriched by activities and indicators of social learning - an aspect of learning that focuses on the influences of learners’ social context and interactions. In this paper we describe a pilot study aimed at exploring the potential for including social learning in an adaptive system. Our analysis of the social learning scale demonstrates its validity and usefulness for our ongoing work. Our qualitative analysis of students’ learning demonstrates how social learning vary among students. We discuss how the rating scale results and observations of social learning can be integrated within a student model needed to drive an adaptive system. More generally, our work illustrates how theories of learning can contribute to the design of adaptive learning systems.","adaptive learning, social constructivism, peer learning, education","","CHI EA '23"
"Conference Paper","Sun L,Li Y,Dong Y","Learning From Expert: Vision-Language Knowledge Distillation for Unsupervised Cross-Modal Hashing Retrieval","","2023","","","499–507","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2023 ACM International Conference on Multimedia Retrieval","Thessaloniki, Greece","2023","","","https://doi.org/10.1145/3591106.3592242;http://dx.doi.org/10.1145/3591106.3592242","10.1145/3591106.3592242","Unsupervised cross-modal hashing (UCMH) has attracted increasing research due to its efficient retrieval performance and label irrelevance. However, existing methods have some bottlenecks: Firstly, the existing unsupervised methods suffer from inaccurate similarity measures due to the lack of correlation between features of different modalities and simple features cannot fully describe the fine-grained relationships of multi-modal data. Secondly, existing methods have rarely explored vision-language knowledge distillation schemes to distil multi-modal knowledge of these vision-language models to guide the learning of student networks. To address these bottlenecks, this paper proposes an effective unsupervised cross-modal hashing retrieval method, called Vision-Language Knowledge Distillation for Unsupervised Cross-Modal Hashing Retrieval (VLKD). VLKD uses the vision-language pre-training (VLP) model to encode features on multi-modal data, and then constructs a similarity matrix to provide soft similarity supervision for the student model. It distils the knowledge of the VLP model to the student model to gain an understanding of multi-modal knowledge. In addition, we designed an end-to-end unsupervised hashing learning model that incorporates a graph convolutional auxiliary network. The auxiliary network aggregates information from similar data nodes based on the similarity matrix distilled by the teacher model to generate more consistent hash codes. Finally, the teacher network does not require additional training, it only needs to guide the student network to learn high-quality hash representation, and VLKD is quite efficient in training and retrieval. Sufficient experiments on three multimedia retrieval benchmark datasets show that the proposed method achieves better retrieval performance compared to existing unsupervised cross-modal hashing methods, demonstrating the effectiveness of the proposed method.","knowledge distillation., graph neural networks, vision-language pre-training, cross-modal hashing retrieval, Deep unsupervised learning","","ICMR '23"
"Conference Paper","Noguchi Y,Nishihata S,Kogure S,Yamashita K,Kondo M,Konishi T","What is the Meaning of My Model? - Self-Review Support Environment Based on Natural Language Translation from Learners' Software Structural Models","","2021","","","80–86","Association for Computing Machinery","New York, NY, USA","Proceedings of the 52nd ACM Technical Symposium on Computer Science Education","Virtual Event, USA","2021","9781450380621","","https://doi.org/10.1145/3408877.3432387;http://dx.doi.org/10.1145/3408877.3432387","10.1145/3408877.3432387","In general, college students enrolled in computer science courses are provided some software design classes and exercises. In a cross-reviewing learning/exercise environment, however, beginners often cannot provide useful feedback and viewpoints to others. One of the reasons for this is that beginners are not confident in their understanding of the software design models. These learners should be encouraged by strengthening their understanding of the models. In this research, we propose a self-review supporting environment that provides learners with feedback generated by translating their Unified Modeling Language (UML) class diagrams into natural language descriptions. This enables beginners to recognize discrepancies between what they would like to describe in their class diagrams and what they actually describe in their class diagrams by comparing them in natural language. We designed three types of templates to make learners aware of the discrepancies. Moreover, we performed an experiment to evaluate whether the feedback produced by translating a learner's model into natural language can support the learner to detect errors in the model themselves, and whether this feedback can support the learner to correct errors in the model themselves. The results of the experiment indicated that the subjects detected errors in their class diagrams with 89.2% accuracy and detected 47.3% of all errors in their diagrams. Furthermore, the subjects corrected the errors they correctly detected with 78.6% accuracy.","class diagram, software structural modeling, UML, learning support environment, natural language generation","","SIGCSE '21"
"Conference Paper","Wang S,Zhang K,Wu L,Ma H,Hong R,Wang M","Privileged Graph Distillation for Cold Start Recommendation","","2021","","","1187–1196","Association for Computing Machinery","New York, NY, USA","Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval","Virtual Event, Canada","2021","9781450380379","","https://doi.org/10.1145/3404835.3462929;http://dx.doi.org/10.1145/3404835.3462929","10.1145/3404835.3462929","The cold start problem in recommender systems is a long-standing challenge, which requires recommending to new users (items) based on attributes without any historical interaction records. In these recommendation systems, warm users (items) have privileged collaborative signals of interaction records compared to cold start users (items), and these Collaborative Filtering (CF) signals are shown to have competing performance for recommendation. Many researchers proposed to learn the correlation between collaborative signal embedding space and the attribute embedding space to improve the cold start recommendation, in which user and item categorical attributes are available in many online platforms. However, the cold start recommendation is still limited by two embedding spaces modeling and simple assumptions of space transformation. As user-item interaction behaviors and user (item) attributes naturally form a heterogeneous graph structure, in this paper, we propose a privileged graph distillation model (PGD). The teacher model is composed of a heterogeneous graph structure for warm users and items with privileged CF links. The student model is composed of an entity-attribute graph without CF links. Specifically, the teacher model can learn better embeddings of each entity by injecting complex higher-order relationships from the constructed heterogeneous graph. The student model can learn the distilled output with privileged CF embeddings from the teacher embeddings. Our proposed model is generally applicable to different cold start scenarios with new user, new item, or new user-new item. Finally, extensive experimental results on the real-world datasets clearly show the effectiveness of our proposed model on different types of cold start problems, with average 6.6%, 5.6%, and 17.1% improvement over state-of-the-art baselines on three datasets, respectively.","knowledge distillation, graph convolutional networks, cold start recommendation","","SIGIR '21"
"Conference Paper","Dadgostar F,Ryu H,Sarrafzadeh A,Overmyer S","Making Sense of Student Use of Nonverbal Cues for Intelligent Tutoring Systems","","2005","","","1–4","Computer-Human Interaction Special Interest Group (CHISIG) of Australia","Narrabundah, AUS","Proceedings of the 17th Australia Conference on Computer-Human Interaction: Citizens Online: Considerations for Today and the Future","Canberra, Australia","2005","9781595932228","","","","Many software systems would significantly improve performance if they could interpret the nonverbal cues in their user's interactions as humans normally do. Currently, Intelligent Tutoring Systems (ITSs) (and other software systems) are unable to use nonverbal cues to interpret student's responses to instructional material as can human tutors. We believe that this capability is essential to adapt teaching strategy to the needs of the learner. An experiment was performed aimed at identifying what kinds of gestures are being used by students in a human-to-human learning context. We have identified a range of gestures being used in one-to-one tutoring environments and a dependency of gesture use on students' skill level. As a result, we suggest how the student model in an ITS should reflect this dependency. These results are applicable to HCI in general.","nonverbal cues, adaptive user interfaces, intelligent tutoring systems, gestures","","OZCHI '05"
"Conference Paper","Allen LK,Snow EL,McNamara DS","Are You Reading My Mind? Modeling Students' Reading Comprehension Skills with Natural Language Processing Techniques","","2015","","","246–254","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fifth International Conference on Learning Analytics And Knowledge","Poughkeepsie, New York","2015","9781450334174","","https://doi.org/10.1145/2723576.2723617;http://dx.doi.org/10.1145/2723576.2723617","10.1145/2723576.2723617","This study builds upon previous work aimed at developing a student model of reading comprehension ability within the intelligent tutoring system, iSTART. Currently, the system evaluates students' self-explanation performance using a local, sentence-level algorithm and does not adapt content based on reading ability. The current study leverages natural language processing tools to build models of students' comprehension ability from the linguistic properties of their self-explanations. Students (n = 126) interacted with iSTART across eight training sessions where they self-explained target sentences from complex science texts. Coh-Metrix was then used to calculate the linguistic properties of their aggregated self-explanations. The results of this study indicated that the linguistic indices were predictive of students' reading comprehension ability, over and above the current system algorithms. These results suggest that natural language processing techniques can inform stealth assessments and ultimately improve student models within intelligent tutoring systems.","corpus linguistics, stealth assessment, natural language processing, reading comprehension, intelligent tutoring systems","","LAK '15"
"Conference Paper","Chen X,Gao Y,Li W","Singing Voice Detection via Similarity-Based Semi-Supervised Learning","","2022","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 4th ACM International Conference on Multimedia in Asia","Tokyo, Japan","2022","9781450394789","","https://doi.org/10.1145/3551626.3564963;http://dx.doi.org/10.1145/3551626.3564963","10.1145/3551626.3564963","Data-driven methods play an important role in Singing Voice Detection (SVD). However, datasets with precise annotations are scarce. In this paper, we propose an SVD method via similarity-based semi-supervised learning (SSSL_SVD). For one thing, we propose to enrich the diversity of training data using the self-training semi-supervised method (SSL). In SSL, pseudo labels of the unlabeled data are first generated by a pre-trained teacher model and are then used to train a student model. For another thing, we propose to measure the audio frame from a similarity-based perspective. Taking it into consideration, we could provide more appropriate learning targets. Finally, experiment results indicate that the proposed method achieved comparable results with state-of-the-art (SOTA) algorithms.","singing voice detection, semi-supervised learning, voice detection, music information retrieval","","MMAsia '22"
"Conference Paper","Faucon L,Olsen JK,Dillenbourg P","A Bayesian Model of Individual Differences and Flexibility in Inductive Reasoning for Categorization of Examples","","2020","","","285–294","Association for Computing Machinery","New York, NY, USA","Proceedings of the Tenth International Conference on Learning Analytics & Knowledge","Frankfurt, Germany","2020","9781450377126","","https://doi.org/10.1145/3375462.3375512;http://dx.doi.org/10.1145/3375462.3375512","10.1145/3375462.3375512","Inductive reasoning is an important educational practice but can be difficult for teachers to support in the classroom due to the high level of preparation and classroom time needed to choose the teaching materials that challenge students' current views. Intelligent tutoring systems can potentially facilitate this work for teachers by supporting the automatic adaptation of examples based on a student model of the induction process. However, current models of inductive reasoning usually lack two main characteristics helpful to adaptive learning environments, individual differences of students and tracing of students' learning as they receive feedback. In this paper, we describe a model to predict and simulate inductive reasoning of students for a categorization task. Our approach uses a Bayesian model for describing the reasoning processes of students. This model allows us to predict students' choices in categorization questions by accounting for their feature biases. Using data gathered from 222 students categorizing three topics, we find that our model has a 75% accuracy, which is 10% greater than a baseline model. Our model is a contribution to learning analytics by enabling us to assign different bias profiles to individual students and tracking these profile changes over time through which we can gain a better understanding of students' learning processes. This model may be relevant for systematically analysing students' differences and evolution in inductive reasoning strategies while supporting the design of adaptive inductive learning environments.","adaptive learning environment, inductive reasoning, process mining, student modeling","","LAK '20"
"Conference Paper","Wang S,Zuccon G","Balanced Topic Aware Sampling for Effective Dense Retriever: A Reproducibility Study","","2023","","","2542–2551","Association for Computing Machinery","New York, NY, USA","Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval","Taipei, Taiwan","2023","9781450394086","","https://doi.org/10.1145/3539618.3591915;http://dx.doi.org/10.1145/3539618.3591915","10.1145/3539618.3591915","Knowledge distillation plays a key role in boosting the effectiveness of rankers based on pre-trained language models (PLMs); this is achieved using an effective but inefficient large model to teach a more efficient student model. In the context of knowledge distillation for a student dense passage retriever, the balanced topic-aware sampling method has been shown to provide state-of-the-art effectiveness. This method intervenes in the creation of the training batches by creating batches that contain positive-negative pairs of passages from the same topic, and balancing the pairwise margins of the positive and negative passages.In this paper, we reproduce the balanced topic-aware sampling method; we do so for both the dataset used for evaluation in the original work (MS MARCO) and for a dataset in a different domain, that of product search (Amazon shopping queries dataset) to study whether the original results generalize to a different context. We show that while we could not replicate the exact results from the original paper, we do confirm the original findings in terms of trends: balanced topic-aware sampling indeed leads to highly effective dense retrievers. These results partially generalize to the other search task we investigate, product search: although we observe the improvements are less significant compared to MS MARCO.In addition to reproducing the original results and studying how the method generalizes to a different dataset, we also investigate a key aspect that influences the effectiveness of the method: the use of a hard margin threshold for negative sampling. This aspect was not studied in the original paper. With respect to hard margins, we find that while setting different hard margin values significantly influences the effectiveness of the student model, this impact is dataset-dependent -- and indeed, it does depend on the score distributions exhibited by retrieval models on the dataset at hand. Our reproducibility code is available at https://github.com/ielab/TAS-B-Reproduction.","knowledge distillation, bert, dense retriever, topic clustering","","SIGIR '23"
"Conference Paper","Yu S,Wang S","Consistency Mean-Teaching for Unsupervised Domain Adaptive Person Re-Identification","","2022","","","159–166","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2022 5th International Conference on Image and Graphics Processing","Beijing, China","2022","9781450395465","","https://doi.org/10.1145/3512388.3512451;http://dx.doi.org/10.1145/3512388.3512451","10.1145/3512388.3512451","Unsupervised domain adaptive (UDA) person re-identification (re-ID) transfers a labeled source domain model to an unlabeled target domain. In this paper, we propose a Consistency Mean Teaching (CMT) method to improve clustering-based UDA Re-ID. Our CMT consists of two consistencies, i.e., an inter-view consistency and an intra-identity consistency. First, the inter-view consistency exploits a popular self-supervised training for UDA, which has been neglected in existing clustering-based UDA methods. Second, the intra-identity consistency imposes regulations between the teacher and student model to output consistent representations for different samples from the same identity. Third, these two consistencies are integrated into a single student-teacher framework and facilitate complementary benefits. Experimental results show that CMT brings significant improvements over the baseline and achieves competitive accuracy on four popular UDA re-ID.","mean-teaching, consistency learning, Re-ID, UDA","","ICIGP '22"
"Conference Paper","Duan X,Duan P","English Education Online Platform Based on Artificial Intelligence","","2022","","","87–90","Association for Computing Machinery","New York, NY, USA","2021 International Conference on Aviation Safety and Information Technology","Changsha, China","2022","9781450390422","","https://doi.org/10.1145/3510858.3510895;http://dx.doi.org/10.1145/3510858.3510895","10.1145/3510858.3510895","Over the years, AIT has begun to present to people's lives, making people's lives more comfortable. With the progress of intelligent scientific method, online education is developing in the field of education. In the face of the pandemic, millions of students around the world have turned to online education platforms to learn. This paper takes English teachers and students as examples to study the innovation and development of online education. This paper compares the influence of new teachers and students through experiential models and traditional teaching models, and focuses on analyzing the benefits of reformed advanced technologies for online English teachers and students. The results showed that 67% of the students in the experimental group were satisfied or very satisfied with the new teacher-student model, while only 46% of the students in the control group were satisfied or very satisfied with the traditional teaching model. Artificial intelligence scientific method (AIT) can promote the reform platform of Online English education.","","","ICASIT 2021"
"Conference Paper","Li M,Wang H","Unsupervised Deep Cross-Modal Hashing by Knowledge Distillation for Large-Scale Cross-Modal Retrieval","","2021","","","183–191","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2021 International Conference on Multimedia Retrieval","Taipei, Taiwan","2021","9781450384636","","https://doi.org/10.1145/3460426.3463626;http://dx.doi.org/10.1145/3460426.3463626","10.1145/3460426.3463626","Cross-modal hashing (CMH) maps heterogeneous multiple modality data into compact binary code to achieve fast and flexible retrieval across different modalities, especially in large-scale retrieval. As the data don't need a lot of manual annotation, unsupervised cross-modal hashing has a wider application prospect than supervised method. However, the existing unsupervised methods are difficult to achieve satisfactory performance due to the lack of credible supervisory information. To solve this problem, inspired by knowledge distillation, we propose a novel unsupervised Knowledge Distillation Cross-Modal Hashing method (KDCMH), which can use similarity information distilled from unsupervised method to guide supervised method. Specifically, firstly, the teacher model adopted an unsupervised distribution-based similarity hashing method, which can construct a modal fusion similarity matrix.Secondly, under the supervision of teacher model distillation information, student model can generate more discriminative hash codes. In two public datasets NUS-WIDE and MIRFLICKR-25K, extensive experiments have proved the significant improvement of KDCMH on several representative unsupervised cross-modal hashing methods.","cross-modal retrieval, cross-modal hashing, unsupervised learning, knowledge distillation","","ICMR '21"
"Conference Paper","Sun Z,Huang J,Lin J,Xu X,Chen Q,Hu W","Joint Pre-Training and Local Re-Training: Transferable Representation Learning on Multi-Source Knowledge Graphs","","2023","","","2132–2144","Association for Computing Machinery","New York, NY, USA","Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining","Long Beach, CA, USA","2023","","","https://doi.org/10.1145/3580305.3599397;http://dx.doi.org/10.1145/3580305.3599397","10.1145/3580305.3599397","In this paper, we present the ""joint pre-training and local re-training'' framework for learning and applying multi-source knowledge graph (KG) embeddings. We are motivated by the fact that different KGs contain complementary information to improve KG embeddings and downstream tasks. We pre-train a large teacher KG embedding model over linked multi-source KGs and distill knowledge to train a student model for a task-specific KG. To enable knowledge transfer across different KGs, we use entity alignment to build a linked subgraph for connecting the pre-trained KGs and the target KG. The linked subgraph is re-trained for three-level knowledge distillation from the teacher to the student, i.e., feature knowledge distillation, network knowledge distillation, and prediction knowledge distillation, to generate more expressive embeddings. The teacher model can be reused for different target KGs and tasks without having to train from scratch. We conduct extensive experiments to demonstrate the effectiveness and efficiency of our framework.","pre-training and re-training, multi-source knowledge graphs, transferable representation learning, knowledge distillation","","KDD '23"
"Journal Article","Mai W,Yao J,Chen G,Zhang Y,Cheung YM,Han B","Server-Client Collaborative Distillation for Federated Reinforcement Learning","ACM Trans. Knowl. Discov. Data","2023","18","1","","Association for Computing Machinery","New York, NY, USA","","","2023-08","","1556-4681","https://doi.org/10.1145/3604939;http://dx.doi.org/10.1145/3604939","10.1145/3604939","Federated Learning (FL) learns a global model in a distributional manner, which does not require local clients to share private data. Such merit has drawn lots of attention in the interaction scenarios, where Federated Reinforcement Learning (FRL) emerges as a cross-field research direction focusing on the robust training of agents. Different from FL, the heterogeneity problem in FRL is more challenging because the data depends on the policy of agents and the environment dynamics. FRL learns to interact under the non-stationary environment feedback, while the typical FL methods aim at handling the constant data heterogeneity. In this article, we are among the first attempts to analyze the heterogeneity problem in FRL and propose an off-policy FRL framework. Specifically, a student–teacher–student model learning and fusion method, termed as Server-Client Collaborative Distillation (SCCD), is introduced. Unlike the traditional FL, we distill all local models on the server side for model fusion. To reduce the variance of the training, a local distillation is also conducted every time the agent receives the global model. Experimentally, we compare SCCD with a range of straightforward combinations between FL methods and RL. The results demonstrate that SCCD has a superior performance in four classical continuous control tasks with non-IID environments.","heterogeneous environment, collaborative learning, Federated learning","",""
"Conference Paper","Wang Q,Zhan L,Thompson P,Zhou J","Multimodal Learning with Incomplete Modalities by Knowledge Distillation","","2020","","","1828–1838","Association for Computing Machinery","New York, NY, USA","Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","Virtual Event, CA, USA","2020","9781450379984","","https://doi.org/10.1145/3394486.3403234;http://dx.doi.org/10.1145/3394486.3403234","10.1145/3394486.3403234","Multimodal learning aims at utilizing information from a variety of data modalities to improve the generalization performance. One common approach is to seek the common information that is shared among different modalities for learning, whereas we can also fuse the supplementary information to leverage modality-specific information. Though the supplementary information is often desired, most existing multimodal approaches can only learn from samples with complete modalities, which wastes a considerable amount of data collected. Otherwise, model-based imputation needs to be used to complete the missing values and yet may introduce undesired noise, especially when the sample size is limited. In this paper, we proposed a framework based on knowledge distillation, utilizing the supplementary information from all modalities, and avoiding imputation and noise associated with it. Specifically, we first train models on each modality independently using all the available data. Then the trained models are used as teachers to teach the student model, which is trained with the samples having complete modalities. We demonstrate the effectiveness of the proposed method in extensive empirical studies on both synthetic datasets and real-world datasets.","knowledge distillation, multimodal learning, incomplete modalities","","KDD '20"
"Conference Paper","Kundu RK,Elsaid OY,Calyam P,Hoque KA","VR-LENS: Super Learning-Based Cybersickness Detection and Explainable AI-Guided Deployment in Virtual Reality","","2023","","","819–834","Association for Computing Machinery","New York, NY, USA","Proceedings of the 28th International Conference on Intelligent User Interfaces","Sydney, NSW, Australia","2023","","","https://doi.org/10.1145/3581641.3584044;http://dx.doi.org/10.1145/3581641.3584044","10.1145/3581641.3584044","Virtual reality (VR) systems are known for their susceptibility to cybersickness, which can seriously hinder users’ experience. Therefore, a plethora of recent research has proposed several automated methods based on machine learning (ML) and deep learning (DL) to detect cybersickness. However, these detection methods are perceived as computationally intensive and black-box methods. Thus, those techniques are neither trustworthy nor practical for deploying on standalone VR head-mounted displays (HMDs). This work presents an explainable artificial intelligence (XAI)-based framework VR-LENS for developing cybersickness detection ML models, explaining them, reducing their size, and deploying them in a Qualcomm Snapdragon 750G processor-based Samsung A52 device. Specifically, we first develop a novel super learning-based ensemble ML model for cybersickness detection. Next, we employ a post-hoc explanation method, such as SHapley Additive exPlanations (SHAP), Morris Sensitivity Analysis (MSA), Local Interpretable Model-Agnostic Explanations (LIME), and Partial Dependence Plot (PDP) to explain the expected results and identify the most dominant features. The super learner cybersickness model is then retrained using the identified dominant features. Our proposed method identified eye tracking, player position, and galvanic skin/heart rate response as the most dominant features for the integrated sensor, gameplay, and bio-physiological datasets. We also show that the proposed XAI-guided feature reduction significantly reduces the model training and inference time by 1.91X and 2.15X while maintaining baseline accuracy. For instance, using the integrated sensor dataset, our reduced super learner model outperforms the state-of-the-art works by classifying cybersickness into 4 classes (none, low, medium, and high) with an accuracy of and regressing (FMS 1–10) with a Root Mean Square Error (RMSE) of 0.03. Our proposed method can help researchers analyze, detect, and mitigate cybersickness in real time and deploy the super learner-based cybersickness detection model in standalone VR headsets.","Explainable Artificial Intelligence, Dimensionality Reduction, Cybersickness Detection, Virtual Reality, Model Deployment, Machine Learning","","IUI '23"
"Conference Paper","Deng X,Bashlovkina V,Han F,Baumgartner S,Bendersky M","LLMs to the Moon? Reddit Market Sentiment Analysis with Large Language Models","","2023","","","1014–1019","Association for Computing Machinery","New York, NY, USA","Companion Proceedings of the ACM Web Conference 2023","Austin, TX, USA","2023","9781450394192","","https://doi.org/10.1145/3543873.3587605;http://dx.doi.org/10.1145/3543873.3587605","10.1145/3543873.3587605","Market sentiment analysis on social media content requires knowledge of both financial markets and social media jargon, which makes it a challenging task for human raters. The resulting lack of high-quality labeled data stands in the way of conventional supervised learning methods. In this work, we conduct a case study approaching this problem with semi-supervised learning using a large language model (LLM). We select Reddit as the target social media platform due to its broad coverage of topics and content types. Our pipeline first generates weak financial sentiment labels for Reddit posts with an LLM and then uses that data to train a small model that can be served in production. We find that prompting the LLM to produce Chain-of-Thought summaries and forcing it through several reasoning paths helps generate more stable and accurate labels, while training the student model using a regression loss further improves distillation quality. With only a handful of prompts, the final model performs on par with existing supervised models. Though production applications of our model are limited by ethical considerations, the model’s competitive performance points to the great potential of using LLMs for tasks that otherwise require skill-intensive annotation.","Finance, Sentiment Analysis, Natural Language Processing, Social Media, Large Language Model","","WWW '23 Companion"
"Conference Paper","Li Y,Zhang Z,Liu B,Yang Z,Liu Y","ModelDiff: Testing-Based DNN Similarity Comparison for Model Reuse Detection","","2021","","","139–151","Association for Computing Machinery","New York, NY, USA","Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis","Virtual, Denmark","2021","9781450384599","","https://doi.org/10.1145/3460319.3464816;http://dx.doi.org/10.1145/3460319.3464816","10.1145/3460319.3464816","The knowledge of a deep learning model may be transferred to a student model, leading to intellectual property infringement or vulnerability propagation. Detecting such knowledge reuse is nontrivial because the suspect models may not be white-box accessible and/or may serve different tasks. In this paper, we propose ModelDiff, a testing-based approach to deep learning model similarity comparison. Instead of directly comparing the weights, activations, or outputs of two models, we compare their behavioral patterns on the same set of test inputs. Specifically, the behavioral pattern of a model is represented as a decision distance vector (DDV), in which each element is the distance between the model's reactions to a pair of inputs. The knowledge similarity between two models is measured with the cosine similarity between their DDVs. To evaluate ModelDiff, we created a benchmark that contains 144 pairs of models that cover most popular model reuse methods, including transfer learning, model compression, and model stealing. Our method achieved 91.7% correctness on the benchmark, which demonstrates the effectiveness of using ModelDiff for model reuse detection. A study on mobile deep learning apps has shown the feasibility of ModelDiff on real-world models.","similarity comparison, model reuse, intellectual property, vulnerability propagation, Deep neural networks","","ISSTA 2021"
"Conference Paper","Mao Y,Li X,Li Z,Li M,Chen S","Network Slimming Method for SAR Ship Detection Based on Knowlegde Distillation","","2020","","","177–181","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2020 International Conference on Aviation Safety and Information Technology","Weihai City, China","2020","9781450375764","","https://doi.org/10.1145/3434581.3434613;http://dx.doi.org/10.1145/3434581.3434613","10.1145/3434581.3434613","This paper proposes a network slimming method for synthetic aperture radar (SAR) ship detection based on knowledge distillation. Firstly, the generic objection detection network is pruned regularly and extremely on filter-level to get lightweight models under different global pruning ratios. Secondly, the knowledge distillation framework based on Kullback Leibler (KL) Divergence is used to train small student network and large teacher network from scratch synchronously to restore the accuracy of student network. To verify the effectiveness of the proposed method, sufficient experiments are conducted on the widely used SAR Ship Detection Dataset (SSDD). YOLO v3@Darknet-53 is selected as the baseline model while YOLO v3@EfficientNet-B7 as the teacher network. Results show that, with our method, a student model with only 15.4M parameters (25% of the baseline model) can achieve high pruning ratio while still maintaining encouraging performance. Compared with the baseline model, there are only 1% and 0.9% differences on average precision (AP) and average recall (AR), respectively. Compared with traditional fine-tuning method which only restores 0.6% AP, the model slimming method based on knowledge distillation proposed in this paper restores 2.4% AP with obvious advantages.","Knowlegde Distillation, Network Pruning, Synthetic Aperture Radar (SAR), Ship Detection","","ICASIT 2020"
"Conference Paper","Zhao W,Zhu X,He Z,Zhang XY,Lei Z","Cross-Architecture Distillation for Face Recognition","","2023","","","8076–8085","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st ACM International Conference on Multimedia","Ottawa ON, Canada","2023","","","https://doi.org/10.1145/3581783.3611711;http://dx.doi.org/10.1145/3581783.3611711","10.1145/3581783.3611711","Transformers have emerged as the superior choice for face recognition tasks, but their insufficient platform acceleration hinders their application on mobile devices. In contrast, Convolutional Neural Networks (CNNs) capitalize on hardware-compatible acceleration libraries. Consequently, it has become indispensable to preserve the distillation efficacy when transferring knowledge from a Transformer-based teacher model to a CNN-based student model, known as Cross-Architecture Knowledge Distillation (CAKD). Despite its potential, the deployment of CAKD in face recognition encounters two challenges: 1) the teacher and student share disparate spatial information for each pixel, obstructing the alignment of feature space, and 2) the teacher network is not trained in the role of a teacher, lacking proficiency in handling distillation-specific knowledge. To surmount these two constraints, 1) we first introduce a Unified Receptive Fields Mapping module (URFM) that maps pixel features of the teacher and student into local features with unified receptive fields, thereby synchronizing the pixel-wise spatial information of teacher and student. Subsequently, 2) we develop an Adaptable Prompting Teacher network (APT) that integrates prompts into the teacher, enabling it to manage distillation-specific knowledge while preserving the model's discriminative capacity. Extensive experiments on popular face benchmarks and two large-scale verification sets demonstrate the superiority of our method.","face recognition, transformer, knowledge distillation","","MM '23"
"Conference Paper","Chen Yuan,Rong Pan","Compressed-Transformer: Distilling Knowledge from Transformer for Neural Machine Translation","","2021","","","131–137","Association for Computing Machinery","New York, NY, USA","Proceedings of the 4th International Conference on Natural Language Processing and Information Retrieval","Seoul, Republic of Korea","2021","9781450377607","","https://doi.org/10.1145/3443279.3443302;http://dx.doi.org/10.1145/3443279.3443302","10.1145/3443279.3443302","Recently, Transformer has achieved state-of-the-art performance in neural machine translation. However, the number of parameters in Transformer is so large that it needs to be compressed before deployed and executed on resource-restricted devices. In this paper, we propose a compressed version of Transformer called Compressed-Transformer. We introduce two techniques, factorizing parameters and block reduction, to compress Transformer model. Consequently, the number of parameters can be reduced by more than 50%. We exploit a stage-wise distillation strategy with the temperature dynamically adjusted in knowledge distillation practice to transfer knowledge from base Transformer (teacher) to Compressed-Transformer (student). A Chinese-to-English (Zh En) dataset of United Nations Parallel Corpus and a German-to-English (De En) dataset of Multi30K are used, and the experimental results show that our compressed model achieves BLEU score only slightly lower than uncompressed teacher model. Specially, when the number of parameters is reduced by 59.3%, the student model can achieve BLEU score of 40.69, only 1.64 lower than that of the teacher model, and the inference speed is improved by 17% on Zh En dataset. The experiments on De En dataset also achieve the similar results.","neural machine translation, knowledge distillation, stage-wise distillation strategy, Compressed-Transformer, factorize parameters","","NLPIR '20"
"Conference Paper","Xu J,Zhang S,Yang J","Adaptive Decoupled Pose Knowledge Distillation","","2023","","","4401–4409","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st ACM International Conference on Multimedia","Ottawa ON, Canada","2023","","","https://doi.org/10.1145/3581783.3611818;http://dx.doi.org/10.1145/3581783.3611818","10.1145/3581783.3611818","Existing state-of-the-art human pose estimation approaches require heavy computational resources for accurate prediction. One promising technique to obtain an accurate yet lightweight pose estimator is Knowledge Distillation (KD), which distills the pose knowledge from a powerful teacher model to a lightweight student model. However, existing human pose KD methods focus more on designing paired student and teacher network architectures, yet ignore the mechanism of pose knowledge distillation. In this work, we reformulate the human pose KD to a coarse to fine process and decouple the classical KD loss into three terms: Binary Keypoint vs. Non-Keypoint Distillation (BiKD), Keypoint Area Distillation (KAD) and Non-keypoint Area Distillation (NAD). Observing the decoupled formulation, we point out an important limitation of the classical pose KD, i.e. the bias between different loss terms limits the performance gain of the student network. To address the biased knowledge distillation problem, we present a novel KD method named Adaptive Decoupled Pose knowledge Distillation (ADPD), enabling BiKD, KAD and NAD to play their roles more effectively and flexibly. Extensive experiments on two standard human pose datasets, MPII and MS COCO, demonstrate that our proposed method outperforms previous KD methods and is generalizable to different teacher-student pairs. The code will be available at https://github.com/SuperJay1996/ADPD.","adaptive weighting, knowledge distillation, human pose estimation, neural networks","","MM '23"
"Conference Paper","Liu F,Chen H,Cheng Z,Nie L,Kankanhalli M","Semantic-Guided Feature Distillation for Multimodal Recommendation","","2023","","","6567–6575","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st ACM International Conference on Multimedia","Ottawa ON, Canada","2023","","","https://doi.org/10.1145/3581783.3611886;http://dx.doi.org/10.1145/3581783.3611886","10.1145/3581783.3611886","Multimodal recommendation exploits the rich multimodal information associated with users or items to enhance the representation learning for better performance. In these methods, end-to-end feature extractors (e.g., shallow/deep neural networks) are often adopted to tailor the generic multimodal features that are extracted from raw data by pre-trained models for recommendation. However, compact extractors, such as shallow neural networks, may find it challenging to extract effective information from complex and high-dimensional generic modality features. Conversely, DNN-based extractors may encounter the data sparsity problem in recommendation. To address this problem, we propose a novel model-agnostic approach called Semantic-guided Feature Distillation (SGFD), which employs a teacher-student framework to extract feature for multimodal recommendation. The teacher model first extracts rich modality features from the generic modality feature by considering both the semantic information of items and the complementary information of multiple modalities. SGFD then utilizes response-based and feature-based distillation loss to effectively transfer the knowledge encoded in the teacher model to the student model. To evaluate the effectiveness of our SGFD, we integrate SGFD into three backbone multimodal recommendation models. Extensive experiments on three public real-world datasets demonstrate that SGFD-enhanced models can achieve substantial improvement over their counterparts.","knowledge distillation, multimodal recommendation, deep learning, collaborative filtering","","MM '23"
"Conference Paper","Doroudi S,Aleven V,Brunskill E","Robust Evaluation Matrix: Towards a More Principled Offline Exploration of Instructional Policies","","2017","","","3–12","Association for Computing Machinery","New York, NY, USA","Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale","Cambridge, Massachusetts, USA","2017","9781450344500","","https://doi.org/10.1145/3051457.3051463;http://dx.doi.org/10.1145/3051457.3051463","10.1145/3051457.3051463","The gold standard for identifying more effective pedagogical approaches is to perform an experiment. Unfortunately, frequently a hypothesized alternate way of teaching does not yield an improved effect. Given the expense and logistics of each experiment, and the enormous space of potential ways to improve teaching, it would be highly preferable if it were possible to estimate in advance of running a study whether an alternative teaching strategy would improve learning. This is true even in learning at scale situations, since even if it is logistically easier to recruit a large number of subjects, it remains a high stakes environment because the experiment is impacting many real students. For certain classes of alternate teaching approaches, such as new ways to sequence existing material, it is possible to build student models that can be used as simulators to estimate the performance of learners under new proposed teaching methods. However, existing methods for doing so can overestimate the performance of new teaching methods. We instead propose the Robust Evaluation Matrix (REM) method which explicitly considers model mismatch between the student model used to derive the teaching strategy and that used as a simulator to evaluate the teaching strategy effectiveness. We then present two case studies from a fractions intelligent tutoring system and from a concept learning task from prior work that show how REM could be used both to detect when a new instructional policy may not be effective on actual students and to detect when it may be effective in improving student learning.","policy selection, off-policy, reinforcement learning, instructional policies, policy estimation","","L@S '17"
"Journal Article","Dinkel H,Wang S,Xu X,Wu M,Yu K","Voice Activity Detection in the Wild: A Data-Driven Approach Using Teacher-Student Training","IEEE/ACM Trans. Audio, Speech and Lang. Proc.","2021","29","","1542–1555","IEEE Press","","","","2021-04","","2329-9290","https://doi.org/10.1109/TASLP.2021.3073596;http://dx.doi.org/10.1109/TASLP.2021.3073596","10.1109/TASLP.2021.3073596","Voice activity detection is an essential pre-processing component for speech-related tasks such as automatic speech recognition (ASR). Traditional supervised VAD systems obtain frame-level labels from an ASR pipeline by using, e.g., a Hidden Markov model. These ASR models are commonly trained on clean and fully transcribed data, limiting VAD systems to be trained on clean or synthetically noised datasets. Therefore, a major challenge for supervised VAD systems is their generalization towards noisy, real-world data. This work proposes a data-driven teacher-student approach for VAD, which utilizes vast and unconstrained audio data for training. Unlike previous approaches, only weak labels during teacher training are required, enabling the utilization of any real-world, potentially noisy dataset. Our approach firstly trains a teacher model on a source dataset (Audioset) using clip-level supervision. After training, the teacher provides frame-level guidance to a student model on an unlabeled, target dataset. A multitude of student models trained on mid- to large-sized datasets are investigated (Audioset, Voxceleb, NIST SRE). Our approach is then respectively evaluated on clean, artificially noised, and real-world data. We observe significant performance gains in artificially noised and real-world scenarios. Lastly, we compare our approach against other unsupervised and supervised VAD methods, demonstrating our method's superiority.","","",""
"Conference Paper","Zhang W,Miao X,Shao Y,Jiang J,Chen L,Ruas O,Cui B","Reliable Data Distillation on Graph Convolutional Network","","2020","","","1399–1414","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data","Portland, OR, USA","2020","9781450367356","","https://doi.org/10.1145/3318464.3389706;http://dx.doi.org/10.1145/3318464.3389706","10.1145/3318464.3389706","Graph Convolutional Network (GCN) is a widely used method for learning from graph-based data. However, it fails to use the unlabeled data to its full potential, thereby hindering its ability. Given some pseudo labels of the unlabeled data, the GCN can benefit from this extra supervision. Based on Knowledge Distillation and Ensemble Learning, lots of methods use a teacher-student architecture to make better use of the unlabeled data and then make a better prediction. However, these methods introduce unnecessary training costs and a high bias of student model if the teacher's predictions are unreliable. Besides, the final ensemble gains are limited due to limited diversity in the combined models. Therefore, we propose Reliable Data Distillation, a reliable data driven semi-supervised GCN training method. By defining the node reliability and edge reliability in a graph, we can make better use of high quality data and improve the graph representation learning. Furthermore, considering the data reliability and data importance, we propose a new ensemble learning method for GCN and a novel Self-Boosting SSL Framework to combine the above optimizations. Finally, our extensive evaluation of Reliable Data Distillation on real-world datasets shows that our approach outperforms the state-of-the-art methods on semi-supervised node classification tasks.","semi-supervised learning, ensemble learning, knowledge distillation, graph convolutional network","","SIGMOD '20"
"Conference Paper","Zhang Y,Chen W,Lu Y,Huang T,Sun X,Cao J","Avatar Knowledge Distillation: Self-Ensemble Teacher Paradigm with Uncertainty","","2023","","","5272–5280","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st ACM International Conference on Multimedia","Ottawa ON, Canada","2023","","","https://doi.org/10.1145/3581783.3611788;http://dx.doi.org/10.1145/3581783.3611788","10.1145/3581783.3611788","Knowledge distillation is an effective paradigm for boosting the performance of pocket-size model, especially when multiple teacher models are available, the student would break the upper limit again. However, it is not economical to train diverse teacher models for the disposable distillation. In this paper, we introduce a new concept dubbed Avatars for distillation, which are the inference ensemble models derived from the teacher. Concretely, (1) For each iteration of distillation training, various Avatars are generated by a perturbation transformation. We validate that Avatars own higher upper limit of working capacity and teaching ability, aiding the student model in learning diverse and receptive knowledge perspectives from the teacher model. (2) During the distillation, we propose an uncertainty-aware factor from the variance of statistical differences between the vanilla teacher and Avatars, to adjust Avatars' contribution on knowledge transfer adaptively. Avatar Knowledge Distillation (AKD) is fundamentally different from existing methods and refines with the innovative view of unequal training. Comprehensive experiments demonstrate the effectiveness of our Avatars mechanism, which polishes up the state-of-the-art distillation methods for dense prediction without more extra computational cost. The AKD brings at most 0.7 AP gains on COCO 2017 for Object Detection and 1.83 mIoU gains on Cityscapes for Semantic Segmentation, respectively.","avatars mechanism, knowledge distillation, model compression","","MM '23"
"Conference Paper","Kim M,Tariq S,Woo SS","CoReD: Generalizing Fake Media Detection with Continual Representation Using Distillation","","2021","","","337–346","Association for Computing Machinery","New York, NY, USA","Proceedings of the 29th ACM International Conference on Multimedia","Virtual Event, China","2021","9781450386517","","https://doi.org/10.1145/3474085.3475535;http://dx.doi.org/10.1145/3474085.3475535","10.1145/3474085.3475535","Over the last few decades, artificial intelligence research has made tremendous strides, but it still heavily relies on fixed datasets in stationary environments. Continual learning is a growing field of research that examines how AI systems can learn sequentially from a continuous stream of linked data in the same way that biological systems do. Simultaneously, fake media such as deepfakes and synthetic face images have emerged as significant to current multimedia technologies. Recently, numerous method has been proposed which can detect deepfakes with high accuracy. However, they suffer significantly due to their reliance on fixed datasets in limited evaluation settings. Therefore, in this work, we apply continuous learning to neural networks' learning dynamics, emphasizing its potential to increase data efficiency significantly. We propose Continual Representation using Distillation (CoReD) method that employs the concept of Continual Learning (CL), Representation Learning (RL), and Knowledge Distillation (KD). We design CoReD to perform sequential domain adaptation tasks on new deepfake and GAN-generated synthetic face datasets, while effectively minimizing the catastrophic forgetting in a teacher-student model setting. Our extensive experimental results demonstrate that our method is efficient at domain adaptation to detect low-quality deepfakes videos and GAN-generated images from several datasets, outperforming the-state-of-art baseline methods.","knowledge distillation, continual learning, incremental learning, catastrophic forgetting, deepfake, representation learning","","MM '21"
"Conference Paper","Lao M,Pu N,Liu Y,Zhong Z,Bakker EM,Sebe N,Lew MS","Multi-Domain Lifelong Visual Question Answering via Self-Critical Distillation","","2023","","","4747–4758","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st ACM International Conference on Multimedia","Ottawa ON, Canada","2023","","","https://doi.org/10.1145/3581783.3612121;http://dx.doi.org/10.1145/3581783.3612121","10.1145/3581783.3612121","Visual Question Answering (VQA) has achieved significant success over the last few years, while most studies focus on training a VQA model on a stationary domain (e.g., a given dataset). In real-world application scenarios, however, these methods are often inefficient because VQA systems are always supposed to extend their knowledge and meet the ever-changing demands of users. In this paper, we introduce a new and challenging multi-domain lifelong VQA task, dubbed MDL-VQA, which encourages the VQA model to continuously learn across multiple domains while mitigating the forgetting on previously-learned domains. Furthermore, we propose a novel replay-free Self-Critical Distillation (SCD) framework tailor-made for MDL-VQA, which alleviates forgetting issue via transferring previous-domain knowledge from teacher to student models. First, we propose to introspect the teacher's understanding over original and counterfactual samples, thereby creating informative instance-relevant and domain-relevant knowledge for logits-based distillation. Second, on the side of feature-based distillation, we propose to introspect the reasoning behavior of student model to establish the harmful domain-specific knowledge acquired in current domain, and further leverage the metric learning strategy to encourage student to learn useful knowledge in new domain. Extensive experiments demonstrate that SCD framework outperforms state-of-the-art competitors with different training orders.","visual question answering, lifelong learning, knowledge distillation, multi-domain learning","","MM '23"
"Conference Paper","Guo S,Gu Y,Wen S,Ma Y,Chen Y,Wang J,Hu C","KiCi: A Knowledge Importance Based Class Incremental Learning Method for Wearable Activity Recognition","","2022","","","646–655","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st ACM International Conference on Information & Knowledge Management","Atlanta, GA, USA","2022","9781450392365","","https://doi.org/10.1145/3511808.3557371;http://dx.doi.org/10.1145/3511808.3557371","10.1145/3511808.3557371","Wearable-based human activity recognition (HAR) is commonly employed in real-world scenarios such as health monitoring, auxiliary diagnosis, etc. As implementing activity recognition is a daunting challenge in an open dynamic environment, incremental learning has become a common method to adapt to variable behavior patterns of users and create dynamic modeling in activity recognition. However, catastrophic forgetting is a significant challenge with incremental learning. This is contrary to our expectations of identifying new activity classes while remembering existing ones. To address this problem, we propose a knowledge importance-based class incremental learning method called KiCi and construct an incremental learning model based on the framework of self-iterative knowledge distillation for dynamic activity recognition. To eliminate the prediction bias of the teacher model on the old knowledge, we utilize the trained weights of previous incremental steps generated by the teacher model as the prior knowledge to obtain knowledge importance. Then use it to make the student model have a reasonable trade-off between old and new knowledge and mitigate catastrophic forgetting by avoiding negative transfer. We conduct extensive experiments on four public HAR datasets and our method consistently outperforms the existing state-of-the-art methods by a large margin.","activity recognition, class incremental learning, knowledge distillation","","CIKM '22"
"Conference Paper","Hao Z,Lu C,Huang Z,Wang H,Hu Z,Liu Q,Chen E,Lee C","ASGN: An Active Semi-Supervised Graph Neural Network for Molecular Property Prediction","","2020","","","731–752","Association for Computing Machinery","New York, NY, USA","Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","Virtual Event, CA, USA","2020","9781450379984","","https://doi.org/10.1145/3394486.3403117;http://dx.doi.org/10.1145/3394486.3403117","10.1145/3394486.3403117","Molecular property prediction (e.g., energy) is an essential problem in chemistry and biology. Unfortunately, many supervised learning methods usually suffer from the problem of scarce labeled molecules in the chemical space, where such property labels are generally obtained by Density Functional Theory (DFT) calculation which is extremely computational costly. An effective solution is to incorporate the unlabeled molecules in a semi-supervised fashion. However, learning semi-supervised representation for large amounts of molecules is challenging, including the joint representation issue of both molecular essence and structure, the conflict between representation and property leaning. Here we propose a novel framework called Active Semi-supervised Graph Neural Network (ASGN) by incorporating both labeled and unlabeled molecules. Specifically, ASGN adopts a teacher-student framework. In the teacher model, we propose a novel semi-supervised learning method to learn general representation that jointly exploits information from molecular structure and molecular distribution. Then in the student model, we target at property prediction task to deal with the learning loss conflict. At last, we proposed a novel active learning strategy in terms of molecular diversities to select informative data during the whole framework learning. We conduct extensive experiments on several public datasets. Experimental results show the remarkable performance of our ASGN framework.","molecular property prediction, active learning, semi-supervised learning, graph neural network","","KDD '20"
"Conference Paper","Zhang Z,Li Y,Wang J,Liu B,Li D,Guo Y,Chen X,Liu Y","ReMoS: Reducing Defect Inheritance in Transfer Learning via relevant model slicing","","2022","","","1856–1868","Association for Computing Machinery","New York, NY, USA","Proceedings of the 44th International Conference on Software Engineering","Pittsburgh, Pennsylvania","2022","9781450392211","","https://doi.org/10.1145/3510003.3510191;http://dx.doi.org/10.1145/3510003.3510191","10.1145/3510003.3510191","Transfer learning is a popular software reuse technique in the deep learning community that enables developers to build custom models (students) based on sophisticated pretrained models (teachers). However, like vulnerability inheritance in traditional software reuse, some defects in the teacher model may also be inherited by students, such as well-known adversarial vulnerabilities and backdoors. Reducing such defects is challenging since the student is unaware of how the teacher is trained and/or attacked. In this paper, we propose ReMoS, a relevant model slicing technique to reduce defect inheritance during transfer learning while retaining useful knowledge from the teacher model. Specifically, ReMoS computes a model slice (a subset of model weights) that is relevant to the student task based on the neuron coverage information obtained by profiling the teacher model on the student task. Only the relevant slice is used to finetune the student model, while the irrelevant weights are retrained from scratch to minimize the risk of inheriting defects. Our experiments on seven DNN defects, four DNN models, and eight datasets demonstrate that ReMoS can reduce inherited defects effectively (by 63% to 86% for CV tasks and by 40% to 61% for NLP tasks) and efficiently with minimal sacrifice of accuracy (3% on average).","program slicing, deep neural networks, relevant slicing","","ICSE '22"
"Conference Paper","Wang X,MacAvaney S,Macdonald C,Ounis I","An Inspection of the Reproducibility and Replicability of TCT-ColBERT","","2022","","","2790–2800","Association for Computing Machinery","New York, NY, USA","Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval","Madrid, Spain","2022","9781450387323","","https://doi.org/10.1145/3477495.3531721;http://dx.doi.org/10.1145/3477495.3531721","10.1145/3477495.3531721","Dense retrieval approaches are of increasing interest because they can better capture contextualised similarity compared to sparse retrieval models such as BM25. Among the most prominent of these approaches is TCT-ColBERT, which trains a light-weight ""student'' model from a more expensive ""teacher'' model. In this work, we take a closer look into TCT-ColBERT concerning its reproducibility and replicability. To structure our study, we propose a three-stage perspective on reproducing the training, inference, and evaluation of model-focused papers, each using artefacts produced from different stages in the pipeline. We find that --- perhaps as expected --- precise reproduction is more challenging when the complete training process is conducted, rather than just inference from a released trained model. Each stage provides the opportunity to perform replication and ablation experiments. We are able to replicate (i.e., produce an effective independent implementation) for model inference and dense indexing/retrieval, but are unable to replicate the training process. We conduct several ablations to cover gaps in the original paper, and make the following observations: (1) the model can function as an inexpensive re-ranker, establishing a new Pareto-optimal result; (2) the index size can be reduced by using lower-precision floating point values, but only if ties in scores are handled appropriately; (3) training needs to be conducted for the entire suggested duration to achieve optimal performance; and (4) student initialisation from the teacher is not necessary.","dense retrieval, reproducibility, knowledge distillation","","SIGIR '22"
"Conference Paper","Blanca-Estela PM,Josefina GG","Semiautomated Cognitive Tutor, to Serve as a Support in Upper Secondary Students in Solving Algebra Problems","","2017","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the XVIII International Conference on Human Computer Interaction","Cancun, Mexico","2017","9781450352291","","https://doi.org/10.1145/3123818.3123876;http://dx.doi.org/10.1145/3123818.3123876","10.1145/3123818.3123876","Learning mathematics is closely related with the fact that the student knows how to solve problems. There are cognitive theories that say that problem solving teaching requires techniques based on the student's cognitive ability, linked to the type of problems or examples (when cognitive ability is low) that must work. This process requires automated tools to identify the characteristics of the students in order to provide more personalized teaching strategies and also manage feedback that helps the student and the teacher to identify their achievements. These types of automated tools are known as cognitive tutors, which are intelligent tutoring systems, with the particularity of being focused on providing individualized support to students to improve their complex cognitive skills, through problem-solving practice. On the other hand, it is considered that algebra, in addition to arithmetic, are the areas that serve as the basis for the understanding of many mathematical subjects. Therefore, in this thesis project a semi-automated tool is proposed, by means of which, the different modules of a cognitive tutor are implemented, following an instructional design for solving algebra problems, through the management of gamification and game strategies based on the techniques of computational theory of tangible user interfaces. For the student model module, a fuzzy model is used to detect and classify the student's cognitive ability. In modules of model of the domain and the tutor model, fuzzy cognitive maps are defined and implemented to determine, respectively, the activities related to the different types of problems related to various algebra topics and to determine the pedagogical activities that the student must follow in each of the stages of problem solving.","cognitive ability, problem solving, intelligent tutorial systems, worked examples, instructional design, teaching - learning algebra, expertise reversal, tangible user interfaces, gamification, evaluation, fuzzy logic, fuzzy cognitive maps, cognitive tutors, cognitive load theory","","Interacción '17"
"Conference Paper","Li X,Chen X,Huang Z,Xie L,Chen J,Yang M","Fine-Grained Pseudo Labels for Scene Text Recognition","","2023","","","5786–5795","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st ACM International Conference on Multimedia","Ottawa ON, Canada","2023","","","https://doi.org/10.1145/3581783.3611791;http://dx.doi.org/10.1145/3581783.3611791","10.1145/3581783.3611791","Pseudo-Labeling based semi-supervised learning has shown promising advantages in Scene Text Recognition (STR). Most of them usually use a pre-trained model to generate sequence-level pseudo labels for text images and then re-train the model. Recently, conducting Pseudo-Labeling in a teacher-student framework (a student model is supervised by the pseudo labels from a teacher model) has become increasingly popular, which trains in an end-to-end manner and yields outstanding performance in semi-supervised learning. However, applying this framework directly to Pseudo-Labeling STR exhibits unstable convergence, as generating pseudo labels at the coarse-grained sequence-level leads to inefficient utilization of unlabelled data. Furthermore, the inherent domain shift between labeled and unlabeled data results in low quality of derived pseudo labels. To mitigate the above issues, we propose a novel Cross-domain Pseudo-Labeling (CPL) approach for scene text recognition, which makes better utilization of unlabeled data at the character-level and provides more accurate pseudo labels. Specifically, our proposed Pseudo-Labeled Curriculum Learning dynamically adjusts the thresholds for different character classes according to the model's learning status. Moreover, an Adaptive Distribution Regularizer is employed to bridge the domain gap and improve the quality of pseudo labels. Extensive experiments show that CPL boosts those representative STR models to achieve state-of-the-art results on six challenging STR benchmarks. Besides, it can be effectively generalized to handwritten text.","scene text recognition, pseudo labels, domain shift","","MM '23"
"Conference Paper","Ding S,Feng F,He X,Jin J,Wang W,Liao Y,Zhang Y","Interpolative Distillation for Unifying Biased and Debiased Recommendation","","2022","","","40–49","Association for Computing Machinery","New York, NY, USA","Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval","Madrid, Spain","2022","9781450387323","","https://doi.org/10.1145/3477495.3532002;http://dx.doi.org/10.1145/3477495.3532002","10.1145/3477495.3532002","Most recommender systems evaluate model performance offline through either: 1) normal biased test on factual interactions; or 2) debiased test with records from the randomized controlled trial. In fact, both tests only reflect part of the whole picture: factual interactions are collected from the recommendation policy, fitting them better implies benefiting the platform with higher click or conversion rate; in contrast, debiased test eliminates system-induced biases and thus is more reflective of user true preference. Nevertheless, we find that existing models exhibit trade-off on the two tests, and there lacks methods that perform well on both tests.In this work, we aim to develop a win-win recommendation method that is strong on both tests. It is non-trivial, since it requires to learn a model that can make accurate prediction in both factual environment (ie normal biased test) and counterfactual environment (ie debiased test). Towards the goal, we perform environment-aware recommendation modeling by considering both environments. In particular, we propose an Interpolative Distillation (InterD) framework, which interpolates the biased and debiased models at user-item pair level by distilling a student model. We conduct experiments on three real-world datasets with both tests. Empirical results justify the rationality and effectiveness of InterD, which stands out on both tests especially demonstrates remarkable gains on less popular items.","debiasing, recommendation, distillation, system-induced biases","","SIGIR '22"
"Journal Article","Shen SQ,Chen Y,Yang C,Liu ZY,Sun MS","Zero-Shot Cross-Lingual Neural Headline Generation","IEEE/ACM Trans. Audio, Speech and Lang. Proc.","2018","26","12","2319–2327","IEEE Press","","","","2018-12","","2329-9290","https://doi.org/10.1109/TASLP.2018.2842432;http://dx.doi.org/10.1109/TASLP.2018.2842432","10.1109/TASLP.2018.2842432","Neural headline generation NHG has been proven to be effective in generating a fully abstractive headline recently. Existing NHG systems are only capable of producing headline of the same language as the original document. Cross lingual headline generation is an important task since it provides an efficient way to understand the key point of a document in a different language. Due to the lack of those parallel corpora of direct source language articles and target language headlines, we propose to deal with the cross-lingual neural headline generation CNHG under the zero-shot scenario. A trivial solution is to translate and summarize the source document in a pipeline way. However, a pipeline solution will lead to error propagation in the translation and summarization phases. This challenge motivates us to build a direct source-to-target CNHG model based on existing parallel corpora of translation and monolingual headline generation. Specifically, we let a parameterized CNHG model student model mimic the output of a pretrained translation or headline generation model teacher model. To the best of our knowledge, this is the first effort to address CNHG problem. Besides, we construct English–Chinese headline generation evaluation datasets by manual translation. Experimental results on English-to-Chinese cross-lingual headline generation demonstrate that our proposed method significantly outperforms the baseline models.","","",""
"Journal Article","Liang Y,Yin Z,Liu H,Zeng H,Wang J,Liu J,Che N","Weakly Supervised Deep Nuclei Segmentation With Sparsely Annotated Bounding Boxes for DNA Image Cytometry","IEEE/ACM Trans. Comput. Biol. Bioinformatics","2021","20","1","785–795","IEEE Computer Society Press","Washington, DC, USA","","","2021-12","","1545-5963","https://doi.org/10.1109/TCBB.2021.3138189;http://dx.doi.org/10.1109/TCBB.2021.3138189","10.1109/TCBB.2021.3138189","Nuclei segmentation is an essential step in DNA ploidy analysis by image-based cytometry (DNA-ICM) which is widely used in cytopathology and allows an objective measurement of DNA content (ploidy). The routine fully supervised learning-based method requires often tedious and expensive pixel-wise labels. In this paper, we propose a novel weakly supervised nuclei segmentation framework which exploits only sparsely annotated bounding boxes, without any segmentation labels. The key is to integrate the traditional image segmentation and self-training into fully supervised instance segmentation. We first leverage the traditional segmentation to generate coarse masks for each box-annotated nucleus to supervise the training of a teacher model, which is then responsible for both the refinement of these coarse masks and pseudo labels generation of unlabeled nuclei. These pseudo labels and refined masks along with the original manually annotated bounding boxes jointly supervise the training of student model. Both teacher and student share the same architecture and especially the student is initialized by the teacher. We have extensively evaluated our method with both our DNA-ICM dataset and public cytopathological dataset. Without bells and whistles, our method outperforms all existing weakly supervised entries on both datasets. Code and our DNA-ICM dataset are publicly available at https://github.com/CVIU-CSU/Weakly-Supervised-Nuclei-Segmentation.","","",""
"Conference Paper","Liu Y,Sheng L,Shao J,Yan J,Xiang S,Pan C","Multi-Label Image Classification via Knowledge Distillation from Weakly-Supervised Detection","","2018","","","700–708","Association for Computing Machinery","New York, NY, USA","Proceedings of the 26th ACM International Conference on Multimedia","Seoul, Republic of Korea","2018","9781450356657","","https://doi.org/10.1145/3240508.3240567;http://dx.doi.org/10.1145/3240508.3240567","10.1145/3240508.3240567","Multi-label image classification is a fundamental but challenging task towards general visual understanding. Existing methods found the region-level cues (e.g., features from RoIs) can facilitate multi-label classification. Nevertheless, such methods usually require laborious object-level annotations (i.e., object labels and bounding boxes) for effective learning of the object-level visual features. In this paper, we propose a novel and efficient deep framework to boost multi-label classification by distilling knowledge from weakly-supervised detection task without bounding box annotations. Specifically, given the image-level annotations, (1) we first develop a weakly-supervised detection (WSD) model, and then (2) construct an end-to-end multi-label image classification framework augmented by a knowledge distillation module that guides the classification model by the WSD model according to the class-level predictions for the whole image and the object-level visual features for object RoIs. The WSD model is the teacher model and the classification model is the student model. After this cross-task knowledge distillation, the performance of the classification model is significantly improved and the efficiency is maintained since the WSD model can be safely discarded in the test phase. Extensive experiments on two large-scale datasets (MS-COCO and NUS-WIDE) show that our framework achieves superior performances over the state-of-the-art methods on both performance and efficiency.","weakly-supervised detection, knowledge distillation, multi-label image classification","","MM '18"
"Conference Paper","Liu T,Gao C,Wang Z,Li D,Hao J,Jin D,Li Y","Uncertainty-Aware Consistency Learning for Cold-Start Item Recommendation","","2023","","","2466–2470","Association for Computing Machinery","New York, NY, USA","Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval","Taipei, Taiwan","2023","9781450394086","","https://doi.org/10.1145/3539618.3592078;http://dx.doi.org/10.1145/3539618.3592078","10.1145/3539618.3592078","Graph Neural Network (GNN)-based models have become the mainstream approach for recommender systems. Despite the effectiveness, they are still suffering from the cold-start problem, i.e., recommend for few-interaction items. Existing GNN-based recommendation models to address the cold-start problem mainly focus on utilizing auxiliary features of users and items, leaving the user-item interactions under-utilized. However, embeddings distributions of cold and warm items are still largely different, since cold items' embeddings are learned from lower-popularity interactions, while warm items' embeddings are from higher-popularity interactions. Thus, there is a seesaw phenomenon, where the recommendation performance for the cold and warm items cannot be improved simultaneously. To this end, we proposed a Uncertainty-aware Consistency learning framework for Cold-start item recommendation (shorten as UCC) solely based on user-item interactions. Under this framework, we train the teacher model (generator) and student model (recommender) with consistency learning, to ensure the cold items with additionally generated low-uncertainty interactions can have similar distribution with the warm items. Therefore, the proposed framework improves the recommendation of cold and warm items at the same time, without hurting any one of them. Extensive experiments on benchmark datasets demonstrate that our proposed method significantly outperforms state-of-the-art methods on both warm and cold items, with an average performance improvement of 27.6%.","cold-start item, graph neural networks, recommender system","","SIGIR '23"
"Conference Paper","Charan G,Hazra J,Beckmann K,Du X,Krishnan G,Joshi RV,Cady NC,Cao Y","Accurate Inference with Inaccurate RRAM Devices: Statistical Data, Model Transfer, and on-Line Adaptation","","2020","","","","IEEE Press","Virtual Event, USA","Proceedings of the 57th ACM/EDAC/IEEE Design Automation Conference","","2020","9781450367257","","","","Resistive random-access memory (RRAM) is a promising technology for in-memory computing with high storage density, fast inference, and good compatibility with CMOS. However, the mapping of a pre-trained deep neural network (DNN) model on RRAM suffers from realistic device issues, especially the variation and quantization error, resulting in a significant reduction in inference accuracy. In this work, we first extract these statistical properties from 65 nm RRAM data on 300mm wafers. The RRAM data present 10--levels in quantization and 50% variance, resulting in an accuracy drop to 31.76% and 10.49% for MNIST and CIFAR-10 datasets, respectively. Based on the experimental data, we propose a combination of machine learning algorithms and on-line adaptation to recover the accuracy with the minimum overhead. The recipe first applies Knowledge Distillation (KD) to transfer an ideal model into a student model with statistical variations and 10 levels. Furthermore, an on-line sparse adaptation (OSA) method is applied to the DNN model mapped on to the RRAM array. Using importance sampling, OSA adds a small SRAM array that is sparsely connected to the main RRAM array; only this SRAM array is updated to recover the accuracy. As demonstrated on MNIST and CIFAR-10 datasets, a 7.86% area cost is sufficient to achieve baseline accuracy for the 65 nm RRAM devices.","robustness, knowledge distillation, in-memory computing, resistive random access memory (RRAM), on-line adaptation","","DAC '20"
"Journal Article","Neuvial P","Asymptotic Results on Adaptive False Discovery Rate Controlling Procedures Based on Kernel Estimators","J. Mach. Learn. Res.","2013","14","1","1423–1459","JMLR.org","","","","2013-05","","1532-4435","","","The False Discovery Rate (FDR) is a commonly used type I error rate in multiple testing problems. It is defined as the expected False Discovery Proportion (FDP), that is, the expected fraction of false positives among rejected hypotheses. When the hypotheses are independent, the Benjamini-Hochberg procedure achieves FDR control at any pre-specified level. By construction, FDR control offers no guarantee in terms of power, or type II error. A number of alternative procedures have been developed, including plug-in procedures that aim at gaining power by incorporating an estimate of the proportion of true null hypotheses.In this paper, we study the asymptotic behavior of a class of plug-in procedures based on kernel estimators of the density of the p-values, as the number m of tested hypotheses grows to infinity. In a setting where the hypotheses tested are independent, we prove that these procedures are asymptotically more powerful in two respects: (i) a tighter asymptotic FDR control for any target FDR level and (ii) a broader range of target levels yielding positive asymptotic power. We also show that this increased asymptotic power comes at the price of slower, non-parametric convergence rates for the FDP. These rates are of the form m-k/(2k+1), where k is determined by the regularity of the density of the p-value distribution, or, equivalently, of the test statistics distribution. These results are applied to one- and two-sided tests statistics for Gaussian and Laplace location models, and for the Student model.","power, criticality, adaptive control, multiple testing, false discovery rate, kernel estimators, test statistics distribution, Benjamini Hochberg's procedure, plug-in procedures, convergence rates","",""
"Conference Paper","Tian Z,Bai T,Zhang Z,Xu Z,Lin K,Wen JR,Zhao WX","Directed Acyclic Graph Factorization Machines for CTR Prediction via Knowledge Distillation","","2023","","","715–723","Association for Computing Machinery","New York, NY, USA","Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining","Singapore, Singapore","2023","9781450394079","","https://doi.org/10.1145/3539597.3570384;http://dx.doi.org/10.1145/3539597.3570384","10.1145/3539597.3570384","With the growth of high-dimensional sparse data in web-scale recommender systems, the computational cost to learn high-order feature interaction in CTR prediction task largely increases, which limits the use of high-order interaction models in real industrial applications. Some recent knowledge distillation based methods transfer knowledge from complex teacher models to shallow student models for accelerating the online model inference. However, they suffer from the degradation of model accuracy in knowledge distillation process. It is challenging to balance the efficiency and effectiveness of the shallow student models. To address this problem, we propose a Directed Acyclic Graph Factorization Machine (KD-DAGFM) to learn the high-order feature interactions from existing complex interaction models for CTR prediction via Knowledge Distillation. The proposed lightweight student model DAGFM can learn arbitrary explicit feature interactions from teacher networks, which achieves approximately lossless performance and is proved by a dynamic programming algorithm. Besides, an improved general model KD-DAGFM+ is shown to be effective in distilling both explicit and implicit feature interactions from any complex teacher model. Extensive experiments are conducted on four real-world datasets, including a large-scale industrial dataset from WeChat platform with billions of feature dimensions. KD-DAGFM achieves the best performance with less than 21.5% FLOPs of the state-of-the-art method on both online and offline experiments, showing the superiority of DAGFM to deal with the industrial scale data in CTR prediction task.","graph factorization machine, knowledge distillation, recommender systems, CTR prediction","","WSDM '23"
"Journal Article","Yoon JW,Lee H,Kim HY,Cho WI,Kim NS","TutorNet: Towards Flexible Knowledge Distillation for End-to-End Speech Recognition","IEEE/ACM Trans. Audio, Speech and Lang. Proc.","2021","29","","1626–1638","IEEE Press","","","","2021-04","","2329-9290","https://doi.org/10.1109/TASLP.2021.3071662;http://dx.doi.org/10.1109/TASLP.2021.3071662","10.1109/TASLP.2021.3071662","In recent years, there has been a great deal of research in developing end-to-end speech recognition models, which enable simplifying the traditional pipeline and achieving promising results. Despite their remarkable performance improvements, end-to-end models typically require expensive computational cost to show successful performance. To reduce this computational burden, knowledge distillation (KD), which is a popular model compression method, has been used to transfer knowledge from a deep and complex model (teacher) to a shallower and simpler model (student). Previous KD approaches have commonly designed the architecture of the student by reducing the width per layer or the number of layers of the teacher. This structural reduction scheme might limit the flexibility of model selection since the student model structure should be similar to that of the given teacher. To cope with this limitation, we propose a KD method for end-to-end speech recognition, namely TutorNet, that applies KD techniques across different types of neural networks at the hidden representation-level as well as the output-level. For concrete realizations, we firstly apply representation-level knowledge distillation (RKD) during the initialization step, and then apply the softmax-level knowledge distillation (SKD) combined with the original task learning. When the student is trained with RKD, we make use of frame weighting that points out the frames to which the teacher pays more attention. Through a number of experiments, it is verified that TutorNet not only distills the knowledge between networks with different topologies but also significantly contributes to improving the performance of the distilled student.","","",""
"Conference Paper","Liu Z,Guo J,Yang M,Yang W,Fan J,Lam KY","Privacy-Enhanced Knowledge Transfer with Collaborative Split Learning over Teacher Ensembles","","2023","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2023 Secure and Trustworthy Deep Learning Systems Workshop","Melbourne, VIC, Australia","2023","","","https://doi.org/10.1145/3591197.3591303;http://dx.doi.org/10.1145/3591197.3591303","10.1145/3591197.3591303","Knowledge Transfer has received much attention for its ability to transfer knowledge, rather than data, from one application task to another. In order to comply with the stringent data privacy regulations, privacy-preserving knowledge transfer is highly desirable. The Private Aggregation of Teacher Ensembles (PATE) scheme is one promising approach to address this privacy concern while supporting knowledge transfer from an ensemble of ""teacher"" models to a ""student"" model under the coordination of an aggregator. To further protect the data privacy of the student node, the privacy-enhanced version of PATE makes use of cryptographic techniques at the expense of heavy computation overheads at the teacher nodes. However, this inevitably hinders the adoption of knowledge transfer due to the highly disparate computational capability of teachers. Besides, in real-life systems, participating teachers may drop out of the system at any time, which causes new security risks for adopted cryptographic building blocks. Thus, it is desirable to devise privacy-enhanced knowledge transfer that can run on teacher nodes with relatively fewer computational resources and can preserve privacy with dropped teacher nodes. In this connection, we propose a dropout-resilient and privacy-enhanced knowledge transfer scheme, Collaborative Split learning over Teacher Ensembles (CSTE), that supports the participating teacher nodes to train and infer their local models using split learning. CSTE not only allows the compute-intensive processing to be performed at a split learning server, but also protects the data privacy of teacher nodes from collusion between the student node and aggregator. Experimental results showed that CSTE achieves significant efficiency improvement from existing schemes.","privacy-preservation, Knowledge transfer, collaborative split learning","","SecTL '23"
"Conference Paper","Li X,He S,Wu J,Yu Y,Nie L,Zhang M","Mask Again: Masked Knowledge Distillation for Masked Video Modeling","","2023","","","2221–2232","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st ACM International Conference on Multimedia","Ottawa ON, Canada","2023","","","https://doi.org/10.1145/3581783.3612129;http://dx.doi.org/10.1145/3581783.3612129","10.1145/3581783.3612129","Masked video modeling has shown remarkable performance in downstream tasks by predicting masked video tokens from visible ones. However, training models from scratch on large-scale unlabeled data remains computationally challenging and time-consuming. Moreover, the commonly used random-based sampling techniques may lead to the selection of redundant or low-information regions, hindering the model from learning discriminative representations within the limited training epochs. To achieve efficient pre-training, we propose MaskAgain, an efficient feature-based knowledge distillation framework for masked video pre-training that facilitates knowledge transfer from a pre-trained teacher model to a student model. In contrast to previous approaches that align all visible token features with the teacher model at output layers, MaskAgain adopts a selective approach by masking visible tokens again at both the hidden and output layers of the transformer block. Attention mechanisms are utilized for informative feature selection. At the hidden level, attention maps generated by the transformer's multi-head attention structure are utilized to select crucial token information at both temporally-global and temporally-local levels. Additionally, at the output level, an activation-based attention map is generated using token features, enabling us to focus on important tokens while preserving feature similarity and the relationship matrix similarity between patches. Extensive experimental results show that MaskAgain achieves comparable or even better performance than existing methods on benchmark datasets with much fewer training epochs and much less memory, which demonstrates that MaskAgain allows for efficient pre-training of accurate video models, reducing computational resources and training time significantly. Code is released at https://github.com/xiaojieli0903/MaskAgain.","video representation learning, masked visual modeling, knowledge distillation","","MM '23"
"Journal Article","Liang X,Wu L,Li J,Qin T,Zhang M,Liu TY","Multi-Teacher Distillation With Single Model for Neural Machine Translation","IEEE/ACM Trans. Audio, Speech and Lang. Proc.","2022","30","","992–1002","IEEE Press","","","","2022-02","","2329-9290","https://doi.org/10.1109/TASLP.2022.3153264;http://dx.doi.org/10.1109/TASLP.2022.3153264","10.1109/TASLP.2022.3153264","Knowledge distillation (KD) is an effective strategy for neural machine translation (NMT) to improve the performance of a student model. Usually, the teacher can guide the student to be better by distilling the soft label or data knowledge from the teacher itself. However, the data diversity and teacher knowledge are limited with only one teacher model. Though a natural solution is to adopt multiple randomized teacher models, one big shortcoming is that the model parameters and training costs are largely increased with the number of teacher models. In this work, we explore to mimic multiple teacher distillation from the sub-network space and permuted variants of one single teacher model. Specifically, we train a teacher by multiple sub-network extraction paradigms: sub-layer reordering, layer-drop, and dropout variants. In doing so, one teacher model can provide multiple outputs variants and causes neither additional parameters nor much extra training cost. Experiments on 8 IWSLT datasets: IWSLT14 En $leftrightarrow$ De, En $leftrightarrow$ Es and IWSLT17 En $leftrightarrow$ Fr, En $leftrightarrow$ Zh and the large WMT14 EN $to$ DE translation tasks show that our method even achieves nearly comparable performance with multiple teacher models with different randomized parameters, both word-level and sequence-level knowledge distillation. Our code is available online at https://github.com/dropreg/RLD.","","",""
"Conference Paper","Tian J,Xu X,Cao Z,Zhang G,Shen F,Yang Y","Zero-Shot Sketch-Based Image Retrieval with Adaptive Balanced Discriminability and Generalizability","","2023","","","407–415","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2023 ACM International Conference on Multimedia Retrieval","Thessaloniki, Greece","2023","","","https://doi.org/10.1145/3591106.3592287;http://dx.doi.org/10.1145/3591106.3592287","10.1145/3591106.3592287","Zero-shot sketch-based image retrieval (ZS-SBIR) is a task that learns semantic knowledge and embedding extraction to retrieve similar images using a sketch without any training examples of unseen classes. Existing methods have attempted to address the modal and semantic gaps in ZS-SBIR by using various strategies such as leveraging category linguistic information for improved discriminability and utilizing knowledge distillation to increase the model’s generalizability towards unseen classes. However, these methods fail to consider the importance of discriminability and generalizability in a unified manner. To address this, we propose a novel method called Adaptive Balanced Discriminability and Generalizability (ABDG) for ZS-SBIR. Specifically, our ABDG method utilizes an advanced two-stage knowledge distillation scheme to balance the learning of discriminability and generalizability for each instance. In addition to task-agnostic teacher models to preserve structural information used in existing work, we introduce a task-specific teacher model pre-trained with a classification objective function to emphasize the discriminability property during knowledge distillation. We also employ a novel entropy-based weighting strategy to balance the effects of structural information preservation and classification losses specific to the classification progress of each instance. Furthermore, we use fine-grained semantic relevance to refine the ego predictions of the student model, with the aim of improving its performance as the training objective continues to converge. Experimental results on three benchmark datasets of ZS-SBIR demonstrate that our ABDG method establishes a state-of-the-art performance by balancing the learning of discriminative and generalizable properties.","Sketch-Based Image Retrieval, Knowledge Distillation, Zero-shot Learning","","ICMR '23"
"Conference Paper","Xu C,Li Q,Ge J,Gao J,Yang X,Pei C,Sun F,Wu J,Sun H,Ou W","Privileged Features Distillation at Taobao Recommendations","","2020","","","2590–2598","Association for Computing Machinery","New York, NY, USA","Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","Virtual Event, CA, USA","2020","9781450379984","","https://doi.org/10.1145/3394486.3403309;http://dx.doi.org/10.1145/3394486.3403309","10.1145/3394486.3403309","Features play an important role in the prediction tasks of e-commerce recommendations. To guarantee the consistency of off-line training and on-line serving, we usually utilize the same features that are both available. However, the consistency in turn neglects some discriminative features. For example, when estimating the conversion rate (CVR), i.e., the probability that a user would purchase the item if she clicked it, features like dwell time on the item detailed page are informative. However, CVR prediction should be conducted for on-line ranking before the click happens. Thus we cannot get such post-event features during serving.We define the features that are discriminative but only available during training as the privileged features. Inspired by the distillation techniques which bridge the gap between training and inference, in this work, we propose privileged features distillation (PFD). We train two models, i.e., a student model that is the same as the original one and a teacher model that additionally utilizes the privileged features. Knowledge distilled from the more accurate teacher is transferred to the student, which helps to improve its prediction accuracy. During serving, only the student part is extracted and it relies on no privileged features. We conduct experiments on two fundamental prediction tasks at Taobao recommendations, i.e., click-through rate (CTR) at coarse-grained ranking and CVR at fine-grained ranking. By distilling the interacted features that are prohibited during serving for CTR and the post-event features for CVR, we achieve significant improvements over their strong baselines. During the on-line A/B tests, the click metric is improved by +5.0% in the CTR task. And the conversion metric is improved by +2.3% in the CVR task. Besides, by addressing several issues of training PFD, we obtain comparable training speed as the baselines without any distillation.","ctr, e-commerce recommendations, privileged features, cvr, distillation","","KDD '20"
"Conference Paper","Zhao W,Zhang H,Zheng C,Yan X,Cui S,Li Z","CPU: Codebook Lookup Transformer with Knowledge Distillation for Point Cloud Upsampling","","2023","","","3917–3925","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st ACM International Conference on Multimedia","Ottawa ON, Canada","2023","","","https://doi.org/10.1145/3581783.3612048;http://dx.doi.org/10.1145/3581783.3612048","10.1145/3581783.3612048","Point clouds produced by 3D scanning are typically sparse, non-uniform, and noisy. Existing upsampling techniques directly learn the mapping from a sparse point set to a dense point set, which is often under-determined and ill-posed. To reduce the uncertainty and ambiguity of the upsampling mapping, this paper proposes a generic three-stage vector-quantization framework, which incorporates a Codebook lookup Transformer and knowledge distillation for Point Cloud Upsampling, named CPU. The proposed CPU reformulates the upsampling task into a relatively determinate code prediction task within a small, discrete proxy space. Since the traditional vector-quantization methods cannot be directly applied to point cloud upsampling scenarios, we introduce a knowledge distillation training scheme that facilitates efficient codebook learning and ensures full utilization of codebook entries. Specifically, we adopt a teacher-student training paradigm to avoid model collapse during codebook learning. In the first stage, we pre-train a vanilla auto-encoder of the dense point set as the teacher model, which provides rich guidance features to ensure sufficient codebook learning. In the second stage, we train a vector-quantized auto-encoder as a student model to capture high-fidelity geometric priors into a learned codebook with the aid of distillation. In the third stage, we propose a Codebook Lookup Transformer to model the global context of the sparse point set and predict the code indices. Then the coarse features of the sparse point set can be quantized and substituted by looking up the indices in the learned codebook. Benefiting from the expressive codebook priors and the distillation training scheme, the proposed CPU outperforms state-of-the-art methods quantitatively and qualitatively.","knowledge distillation, vector quantization, codebook learning, point cloud upsampling","","MM '23"
"Conference Paper","Ni J,Ngu AH,Yan Y","Progressive Cross-Modal Knowledge Distillation for Human Action Recognition","","2022","","","5903–5912","Association for Computing Machinery","New York, NY, USA","Proceedings of the 30th ACM International Conference on Multimedia","Lisboa, Portugal","2022","9781450392037","","https://doi.org/10.1145/3503161.3548238;http://dx.doi.org/10.1145/3503161.3548238","10.1145/3503161.3548238","Wearable sensor-based Human Action Recognition (HAR) has achieved remarkable success recently. However, the accuracy performance of wearable sensor-based HAR is still far behind the ones from the visual modalities-based system (i.e., RGB video, skeleton and depth). Diverse input modalities can provide complementary cues and thus improve the accuracy performance of HAR, but how to take advantage of multi-modal data on wearable sensor-based HAR has rarely been explored. Currently, wearable devices, i.e., smartwatches, can only capture limited kinds of non-visual modality data. This hinders the multi-modal HAR association as it is unable to simultaneously use both visual and non-visual modality data. Another major challenge lies in how to efficiently utilize multi-modal data on wearable devices with their limited computation resources. In this work, we propose a novel Progressive Skeleton-to-sensor Knowledge Distillation (PSKD) model which utilizes only time-series data, i.e., accelerometer data, from a smartwatch for solving the wearable sensor-based HAR problem. Specifically, we construct multiple teacher models using data from both teacher (human skeleton sequence) and student (time-series accelerometer data) modalities. In addition, we propose an effective progressive learning scheme to eliminate the performance gap between teacher and student models. We also designed a novel loss function called Adaptive-Confidence Semantic (ACS), to allow the student model to adaptively select either one of the teacher models or the ground-truth label it needs to mimic. To demonstrate the effectiveness of our proposed PSKD method, we conduct extensive experiments on Berkeley-MHAD, UTD-MHAD and MMAct datasets. The results confirm that the proposed PSKD method has competitive performance compared to the previous mono sensor-based HAR methods.","machine learning, progressive learning, sensor-based human activity recognition, knowledge distillation","","MM '22"
"Conference Paper","Paul I,Negi S","Sub-Task Imputation via Self-Labelling to Train Image Moderation Models on Sparse Noisy Data","","2022","","","3461–3471","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st ACM International Conference on Information & Knowledge Management","Atlanta, GA, USA","2022","9781450392365","","https://doi.org/10.1145/3511808.3557149;http://dx.doi.org/10.1145/3511808.3557149","10.1145/3511808.3557149","E-commerce marketplaces protect shopper experience and trust at scale by deploying deep learning models trained on human annotated moderation data, for the identification and removal of advert imagery that does not comply with moderation policies (a.k.a. defective images). However, human moderation labels can be hard to source for smaller advert programs that target specific device types with separate formats or for recently launched locales with unique moderation policies. Additionally, the sourced labels can be noisy due to annotator biases or policy rules clubbing multiple types of transgressions into a single category. Therefore, training advert image moderation models necessitates an approach that can effectively improve the sample efficiency of training, weed out noise and discover latent moderation sub-labels in one go.Our work demonstrates the merits of automated sub-label discovery using self-labelling. We show that self-labelling approaches can be used to decompose an image moderation task into its hidden sub-tasks (corresponding to intercepting a single sub-label) in an unsupervised manner, thus helping with cases where the granularity of labels is inadequate. This enables us to bootstrap useful representations quickly, via low-capacity but fast-learning teacher models that each specialize in a single distinct sub-task of the main classification task. These sub-task specialists then distil their logits to a high-capacity but slow-learning generalist student model, thus allowing it to perform well on complex moderation tasks with relatively fewer labels than vanilla supervised training. We conduct all our experiments on the moderation of sexually explicit advert images (though this method can be utilized for any defect type) and show a sizeable improvement in NPV (+30.2% absolute gain) viz-a-viz regular supervised baselines at a 1% FPR level. A long-term A/B test of our deployed model shows a significant relative reduction (-45.6%) in the prevalence of such advertisements compared to the previously deployed model.","self-labelling, knowledge distillation, neural networks, computer vision","","CIKM '22"
"Journal Article","Zhao C,Caragea C","Deep Gated Multi-Modal Fusion for Image Privacy Prediction","ACM Trans. Web","2023","17","4","","Association for Computing Machinery","New York, NY, USA","","","2023-10","","1559-1131","https://doi.org/10.1145/3608446;http://dx.doi.org/10.1145/3608446","10.1145/3608446","With the rapid development of technologies in mobile devices, people can post their daily lives on social networking sites such as Facebook, Flickr, and Instagram. This leads to new privacy concerns due to people’s lack of understanding that private information can be leaked and used to their detriment. Image privacy prediction models are developed to predict whether images contain sensitive information (private images) or are safe to be shared online (public images). Despite significant progress on this task, there are still some crucial problems that remain to be solved. Firstly, images’ content and tags are found to be useful modalities to automatically predict images’ privacy. To date, most image privacy prediction models use single modalities (image-only or tag-only), which limits their performance. Secondly, we observe that current image privacy prediction models are surprisingly vulnerable to even small perturbations in the input data. Attackers can add small perturbations to input data and easily damage a well-trained image privacy prediction model. To address these challenges, in this article, we propose a new decision-level Gated multi-modal fusion (GMMF) approach that fuses object, scene, and image tags modalities to predict privacy for online images. In particular, the proposed approach identifies fusion weights of class probability distributions generated by single-modal classifiers according to their reliability of the privacy prediction for each target image in a sample-by-sample manner and performs a weighted decision-level fusion, so that modalities with high reliability are assigned with higher fusion weights while ones with low reliability are restrained with lower fusion weights. The results of our experiments show that the gated multi-modal fusion network effectively fuses single modalities and outperforms state-of-the-art models for image privacy prediction. Moreover, we perform adversarial training on our proposed GMMF model using multiple types of noise on input data (i.e., images and/or tags). When some modalities are failed by input data with noise attacks, our approach effectively utilizes clean modalities and minimizes negative influences brought by degraded ones using fusion weights, achieving significantly stronger robustness over traditional fusion methods for image privacy prediction. The robustness of our GMMF model against data noise can even be generalized to more severe noise levels. To the best of our knowledge, we are the first to investigate the robustness of image privacy prediction models against noise attacks. Moreover, as the performance of decision-level multi-modal fusion depends highly on the quality of single-modal networks, we investigate self-distillation on single-modal privacy classifiers and observe that transferring knowledge from a trained teacher model to a student model is beneficial in our proposed approach.","Image privacy prediction, deep neural network, multi-modal fusion","",""
